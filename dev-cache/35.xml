<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-06-24T14:14:47+00:00</updated><id>/feed.xml</id><title type="html">Considerations on Codecrafting</title><subtitle>Programming, math, and other things gratuitously nerdy</subtitle><entry><title type="html">Hitting the wall with Rust’s borrow checker</title><link href="/2024/06/24/hitting-the-wall-with-rust-s-borrow-checker.html" rel="alternate" type="text/html" title="Hitting the wall with Rust’s borrow checker" /><published>2024-06-24T06:16:00+00:00</published><updated>2024-06-24T06:16:00+00:00</updated><id>/2024/06/24/hitting-the-wall-with-rust-s-borrow-checker</id><content type="html" xml:base="/2024/06/24/hitting-the-wall-with-rust-s-borrow-checker.html"><![CDATA[<p>For many years, I’ve dreamed of creating my own programming language with advanced type checking, but no matter how hard I try, I’ve never been able to find a design that satisfies me. The fundamental dilemma runs as follows:</p>

<ol>
  <li><a href="/2023/03/05/fixing-the-next-10-000-aliasing-bugs.html">In order to catch common bugs, you need linear types, lifetimes, and borrow checking.</a></li>
  <li>In order to be useful, functions have to be generic over lifetimes.</li>
  <li>In order to be useful, you need to be able to pass around lifetime-generic functions (aka higher rank lifetimes).</li>
  <li>In order to be useful, you need to support closures, methods, or equivalent functionality.</li>
  <li>In order to be useful, you need some form of subtyping for lifetimes, whether this is explicit intersections and unions or generic lifetime bounds.</li>
  <li>Typechecking higher rank lifetimes with subtyping is NP-Complete, meaning it requires exponential time in the worst case and leads to bad error messages.</li>
  <li>I want my language to have fast <em>worst case</em> compilation times.</li>
</ol>

<p>Today I got curious to see how Rust solves this dilemma, as Rust is the first mainstream language with borrow checking and lifetimes. Unfortunately, the answer turns out to be that <strong>it doesn’t</strong>. Not even the <em>easy</em> part. If you do anything even the slightest bit complicated, the compiler just yells at you to go away and hope that <a href="https://blog.rust-lang.org/inside-rust/2023/10/06/polonius-update.html">Polonius</a> might someday fix things.</p>

<p>Let’s see how lifetime checking works in Rust, or rather doesn’t work.</p>

<p><strong>Note: The following is entirely based on experimentation with the Rust Playground and some failed searches for help. It is possible that there’s some obscure workaround I wasn’t able to find. In fact, I would <em>very much like</em> to be wrong about this. Please let me know if I am.</strong></p>

<p><strong>Update: It turns out that the “true intersection” section is incorrect, and I just had a typo in the code.</strong></p>

<h1 id="basic-lifetime-bounds">Basic lifetime bounds</h1>

<p>First, we have the most basic function. This just takes in a reference and returns the same reference. Since we want it to be usable for references with arbitrary lifetimes, we define a lifetime parameter (the <code class="language-plaintext highlighter-rouge">&lt;'a&gt;</code> part between <code class="language-plaintext highlighter-rouge">id</code> and <code class="language-plaintext highlighter-rouge">(</code>), and then annotate the function as taking an argument of type <code class="language-plaintext highlighter-rouge">&amp;'a u8</code> and returning the type <code class="language-plaintext highlighter-rouge">&amp;'a u8</code>.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">id</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="n">a</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now let’s try a slightly more complicated function, where we take in <em>two</em> references with different lifetimes, and can return either one of them.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;???</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Defining two lifetime parameters and corresponding argument types is straightforward enough, but what is the return type? What goes in the <code class="language-plaintext highlighter-rouge">???</code> part? We need a lifetime that is the <em>intersection</em> of <code class="language-plaintext highlighter-rouge">'a</code> and <code class="language-plaintext highlighter-rouge">'b</code>, i.e. a lifetime that lasts only as long as both <code class="language-plaintext highlighter-rouge">'a</code> <em>and</em> <code class="language-plaintext highlighter-rouge">'b</code> are still valid. You might expect to be able to write <code class="language-plaintext highlighter-rouge">'a &amp; 'b</code> or something for the intersection, but unfortunately, Rust does not have syntax for lifetime intersections or unions. Instead, we’ll have to use a minor workaround.</p>

<p>This particular example actually has a much simpler solution. Thanks to variance, we don’t actually need multiple lifetimes in the first place. We can just use a single lifetime for everything.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, it’s easy to modify the example so that a single lifetime no longer works. For example, what if we want to return the first reference (<code class="language-plaintext highlighter-rouge">a</code>) <em>and</em> a reference that can be either <code class="language-plaintext highlighter-rouge">a</code> or <code class="language-plaintext highlighter-rouge">b</code>?</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;???</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In this case, using a single lifetime will no longer work. If we did try to use a single lifetime, the first return value would incorrectly be tied to the second argument. Therefore a second lifetime of some sort is required. Fortunately, this isn’t hard to fake.</p>

<p>Rust doesn’t have intersections or unions, but it does let you specify <em>bounds</em> on the lifetime parameters, which is just as good. In particular, we can solve this example by adding the bound <code class="language-plaintext highlighter-rouge">'a: 'b</code>, which says that <code class="language-plaintext highlighter-rouge">'a</code> <em>outlives</em> <code class="language-plaintext highlighter-rouge">'b</code>, and thus <code class="language-plaintext highlighter-rouge">'b</code> is a subtype of <code class="language-plaintext highlighter-rouge">'a</code>.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="nv">'b</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<h1 id="true-intersections"><del>True intersections</del></h1>

<p><strong>Edit: This section is incorrect. It turns out that I just had a typo in my code.</strong></p>

<p><del>The previous example works because we never return a reference of lifetime <code class="language-plaintext highlighter-rouge">'b</code> only, so we can afford to “reinterpret” <code class="language-plaintext highlighter-rouge">'b</code> as actually being <code class="language-plaintext highlighter-rouge">'a &amp; 'b</code> thanks to variance. However, we can modify the example by returning <em>both</em> input references as well as their intersection:</del></p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice3</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;???</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p><del>What should go in the <code class="language-plaintext highlighter-rouge">???</code>? The natural approach is to try adding a <em>third</em> dummy lifetime parameter to represent the intersection of <code class="language-plaintext highlighter-rouge">'a</code> and <code class="language-plaintext highlighter-rouge">'b</code>. We’ll call this dummy lifetime <code class="language-plaintext highlighter-rouge">'a_and_b</code> and add the bounds <code class="language-plaintext highlighter-rouge">'a: 'a_and_b</code> and <code class="language-plaintext highlighter-rouge">'b: 'a_and_b</code> in order to force <code class="language-plaintext highlighter-rouge">'a_and_b</code> to be at most as long as the intersection of <code class="language-plaintext highlighter-rouge">'a</code> and <code class="language-plaintext highlighter-rouge">'b</code>.</del></p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice3</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="nv">'a_and_b</span><span class="p">,</span> <span class="nv">'b</span><span class="p">:</span> <span class="nv">'a_and_b</span><span class="p">,</span> <span class="nv">'a_and_b</span><span class="o">&gt;</span><span class="p">(</span>
    <span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span>
    <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span>
<span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'a_and_b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span> <span class="n">a</span> <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="n">b</span> <span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p><del>This <em>should</em> work, but unfortunately, the compiler emits a spurious error instead:</del></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error: lifetime may not live long enough
  --&gt; src/lib.rs:18:5
   |
14 | fn choice3&lt;'a: 'a_and_b, 'b: 'a_and_b, 'a_and_b&gt;(
   |            --          -- lifetime `'b` defined here
   |            |
   |            lifetime `'a` defined here
...
18 |    (a, b, if (true) { a } else { b })
   |    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ function was supposed to return data with lifetime `'b` but it is returning data with lifetime `'a`
   |
   = help: consider adding the following bound: `'a: 'b`
</code></pre></div></div>

<p><del>For some reason, the Rust compiler seems to <em>really, really</em> not like intersections. If you ever attempt to intersect two lifetimes, it will force you to add a linear ordering between them for no good reason.</del></p>

<p><del>To be honest, I didn’t expect to get stuck this quickly. I figured that Rust probably only had partial support for higher rank lifetimes, but I assumed that at least the most basic functions which just take and return a lifetime directly would be well supported. Unfortunately, that’s not the case.</del></p>

<h1 id="higher-rank-lifetimes">Higher rank lifetimes</h1>

<p>It turns out that even basic pure functions are broken, but let’s see how <em>higher rank</em> lifetimes are handled as well, for completeness. So what is a higher rank lifetime?</p>

<p>Remember our <code class="language-plaintext highlighter-rouge">id</code> function before? What is its type?</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">id</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="n">a</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">_ID</span><span class="p">:</span> <span class="o">???</span> <span class="o">=</span> <span class="n">id</span><span class="p">;</span>
</code></pre></div></div>

<p>What goes in the <code class="language-plaintext highlighter-rouge">???</code>? <code class="language-plaintext highlighter-rouge">id</code> is a function that can take in a reference with <em>any</em> lifetime and returns a reference with the <em>same</em> lifetime. It is <em>generic</em> over the input lifetime. Therefore, any <em>specific</em> lifetime we try to put in the type signature is incorrect. We need some way of writing a <em>type signature</em> with a generic lifetime parameter. These are known as <em>higher rank lifetimes</em>.</p>

<p>As it turns out, this is possible in Rust. The way to do it is with the syntax <code class="language-plaintext highlighter-rouge">for&lt;'a&gt; ...</code>. In particular, the type of our <code class="language-plaintext highlighter-rouge">id</code> function can be written as <code class="language-plaintext highlighter-rouge">for&lt;'a&gt; fn(&amp;'a u8) -&gt; &amp;'a u8</code>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="n">_ID</span><span class="p">:</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span> <span class="o">=</span> <span class="n">id</span><span class="p">;</span>
</code></pre></div></div>

<p>Now what about our <code class="language-plaintext highlighter-rouge">choice2</code> function? This is basically the same as <code class="language-plaintext highlighter-rouge">id</code> except with the added complication that we need to put a <em>bound</em> on the <code class="language-plaintext highlighter-rouge">'a</code> parameter as well. The natural thing to try would be to use the same bound syntax as before:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="nv">'b</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">})</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">_CHOICE2</span><span class="p">:</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="nv">'b</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span> <span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">=</span> <span class="n">choice2</span><span class="p">;</span>
</code></pre></div></div>

<p>Rust’s <em>grammar</em> even does allow bounds here. Unfortunately, the compiler as a whole does not:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error: bounds cannot be used in this context
  --&gt; src/lib.rs:18:26
   |
18 | static _CHOICE2: for&lt;'a: 'b, 'b&gt; fn(&amp;'a u8, &amp;'b u8) -&gt; (&amp;'a u8, &amp;'b u8) = choice2;
   |                        ^^
</code></pre></div></div>

<p>For some reason, you can’t actually write bounds in types, even though this is usually required to represent the actual types of functions.</p>

<p>Fortunately, there is a secret, very ugly workaround. You can’t write <em>explicit</em> bounds in types, but Rust will magically insert <em>implicit</em> bounds in some cases, which work just as well. Specifically, if any part of the type mentions something like <code class="language-plaintext highlighter-rouge">&amp;'b &amp;'a ()</code>, Rust will implicitly add a <code class="language-plaintext highlighter-rouge">'a: 'b</code> bound, and implicit bounds <em>are</em> still allowed in types.</p>

<p>Therefore, we can add a completely pointless extra dummy parameter to the function with a type that mentions <code class="language-plaintext highlighter-rouge">&amp;'b &amp;'a ()</code>, in order to insert the implicit bound we need. This requires callers to pass a dummy parameter everywhere for no reason, but hey, at least it works:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">marker</span><span class="p">::</span><span class="n">PhantomData</span><span class="p">;</span>
<span class="k">fn</span> <span class="n">choice2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">phantom</span><span class="p">:</span> <span class="n">PhantomData</span><span class="o">&lt;&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span> <span class="n">a</span> <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="n">b</span> <span class="p">})</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">_CHOICE2</span><span class="p">:</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span> <span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">=</span>
    <span class="n">choice2</span><span class="p">;</span>
</code></pre></div></div>

<h1 id="closures">Closures</h1>

<p>So far, we’ve only looked at the <em>easy</em> case, with simple pure functions. Now let’s see how Rust handles <em>closures</em>. Specifically, let’s see what happens if we want to bind values to our <code class="language-plaintext highlighter-rouge">choice2</code> function in order to create a partial function. Recall that <code class="language-plaintext highlighter-rouge">choice2</code> was defined as follows:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="nv">'b</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span><span class="n">a</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span><span class="n">b</span><span class="p">})</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Let’s see what happens if we want to <em>bind</em> a <em>specific</em> value to a parameter. For example, one thing we could do is bind the dummy parameter so callers don’t have to pass it at every callsite.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">outer</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">bound</span> <span class="o">=</span> <span class="p">|</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">|</span> <span class="nf">choice2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">PhantomData</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now, what is the type of <code class="language-plaintext highlighter-rouge">bound</code>? As it turns out, it is impossible to name the type of <code class="language-plaintext highlighter-rouge">bound</code>, not just because of lifetimes, but for <a href="/2024/06/07/the-inconceivable-types-of-rust-how-to-make-self-borrows-safe.html#unnameable-types">unrelated dumb reasons</a> as well. We can solve <em>that</em> particular issue by boxing everything and using <code class="language-plaintext highlighter-rouge">dyn Trait</code> for no reason (no, not even <code class="language-plaintext highlighter-rouge">impl Trait</code> is allowed here).</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">outer</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">bound</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">:</span> <span class="o">???</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">=</span>
        <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">|</span> <span class="nf">choice2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">PhantomData</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, even with the <code class="language-plaintext highlighter-rouge">Box</code>, it’s still impossible to name the type due to the lack of support for lifetime bounds. Remember, the whole reason we even added the <code class="language-plaintext highlighter-rouge">PhantomData</code> parameter in the first place is that it is necessary in order to make the function type nameable in Rust’s type system. Therefore, we’ll have to give up on this line.</p>

<p>Now let’s try binding an external reference value (<code class="language-plaintext highlighter-rouge">x</code>) to the first parameter (<code class="language-plaintext highlighter-rouge">a</code>). Fortunately, this part actually works for once:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">+</span> <span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span>
        <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Binding <code class="language-plaintext highlighter-rouge">x</code> to the <code class="language-plaintext highlighter-rouge">b</code> parameter also works:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">bound_b</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;&amp;</span><span class="nv">'x</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">+</span> <span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span>
        <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">a</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div>

<h1 id="fixing-variance">Fixing variance</h1>

<p>Unfortunately, the extra <code class="language-plaintext highlighter-rouge">PhantomData</code> parameter in the previous examples doesn’t just add pointless noise to every callsite, it also breaks <em>variance</em>.</p>

<p>Suppose hypothetically that Rust supported lifetime bounds and the dummy parameter was not necessary. In that case, our <code class="language-plaintext highlighter-rouge">bound_a</code> closure <code class="language-plaintext highlighter-rouge">|b| choice2(x, b)</code> would just have the type <code class="language-plaintext highlighter-rouge">for&lt;'b&gt; Fn(&amp;'b u8) -&gt; (&amp;'x u8, &amp;('b &amp; 'x) u8)&gt;</code>.</p>

<p>This is <em>covariant</em> in <code class="language-plaintext highlighter-rouge">'x</code>, meaning that substituting a longer lifetime for <code class="language-plaintext highlighter-rouge">'x</code> results in a subtype, and vice versa. For example, if we instead bound a <code class="language-plaintext highlighter-rouge">'static</code> lifetime, the result should be something that is a <em>subtype</em> of the <code class="language-plaintext highlighter-rouge">'x</code> version. However, the <code class="language-plaintext highlighter-rouge">PhantomData</code> parameter is covariant in <code class="language-plaintext highlighter-rouge">'x</code> (which gets flipped to <em>contravariant</em> since it is a function parameter), making the function type overall is <em>invariant</em>.</p>

<p>In order to restore the correct variance, we have to change the <code class="language-plaintext highlighter-rouge">PhantomData</code> to something <em>contravariant</em> like so:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">choice2b</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">phantom</span><span class="p">:</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="k">if</span> <span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="p">{</span> <span class="n">a</span> <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="n">b</span> <span class="p">})</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">_CHOICE2B</span><span class="p">:</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="o">&gt;</span> <span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">=</span>
    <span class="n">choice2b</span><span class="p">;</span>
</code></pre></div></div>

<p>We can then bind closures with <code class="language-plaintext highlighter-rouge">choice2b</code> like before:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer2</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">+</span> <span class="nv">'x</span><span class="p">,</span>
    <span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2b</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>

    <span class="c1">// Check reassigning with same type</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span> <span class="o">+</span> <span class="nv">'x</span><span class="p">,</span>
    <span class="o">&gt;</span> <span class="o">=</span> <span class="n">bound_a</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Since repeating the type like that all the time makes the code very verbose, let’s define a type alias <code class="language-plaintext highlighter-rouge">BoundA&lt;'bound&gt;</code> to make things clearer:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer2</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">type</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'bound</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'bound</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'bound</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span>
            <span class="o">+</span> <span class="nv">'bound</span><span class="p">,</span>
    <span class="o">&gt;</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2b</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
    
    <span class="c1">// Check reassigning with same type</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">bound_a</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h1 id="subtyping">Subtyping</h1>

<p>Now let’s test whether variance actually works. Since our <code class="language-plaintext highlighter-rouge">bound_a</code> closure is covariant in <code class="language-plaintext highlighter-rouge">'x</code>, we should be able to bind a <code class="language-plaintext highlighter-rouge">'static</code> reference instead of <code class="language-plaintext highlighter-rouge">x</code> and assign it to the <code class="language-plaintext highlighter-rouge">BoundA&lt;'x&gt;</code> type and have it still work.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer2</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">type</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'bound</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'bound</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'bound</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span>
            <span class="o">+</span> <span class="nv">'bound</span><span class="p">,</span>
    <span class="o">&gt;</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">s</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">u8</span> <span class="o">=</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2b</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
    
    <span class="c1">// Check reassigning with same type</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">bound_a</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Notice how we’re now binding <code class="language-plaintext highlighter-rouge">s</code> inside the closure instead of <code class="language-plaintext highlighter-rouge">x</code>. This part does work.</p>

<p>We can also bind <code class="language-plaintext highlighter-rouge">s</code> and give it a <code class="language-plaintext highlighter-rouge">BoundA&lt;'static&gt;</code> type. This works as well:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer2</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">type</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'bound</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'bound</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'bound</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span>
            <span class="o">+</span> <span class="nv">'bound</span><span class="p">,</span>
    <span class="o">&gt;</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">s</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">u8</span> <span class="o">=</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2b</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now it’s time to test subtyping. Logically, if our <code class="language-plaintext highlighter-rouge">s</code> closure works when assigned to the <code class="language-plaintext highlighter-rouge">BoundA&lt;'x&gt;</code> type <em>and</em> works when assigned to the <code class="language-plaintext highlighter-rouge">BoundA&lt;'static&gt;</code> type, and <code class="language-plaintext highlighter-rouge">BoundA&lt;'static&gt;</code> is a subtype of <code class="language-plaintext highlighter-rouge">BoundA&lt;'x&gt;</code>, we should be able to first assign it to the <code class="language-plaintext highlighter-rouge">BoundA&lt;'static&gt;</code> and then reassign it to the <code class="language-plaintext highlighter-rouge">BoundA&lt;'x&gt;</code> and have it still work. Right???</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">outer2</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'x</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">type</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'bound</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nb">Box</span><span class="o">&lt;</span>
        <span class="k">dyn</span> <span class="k">for</span><span class="o">&lt;</span><span class="nv">'b</span><span class="o">&gt;</span> <span class="nf">Fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="k">fn</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'b</span> <span class="o">&amp;</span><span class="nv">'bound</span> <span class="p">())</span> <span class="k">-&gt;</span> <span class="p">()</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="o">&amp;</span><span class="nv">'bound</span> <span class="nb">u8</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="nb">u8</span><span class="p">)</span>
            <span class="o">+</span> <span class="nv">'bound</span><span class="p">,</span>
    <span class="o">&gt;</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">s</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">u8</span> <span class="o">=</span> <span class="o">&amp;</span><span class="mi">0</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(|</span><span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">|</span> <span class="nf">choice2b</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">phantom</span><span class="p">));</span>
    
    <span class="k">let</span> <span class="n">bound_a</span><span class="p">:</span> <span class="n">BoundA</span><span class="o">&lt;</span><span class="nv">'x</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">bound_a</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error: lifetime may not live long enough
  --&gt; src/lib.rs:75:18
   |
68 | fn outer2&lt;'x&gt;(x: &amp;'x u8) {
   |           -- lifetime `'x` defined here
...
75 |     let bound_a: BoundA&lt;'static&gt; = Box::new(|b, phantom| choice2b(s, b, phantom));
   |                  ^^^^^^^^^^^^^^^ type annotation requires that `'x` must outlive `'static`
</code></pre></div></div>

<h1 id="-">(╯°□°)╯︵ ┻━┻</h1>]]></content><author><name></name></author><summary type="html"><![CDATA[For many years, I’ve dreamed of creating my own programming language with advanced type checking, but no matter how hard I try, I’ve never been able to find a design that satisfies me. The fundamental dilemma runs as follows:]]></summary></entry><entry><title type="html">The Inconceivable Types of Rust: How to Make Self-Borrows Safe</title><link href="/2024/06/07/the-inconceivable-types-of-rust-how-to-make-self-borrows-safe.html" rel="alternate" type="text/html" title="The Inconceivable Types of Rust: How to Make Self-Borrows Safe" /><published>2024-06-07T04:47:00+00:00</published><updated>2024-06-07T04:47:00+00:00</updated><id>/2024/06/07/the-inconceivable-types-of-rust-how-to-make-self-borrows-safe</id><content type="html" xml:base="/2024/06/07/the-inconceivable-types-of-rust-how-to-make-self-borrows-safe.html"><![CDATA[<p>One of the first things any Rust programmer learns is that you can’t pass an object and a reference to that object around at the same time. It’s impossible to do, even indirectly. This limitation has been the subject of countless questions on Stack Overflow and posts on Reddit and the Rust forums and anywhere else where Rust programmers might ask for help. It’s so well-known that most people treat it like an axiom, not just a limitation of Rust <em>as it currently exists</em>, but an inherent limitation of borrow checking <em>in general</em>.</p>

<p>However, that’s not the case. In fact, with the right perspective, the way to support it is obvious. In this post, I’ll walk through the steps and show how self-borrows and much more could be supported in a hypothetical alternate or future version of Rust.</p>

<h3 id="but-first-some-obligatory-disclaimers">But first, some obligatory disclaimers</h3>

<p>To be clear, when I say something can’t be done in Rust, what I mean is that it can’t be done <em>in a safe, zero-cost way</em>. As an army of internet commenters are no doubt rushing to observe, any limitation of a static type system can be bypassed by using unsafety or runtime checks instead (e.g. “lol, just wrap everything in <code class="language-plaintext highlighter-rouge">Arc&lt;Mutex&lt;T&gt;&gt;</code>” or “lol, just build your own memory management on top of <code class="language-plaintext highlighter-rouge">Vec</code> indices”). And the fact that a less safe or efficient workaround exists <em>is</em> of great interest to people who just need to solve a problem quickly. But from a language design perspective, the pertinent fact is that Rust’s type system has gaps which make certain common tasks impossible to do <em>in a way that lets Rust be Rust</em>, and not just a glorified C or Javascript.</p>

<p>Lastly, this post will discuss changes purely from a type checking perspective without regard to how hard they’d actually be to implement. In a major real-world language like Rust, <em>any</em> change, no matter how trivial, has a huge cost in terms of ecosystem, documentation, tooling, backwards compatibility, etc. But I’m a language design hobbyist, not a Rust compiler engineer, so language design is the part I’ll speak about.</p>

<p>So how do you type-check self borrows? The trick is actually to adopt an even more ambitious goal, <em>safe async functions</em>.</p>

<h2 id="a-brief-history-of-rust">A brief history of Rust</h2>

<p>Rust 1.0 shipped with no support whatsoever for non-movable types. The fact that any value of any type could be arbitrarily memcpy’d around and still work was a core assumption of the language.</p>

<p>However, it didn’t take long before people realized that non-movable types are actually very useful. In particular, async functions nearly always produce non-movable future types, so you can’t have async Rust without support in some fashion for non-movable types.</p>

<p>Sadly, it was too late to do things properly (i.e. a <code class="language-plaintext highlighter-rouge">Move</code> auto-trait), but they were able to at least hack in partial support via the <a href="https://doc.rust-lang.org/std/pin/struct.Pin.html"><code class="language-plaintext highlighter-rouge">Pin</code></a> type, added in Rust 1.33.0.</p>

<h3 id="but-not-for-thee">…but not for thee</h3>

<p>Now if you’re like me, you might have thought, “Pin is added, which means support for self-borrows. Great, now I can refactor and simplify all my code!” Unfortunately, that’s not what actually happened.</p>

<p><code class="language-plaintext highlighter-rouge">Pin</code> made it possible for Rust code to <em>work with</em> and <em>pass around</em> non-movable types, but there was still no way to actually <em>create</em> them. That is a bit of dark magic that the compiler jealously hoards for itself. Whenever you write an async function, the compiler will magically generate a secret non-movable type, and <code class="language-plaintext highlighter-rouge">Pin</code> makes it possible to work with these types, but there is still no way to actually create self-referential types yourself (again, in safe, zero-cost code).</p>

<p>However, <strong>what if it didn’t have to be this way?</strong> Personally, I think async functions (and closures) should be desugared into 100% safe Rust code that the user <em>could</em> have written themselves if they wanted to. Not because users would necessary actually want to do that very often, but because having a desugared version of every magic feature is useful didactically and for low-level libraries, and because it forces Rust to be <em>honest about its type system</em> instead of papering over the cracks with compiler magic.</p>

<p>Since async functions have self-borrows, supporting them conveniently also implies support for self-borrows more generally. Now the only question is how to actually support safe async functions.</p>

<p>The rest of this post is divided into two parts. In part 1, I will cover the changes needed from a high level type system perspective, while in part 2, I’ll cover the remaining low level details.</p>

<h1 id="part-1-the-value-level">Part 1: The value level</h1>

<p>In order to make async functions possible in (safe) Rust, we first have to figure out why they <em>aren’t</em> possible already. Most people would answer “async functions have self-borrows, and it is impossible to support self-borrows in the borrow checker”, but that is the wrong way to look at things. The <em>actual</em> answer is that <strong>it is impossible to name the types of local variables</strong>.</p>

<p>To see why this is, consider how you would go about desugaring an async function. Suppose we have a simple async function <code class="language-plaintext highlighter-rouge">foo</code> that adds some numbers and calls another async function like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">sub</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">Pin</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">Output</span><span class="o">=</span><span class="p">()</span><span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="nd">todo!</span><span class="p">()}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">foo</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">u32</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">12345</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">f</span> <span class="o">=</span> <span class="nf">sub</span><span class="p">();</span>
    <span class="n">f</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="k">let</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">f2</span> <span class="o">=</span> <span class="nf">sub</span><span class="p">();</span>
    <span class="n">f2</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="p">}</span>
</code></pre></div></div>

<p>How would we desugar <code class="language-plaintext highlighter-rouge">foo</code> by hand? We need to create a custom Future type <code class="language-plaintext highlighter-rouge">Foo</code> with a state machine representing the possible states of the original <code class="language-plaintext highlighter-rouge">foo</code> function. Specifically, we need a state machine with one state per <code class="language-plaintext highlighter-rouge">await</code> point in the function, plus a begin and end state. And the contents of each state are just the local variables that are live at that point in the function.</p>

<p>Therefore, our custom state machine type would look like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="n">Initial</span><span class="p">,</span>
    <span class="n">Await1</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="nb">Pin</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">Output</span><span class="o">=</span><span class="p">()</span><span class="o">&gt;&gt;&gt;</span><span class="p">},</span>
    <span class="n">Await2</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">f2</span><span class="p">:</span> <span class="nb">Pin</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">Output</span><span class="o">=</span><span class="p">()</span><span class="o">&gt;&gt;&gt;</span><span class="p">},</span>
    <span class="n">Final</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In order to create this type, we “just” have to list every local variable that is live at an await point, along with the types of all those local variables. Therefore, supporting async functions in safe Rust is just a matter of making it consistently possible to name the types of every variable. So why is this impossible to do right now? The first obstacle is <strong>unnameable types</strong>.</p>

<h2 id="unnameable-types">Unnameable types</h2>

<p><img src="/img/20240606_padme_rust.jpg" /></p>

<p>Rust made the interesting design decision to <em>require</em> explicit type annotations on every function boundary and every custom type, and yet also make it <em>impossible</em> to write explicit types in many cases. This was already a problem in Rust 1.0 with closures, but got much worse a few years later with the introduction of async Rust and impl Trait.</p>

<p>Basically, some types (closures, async functions, impl Trait) <em>exist</em> in Rust’s type system but do not have a <em>name</em> and hence are impossible to <em>talk about</em> in your code. You can still pass those values around and interact with them as long as you never have to explicitly name their type, but as soon as you hit a function boundary or want to store them inside a struct or enum, whoops, it’s time to add generics or pointlessly <code class="language-plaintext highlighter-rouge">Box</code> everything up.</p>

<p>Even in the example code above, this is already a problem. I had to go out of my way to make <code class="language-plaintext highlighter-rouge">sub</code> return a boxed <code class="language-plaintext highlighter-rouge">dyn Future</code> in order to have a nameable type for the sake of example, but any realistic code would instead be working with unnameable futures everywhere.</p>

<p>Fortunately, this is also a very easy problem to solve - <strong>just give every type a name</strong>. Efforts to do this already have been indefinitely stalled over concerns about stabilizing the order of generic type parameters, but that’s a trivial concern compared to the much more invasive changes we’ll get into later.</p>

<h3 id="named-lifetimes">Named lifetimes</h3>

<p>There’s actually another kind of unnameable type as well - function local lifetimes. Unlike closures and futures, these can never cross a function boundary without being replaced by generic parameters, so they don’t cause problems for <em>existing</em> code, but they’re still types that can’t be named, and if we’re going to support async functions in Rust, we need a way to name them.</p>

<p>Any syntax actually added to Rust would obviously have to get bikeshedded to death and assessed for education and tooling and so on, but as I’m just a person writing a blog post, I’m under no such constraints, so for the sake of example, I’ll propose the following syntax:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">v</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
<span class="n">life</span> <span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="p">;</span>

<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="n">v</span><span class="p">;</span>
<span class="c1">// do stuff with r</span>
<span class="n">end</span> <span class="nv">'a</span><span class="p">;</span>

<span class="k">let</span> <span class="n">r2</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="k">mut</span> <span class="n">v</span><span class="p">;</span>
<span class="c1">// do stuff with r2</span>
<span class="n">end</span> <span class="nv">'b</span><span class="p">;</span>
</code></pre></div></div>

<p>In this proposal, you first declare a <em>lifetime token</em> via <code class="language-plaintext highlighter-rouge">life 'a</code>. This token represents a lifetime that lasts as long as the token exists. Next, when borrowing a reference, you can optionally specify an explicit lifetime, e.g. <code class="language-plaintext highlighter-rouge">&amp;'a mut v</code>. Finally, you can <em>end</em> a lifetime via <code class="language-plaintext highlighter-rouge">end 'a</code>, which consumes the token.</p>

<p>This syntax is more verbose than the current syntax, but I don’t expect users to actually use named lifetime syntax that often. I see it like <code class="language-plaintext highlighter-rouge">drop</code>. You <em>can</em> write all your <code class="language-plaintext highlighter-rouge">drop</code>s explicitly if you want to, but most of the time people let the compiler insert them implicitly instead. Likewise under my proposal, people will usually still use the current syntax and let the compiler implicitly insert anonymous lifetimes, but they can also write named lifetimes explicitly if they want to.</p>

<h3 id="static-checking">Static checking</h3>

<p>Under my named lifetimes proposal, <em>all checking is still done purely at compile time</em>, just like the existing borrow checker. The lifetime tokens only exist at compile time and there is no runtime impact.</p>

<p>In order to do all type checking statically, we have to enforce certain invariants. Specifically, <em>types can only refer to lifetimes in the current scope</em>. Any type that escapes outside of the scope of the lifetime token it refers to becomes invalid. Likewise, consuming a lifetime token invalidates all types that refer to that lifetime.</p>

<h2 id="inconceivable-types">Inconceivable types</h2>

<p>As it turns out, unnameable types aren’t the only barrier to naming the types of variables in Rust. Unnameable types are types that still exist in Rust’s formal type system, but don’t have names. However, Rust’s formal type system is only a subset of its de-facto type system because in addition to Rust’s official type checker, the compiler also incorporates <em>shadow type checkers</em> which do type-checking like things but are not formally part of the type checker.</p>

<p>There are types that are part of Rust’s de-facto type system which don’t even exist in Rust’s formal type system in the first place, let alone have names. I call these types <strong>inconceivable types</strong> because from the perspective of a Rust compiler engineer, they aren’t types and don’t even exist in the first place.</p>

<p>Therefore, in order to support async functions, we’ll also need to add all the missing inconceivable types into Rust’s formal type system.</p>

<h3 id="partial-moves">Partial moves</h3>

<p>What are these shadow type checkers? Consider the following Rust code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">mem</span><span class="p">::</span><span class="nb">drop</span><span class="p">;</span>

<span class="nd">#[derive(Default)]</span>
<span class="k">struct</span> <span class="n">MyStrings</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">foo</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">ms</span> <span class="o">=</span> <span class="nn">MyStrings</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    
    <span class="nf">drop</span><span class="p">(</span><span class="n">ms</span><span class="py">.x</span><span class="p">);</span>
    <span class="nf">drop</span><span class="p">(</span><span class="n">ms</span><span class="py">.y</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>At first glance, this code shouldn’t compile. After all, <code class="language-plaintext highlighter-rouge">ms</code> is used twice, right? <code class="language-plaintext highlighter-rouge">ms</code> should already be moved when it is referenced the first time in <code class="language-plaintext highlighter-rouge">ms.x</code>, which would make <code class="language-plaintext highlighter-rouge">ms.y</code> a compile error. However, the Rust compiler actually allows this!</p>

<p>The reason is because Rust has a secret shadow type checker which allows you to partially move and partially borrow values as long as they stay within a function. The fact that this is limited to within a function makes it harder to spot since it never forces the user to write the function-boundary-mandatory type annotations that would be impossible since these types don’t actually exist in Rust’s formal type system.</p>

<p>However, they are still a problem for async functions because we need to be able to specify the types of <em>local</em> variables as well. Consider the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">foo</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">ms</span> <span class="o">=</span> <span class="nn">MyStrings</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    
    <span class="nf">drop</span><span class="p">(</span><span class="n">ms</span><span class="py">.x</span><span class="p">);</span>
    <span class="c1">// What is ms's type here?!?!</span>
    <span class="nf">sub</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    <span class="nf">drop</span><span class="p">(</span><span class="n">ms</span><span class="py">.y</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>What is the type of <code class="language-plaintext highlighter-rouge">ms</code> at the await point? The formal type system would answer “oh, the type is <code class="language-plaintext highlighter-rouge">MyStrings</code>, that doesn’t change.” However, its <em>de-facto</em> type clearly does change. After all, you can’t access the <code class="language-plaintext highlighter-rouge">x</code> field on it like you could for any true value of type <code class="language-plaintext highlighter-rouge">MyStrings</code>. The true type is now something else entirely, an inconceivable type.</p>

<p>Therefore, the next step is to add the inconceivable types for partial borrows and partial moves to Rust’s formal type system, so that they can be referenced in type annotations. For this, I propose the syntax <code class="language-plaintext highlighter-rouge">Foo{bar, baz}</code>, to list the fields explicitly. E.g. <code class="language-plaintext highlighter-rouge">MyStrings{y}</code> means a value with the <em>memory layout</em> of <code class="language-plaintext highlighter-rouge">MyStrings</code>, but where only field <code class="language-plaintext highlighter-rouge">y</code> remains (with the <code class="language-plaintext highlighter-rouge">x</code> part being arbitrary uninitialized data). This can be extended to partial borrows as well, e.g. <code class="language-plaintext highlighter-rouge">&amp;mut Foo{bar, baz}</code>.</p>

<p>However, that’s not all. There’s still one more shadow type checker to deal with, and it’s a really big one. As it turns out, the borrow checker is <em>also</em> a shadow type checker.</p>

<h3 id="borrowed-types">Borrowed types</h3>

<p>Consider the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">foo</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="s">"Hello, world"</span><span class="nf">.to_string</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">;</span>
    <span class="c1">// What is the type of s here???</span>
    <span class="nf">sub</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="n">r</span><span class="nf">.push</span><span class="p">(</span><span class="sc">'!'</span><span class="p">);</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{}"</span><span class="p">,</span> <span class="n">s</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>What is the type of <code class="language-plaintext highlighter-rouge">s</code> at the await point? Again, the formal type system says “it’s <code class="language-plaintext highlighter-rouge">String</code> the whole time, that doesn’t change”, but again that’s a lie. The de-facto type of <code class="language-plaintext highlighter-rouge">s</code> can’t be <code class="language-plaintext highlighter-rouge">String</code>, because it doesn’t support the operations of a value of type <code class="language-plaintext highlighter-rouge">String</code>. In fact, it doesn’t support <em>any</em> operations, because any attempt to access <code class="language-plaintext highlighter-rouge">s</code> at that point will result in a compile error.</p>

<p>Therefore, the type of <code class="language-plaintext highlighter-rouge">s</code> must be temporarily changing to some other, inconceivable type. Specifically, the types of <em>borrowed values</em> are inconceivable types.</p>

<p>For this, I propose the syntax <code class="language-plaintext highlighter-rouge">!'a mut String</code>, but to understand why, we’ll first have to go into a brief digression on the theoretical basis for borrow checking.</p>

<h2 id="why-borrow-checking">Why borrow checking?</h2>

<p>There’s a common misconception, even in the Rust community, that borrow checking is just a memory management strategy, just a quirk of languages in the C++ niche and not something you need in a language with garbage collection. In fact however, borrow checking is the inevitable consequence of <a href="/2023/03/05/fixing-the-next-10-000-aliasing-bugs.html">protecting against aliasing bugs</a>, regardless of which memory management strategy a language uses.</p>

<h3 id="affine-types">Affine types</h3>

<p>In a traditional language, if you have a value of type <code class="language-plaintext highlighter-rouge">T</code>, you can make any number of copies of that value that all still have type T, just by reading it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>let foo: T = ...;
let bar: T = foo;
// foo and bar have type T
</code></pre></div></div>

<p>However, this doesn’t work if you want to reason about aliasing. In particular, if you have a type for <em>exclusively referenced</em> objects (written <code class="language-plaintext highlighter-rouge">xcl</code> in this section for the sake of example), it is not sound to allow copying like this, because then you’ll have two references to the same object, both of which think they are the only one.</p>

<p>Therefore, exclusive references must be <em>affine types</em>, meaning that they can only be used once.</p>

<h3 id="splitting">Splitting</h3>

<p>However, being able to use each value only once makes it impossible to write all but the most trivial programs. In order to do anything useful, you need to be able to <em>split</em> a type so you can use values more than once.</p>

<p>A type can be thought of as a set of permissions to access the associated value, and thus it is safe to copy a value as long as the <em>permissions</em> aren’t copied. Instead, the child values need to have a <em>disjoint</em> set of permissions.</p>

<p>For example, suppose we have an exclusive reference to an object with fields of type <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">U</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>let a = {foo: _, bar: _};
// a has the type xcl {foo: T, bar: U};

let b = a as {foo: T};
// b has type xcl {foo: T}
// a has type xcl {bar: U}
</code></pre></div></div>

<p>We can create a second reference to the object by <em>splitting</em> the permissions - after the split <code class="language-plaintext highlighter-rouge">a</code> <em>only</em> has the ability to read the field <code class="language-plaintext highlighter-rouge">bar</code> while <code class="language-plaintext highlighter-rouge">b</code> <em>only</em> has the ability to read field foo. Since they can only read disjoint parts of the object, it is still sound to have two exclusive references to the same object. (Note: this is pseudocode in a high level language for the sake of example - Rust doesn’t actually work this way due to other, low level considerations).</p>

<p>For traditional types (or <code class="language-plaintext highlighter-rouge">Copy</code> types in Rust parlance), you have the splitting rule <code class="language-plaintext highlighter-rouge">T =&gt; T + T</code>. In other words, given a value of <code class="language-plaintext highlighter-rouge">T</code>, you can split it into two values that both still have type <code class="language-plaintext highlighter-rouge">T</code>. For affine types, that splitting rule doesn’t exist, but there are still other splitting rules that are sound. For example, you can split by fields as we just saw: <code class="language-plaintext highlighter-rouge">xcl {foo: T, bar: U} =&gt; (xcl {foo: T}) + (xcl {bar: U})</code>.</p>

<h3 id="temporal-splitting">Temporal splitting</h3>

<p>The previous splitting rule is <em>spacial</em> - you can split access over disjoint fields of an object. However, spatial splitting alone doesn’t get you very far. In order to write practical code, you need another splitting rule. Besides splitting access by <em>space</em>, you can also split access by <em>time</em>.</p>

<p>Specifically, you can create a second copy of the reference as long as one copy can only be accessed <em>before</em> a given time, and the other copy can only be accessed <em>after</em> a given time. Since the access is split into disjoint periods of time, this is still sound.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">life</span> <span class="nv">'a</span><span class="p">;</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="mi">42</span><span class="p">];</span>
<span class="c1">// v has exclusive access to the object</span>

<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="n">v</span><span class="p">;</span>
<span class="c1">// r has exclusive access to the object before time a</span>
<span class="c1">// v has exclusive access to the object *after* time a</span>
</code></pre></div></div>

<p>This is the essence of borrow checking. It’s not some arcane, low level memory management strategy, but just a natural, essential method of statically reasoning about <em>aliasing</em> in your code.</p>

<h3 id="negative-lifetime-bounds">Negative lifetime bounds</h3>

<p>Borrow checking involves two kinds of types - references that are valid <em>before</em> a given time, and references that are valid <em>after</em> a given time. The first kind is already part of Rust’s formal type system, the ordinary references you know and love. A value of type <code class="language-plaintext highlighter-rouge">&amp;'a mut T</code> has exclusive access <em>before</em> time <code class="language-plaintext highlighter-rouge">a</code>, and no access after time <code class="language-plaintext highlighter-rouge">a</code>.</p>

<p>However, Rust’s formal type system has no notion of the second kind of type, of references that are valid <em>after</em> a given time. This is the inconceivable type we need to add.</p>

<p>Since these are the opposite of normal lifetimes, it makes sense to use the “not” symbol <code class="language-plaintext highlighter-rouge">!</code>, e.g. <code class="language-plaintext highlighter-rouge">!'a</code>, which I call a <em>negative lifetime bound</em>. A bound of <code class="language-plaintext highlighter-rouge">'a</code> means the type is only valid <em>until</em> <code class="language-plaintext highlighter-rouge">a</code>, while a bound of <code class="language-plaintext highlighter-rouge">!'a</code> means it is only valid <em>after</em> <code class="language-plaintext highlighter-rouge">a</code> instead.</p>

<h2 id="bound-lifetimes">Bound lifetimes</h2>

<p>We can now express the types of all local variables, even the types that don’t currently exist in Rust, but there’s still one more problem. Recall that the example of named lifetimes looked like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">v</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
<span class="n">life</span> <span class="nv">'a</span><span class="p">,</span> <span class="nv">'b</span><span class="p">;</span>

<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="n">v</span><span class="p">;</span>
<span class="c1">// do stuff with r</span>
<span class="n">end</span> <span class="nv">'a</span><span class="p">;</span>

<span class="k">let</span> <span class="n">r2</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="k">mut</span> <span class="n">v</span><span class="p">;</span>
<span class="c1">// do stuff with r2</span>
<span class="n">end</span> <span class="nv">'b</span><span class="p">;</span>
</code></pre></div></div>

<p>The problem is that the lifetime tokens (<code class="language-plaintext highlighter-rouge">'a</code> and <code class="language-plaintext highlighter-rouge">'b</code>) are <em>themselves</em> part of the function’s local state, and thus <em>also</em> have to be stored inside the state machine enum. Therefore, we need a way to store lifetime tokens inside of objects.</p>

<p>My proposed syntax introduces a new expression, <code class="language-plaintext highlighter-rouge">bind 'a in x</code>, which <em>moves</em> the lifetime token ‘a into the value x. And likewise, we have new destructuring pattern syntax, <code class="language-plaintext highlighter-rouge">let bind 'a in x = y;</code>, to do the reverse. Lastly, this also adds a new type, <code class="language-plaintext highlighter-rouge">bind 'a in T</code>, representing a type <code class="language-plaintext highlighter-rouge">T</code> with bound lifetime token <code class="language-plaintext highlighter-rouge">'a</code>.</p>

<p>Note that lifetime tokens and lifetimes only exist at compile time and have no runtime representation. <code class="language-plaintext highlighter-rouge">bind 'a in v</code> and the like are noops that exist purely for the sake of static type checking, and <code class="language-plaintext highlighter-rouge">bind 'a in T</code> has the same runtime representation as <code class="language-plaintext highlighter-rouge">T</code>.</p>

<h3 id="moving-lifetime-tokens">Moving lifetime tokens</h3>

<p>With the <code class="language-plaintext highlighter-rouge">end 'a</code> syntax, the lifetime token <code class="language-plaintext highlighter-rouge">'a</code> is consumed in place, which means that we know precisely when it ends. All types in scope with a positive (<code class="language-plaintext highlighter-rouge">'a</code>) bound become invalid, while all types in scope with a negative bound (<code class="language-plaintext highlighter-rouge">!'a</code>) have the negative bound removed (returning it to the original, unborrowed type).</p>

<p>However, when we <em>move</em> a lifetime token into a value, types referring to that lifetime which were in the old scope but not the new scope have to be treated differently. In this case, the lifetime token is no longer in scope <em>without</em> being ended, and so we have to pessimistically invalidate both positive <em>and</em> negative bounds. Types that reference the lifetime which are still within the new scope (i.e. the value that the lifetime token was bound to) are unaffected.</p>

<h2 id="examples">Examples</h2>

<p>This can be pretty confusing, so let’s look at some examples to show how the new lifetime system works.</p>

<p>First, suppose you try to return a reference to a local variable:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">life</span> <span class="nv">'a</span><span class="p">;</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="s">"Hello"</span><span class="nf">.to_string</span><span class="p">());</span>
<span class="c1">// s has type Box&lt;String&gt;</span>
<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="o">*</span><span class="n">s</span><span class="p">;</span>
<span class="c1">// r has type &amp;'a mut String</span>
<span class="c1">// s has type Box&lt;!'a mut String&gt;</span>
<span class="k">return</span> <span class="n">r</span><span class="p">;</span> <span class="c1">// error: r is invalid</span>
</code></pre></div></div>

<p>This naturally results in a compile error because <code class="language-plaintext highlighter-rouge">r</code> has the type <code class="language-plaintext highlighter-rouge">&amp;'a mut String</code>, but the lifetime token <code class="language-plaintext highlighter-rouge">'a</code> is <em>local</em> to the function. Therefore, when r is returned, it is no longer within the scope where <code class="language-plaintext highlighter-rouge">'a</code> exists and hence is invalid.</p>

<p>Now suppose we try binding <code class="language-plaintext highlighter-rouge">'a</code> to <code class="language-plaintext highlighter-rouge">r</code> before returning it:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">life</span> <span class="nv">'a</span><span class="p">;</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="s">"Hello"</span><span class="nf">.to_string</span><span class="p">());</span>
<span class="c1">// s has type Box&lt;String&gt;</span>
<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="o">*</span><span class="n">s</span><span class="p">;</span>
<span class="c1">// r has type &amp;'a mut String</span>
<span class="c1">// s has type Box&lt;!'a mut String&gt;</span>
<span class="k">let</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="n">r</span><span class="p">;</span>
<span class="c1">// ret has type (bind 'a in &amp;'a mut String)</span>
<span class="c1">// s has type invalid</span>
<span class="k">return</span> <span class="n">ret</span><span class="p">;</span> <span class="c1">// error: s is invalid</span>
</code></pre></div></div>

<p>This time, <code class="language-plaintext highlighter-rouge">ret</code> contains its own lifetime token, and so is not invalidated when returning. However, moving the lifetime token <code class="language-plaintext highlighter-rouge">'a</code> into <code class="language-plaintext highlighter-rouge">ret</code> invalidates <code class="language-plaintext highlighter-rouge">s</code>. Returning causes <code class="language-plaintext highlighter-rouge">s</code> to be implicitly dropped, but it can’t be dropped because it is invalid, resulting in a compile error.</p>

<p>Finally, let’s try binding <code class="language-plaintext highlighter-rouge">'a</code> to a tuple of both <code class="language-plaintext highlighter-rouge">r</code> <em>and</em> <code class="language-plaintext highlighter-rouge">s</code> and returning that:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">life</span> <span class="nv">'a</span><span class="p">;</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="s">"Hello"</span><span class="nf">.to_string</span><span class="p">());</span>
<span class="c1">// s has type Box&lt;String&gt;</span>
<span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="o">*</span><span class="n">s</span><span class="p">;</span>
<span class="c1">// r has type &amp;'a mut String</span>
<span class="c1">// s has type Box&lt;!'a mut String&gt;</span>
<span class="k">let</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">r</span><span class="p">);</span>
<span class="c1">// ret has type (bind 'a in (Box&lt;!'a mut String&gt;, &amp;'a mut String))</span>
<span class="k">return</span> <span class="n">ret</span><span class="p">;</span> <span class="c1">// ok</span>
</code></pre></div></div>

<p>This time, everything works. We’ve just returned a string <em>along with a borrowed reference to that string</em> in a 100% safe and zero-cost manner!</p>

<h3 id="destructuring">Destructuring</h3>

<p>Now that we’ve successfully returned a self-borrowed object, let’s look at how you would <em>use</em> an object with self-borrows.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="p">(</span><span class="nb">Box</span><span class="o">&lt;!</span><span class="nv">'a</span> <span class="k">mut</span> <span class="nb">String</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="nb">String</span><span class="p">))</span> <span class="p">{</span>
    <span class="c1">// v has type (bind 'a in (Box&lt;!'a mut String&gt;, &amp;'a mut String))</span>

    <span class="k">let</span> <span class="n">bind</span> <span class="nv">'b</span> <span class="k">in</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">=</span> <span class="n">v</span><span class="p">;</span>
    <span class="c1">// 'b is a lifetime token</span>
    <span class="c1">// s has type Box&lt;!'b mut String&gt;</span>
    <span class="c1">// r has type &amp;'b mut String</span>

    <span class="n">r</span><span class="nf">.push_str</span><span class="p">(</span><span class="s">" world!"</span><span class="p">);</span>
    <span class="n">end</span> <span class="nv">'b</span><span class="p">;</span>
    <span class="c1">// s has type Box&lt;String&gt;</span>
    <span class="c1">// r is invalid</span>

    <span class="nd">println!</span><span class="p">(</span><span class="s">"{}"</span><span class="p">,</span> <span class="n">s</span><span class="p">);</span>
<span class="p">}</span>

</code></pre></div></div>

<h2 id="external-lifetimes">External lifetimes</h2>

<p>So far, we’ve only looked at <em>owned</em> lifetime tokens. However, in some cases, you instead have a <em>reference</em> to an unknown lifetime token that exists elsewhere. There are two cases where this can happen:</p>

<p><strong>Generic lifetime parameters</strong></p>

<p>When a generic function is called, the generic lifetime parameters represent <em>some</em> lifetime which is owned by some caller of the function. These lifetimes are guaranteed to last at least as long as the function call, but could last longer.</p>

<p><strong>Destructured <em>references</em> to bound lifetimes</strong></p>

<p>In the previous example, we destructured an <em>owned value</em> that contained a lifetime token, resulting in the token being moved into the current scope.</p>

<p>If you destructure a <em>reference</em> to a value with a lifetime token, you instead get a reference to a lifetime token, rather than the token itself. These lifetimes are guaranteed to last at least as long as the destructured reference, but could last longer.</p>

<p>When you have a reference to an external lifetime, you can’t <em>end</em> or <em>move</em> the lifetime, since you don’t own the corresponding token. However, as long as the lifetime reference exists, you still can interact with types that refer to that lifetime.</p>

<p>Here’s an example of mutating a value with a bound lifetime via a mutable reference:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">foo</span><span class="o">&lt;</span><span class="nv">'call</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'call</span> <span class="k">mut</span> <span class="p">(</span><span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="p">(</span><span class="o">!</span><span class="nv">'a</span> <span class="nb">String</span><span class="p">,</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="p">)))</span> <span class="p">{</span>
    <span class="c1">// 'call is an external lifetime</span>
    <span class="c1">// v has type &amp;'call mut (bind 'a in (!'a String, &amp;'a str))</span>

    <span class="k">let</span> <span class="n">bind</span> <span class="nv">'b</span> <span class="k">in</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">=</span> <span class="n">v</span><span class="p">;</span>
    <span class="c1">// 'b is an external lifetime</span>
    <span class="c1">// s has type &amp;'call mut (!'b String)</span>
    <span class="c1">// r has type &amp;'call mut (&amp;'b str)</span>

    <span class="k">let</span> <span class="p">(</span><span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span> <span class="o">=</span> <span class="n">r</span><span class="nf">.split_at</span><span class="p">(</span><span class="mi">32</span><span class="p">);</span>
    <span class="c1">// r1 and r2 have type (&amp;'b str)</span>

    <span class="c1">// can assign back to r since they both have type &amp;'b str</span>
    <span class="o">*</span><span class="n">r</span> <span class="o">=</span> <span class="n">r2</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Lastly, we also need to add a type to represent bound <em>lifetime references</em> in a type. However, the recursion stops there because a reference to a reference to a lifetime is equivalent to just a reference to a lifetime, since they don’t actually have any state or runtime representation and can’t be mutated.</p>

<h1 id="part-2-the-bytes-level">Part 2: The bytes level</h1>

<p>If we were writing a high-level language, we’d already be done, but for Rust, we still have the low-level details to worry about.</p>

<p>There are two ways to consider a type system. The first is <em>what</em> your code does, in an abstract machine, with no concerns about how it is actually implemented. I call this “the value level”.</p>

<p>The second level is <em>how</em> your code does it, in terms of low level implementation details like how values are stored in memory, which I call “the bytes level”. In a high level language, this might not even be exposed to users, but as Rust is a systems language, it gives programmers control over low level details like this.</p>

<p>To keep things simple, Rust has a single type system which implicitly encodes both levels in a single type. Unfortunately, this means that the desired combination is sometimes simply not represented in Rust’s type system.</p>

<p>In particular, Rust conflates ownership of <em>values</em> with ownership of <em>the memory where those values are stored</em>. This isn’t just a problem for a <em>new</em> feature like async functions. It causes problems even in ordinary real-world Rust coding. In particular, it means that <code class="language-plaintext highlighter-rouge">Drop</code> has the wrong type signature because the correct type signature simply doesn’t exist in Rust.</p>

<h2 id="drop">Drop</h2>

<p>When I say “<code class="language-plaintext highlighter-rouge">Drop</code> has the wrong type signature”, some people might be thinking, “oh, you mean it should have wrapped <code class="language-plaintext highlighter-rouge">self</code> in <code class="language-plaintext highlighter-rouge">Pin</code>, right?”. But that’s just a minor inconvenience to people who are writing unsafe code anyway, and <code class="language-plaintext highlighter-rouge">Pin</code> itself only dates back to Rust 1.33.0. The problem I’m talking about is much worse. <strong><code class="language-plaintext highlighter-rouge">Drop</code> was broken, even in Rust 1.0</strong>.</p>

<p>For example, last year, I had a struct containing a Tokio oneshot channel, and I wanted to send on that channel when the container was dropped. No problem, I figured, this is exactly the kind of thing Rust is good at. Should be easy, right?</p>

<p>…right??</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="n">channel</span><span class="p">:</span> <span class="nn">tokio</span><span class="p">::</span><span class="nn">sync</span><span class="p">::</span><span class="nn">oneshot</span><span class="p">::</span><span class="n">Sender</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>
<span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// error[E0507]: cannot move out of `self.channel` which is behind a mutable reference</span>
        <span class="k">self</span><span class="py">.channel</span><span class="nf">.send</span><span class="p">(());</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>As it turns out, this seemingly simple task is <em>impossible</em> to do in Rust. (And yes, as always, you can throw away static checking and just use <code class="language-plaintext highlighter-rouge">unsafe</code> or wrap your type in an unnecessary <code class="language-plaintext highlighter-rouge">Option</code> or whatever. I’m talking about <em>safe</em> <em>zero-cost</em> Rust here.)</p>

<p>The reason why this seemingly simple code pattern is impossible is right there in the error message. <code class="language-plaintext highlighter-rouge">Drop</code> takes <code class="language-plaintext highlighter-rouge">self</code> <em>by mutable reference</em>. In Rust, mutable references have the <em>invariant</em> that the type is unchanged. You can’t move fields out of a mutable reference (unless you replace them with another value of the same type).</p>

<p>The whole point of a destructor is to destruct your type. The value is disassembled and the type goes away. You start with <code class="language-plaintext highlighter-rouge">T</code> and end with <em>nothing</em>. However, <code class="language-plaintext highlighter-rouge">Drop</code> takes <code class="language-plaintext highlighter-rouge">&amp;mut T</code> instead, which has the postcondition that everything is unchanged and your <code class="language-plaintext highlighter-rouge">T</code> is still sitting there, good as always. Somehow, Rust ended up with a destructor api <em>that can’t actually destruct anything</em>.</p>

<p>So how did Rust make such an obvious mistake? The problem is that the Rust designers painted themselves into a corner in a misguided attempt to minimize the number of types in the formal type system.</p>

<h3 id="owned-references">Owned references</h3>

<p>Currently, Rust has three kinds of types: <code class="language-plaintext highlighter-rouge">T</code>, <code class="language-plaintext highlighter-rouge">&amp;mut T</code>, and <code class="language-plaintext highlighter-rouge">&amp;T</code>. If you plot their ownership and representation, you get this:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Owned?</th>
      <th>Representation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>T</td>
      <td>yes</td>
      <td>inline</td>
    </tr>
    <tr>
      <td>&amp;mut T</td>
      <td>no</td>
      <td>pointer</td>
    </tr>
    <tr>
      <td>&amp;T</td>
      <td>no</td>
      <td>pointer</td>
    </tr>
  </tbody>
</table>

<p>Notice something missing? There is no possible type with “yes, pointer” (or “no, inline” for that matter, but that doesn’t matter much). Rust conflates <em>ownership</em> with <em>representation</em>. (More specifically, there is no way to own a <em>value</em> without owning the underlying memory - <code class="language-plaintext highlighter-rouge">Box&lt;T&gt;</code> is technically an owned pointer, but the pointer can only point to its own, owned memory, not memory that is managed elsewhere.)</p>

<p>In Rust, there is no way to transfer ownership of a value without <em>moving</em> the value. This was a major problem when Rust added async and decided that it needed to deal with non-movable types after all. Since the assumption of movability is built into the language in such a core way, there was no way to add non-movable types other than just saying “ok, everything related to them is unsafe, but here’s <code class="language-plaintext highlighter-rouge">Pin</code> so you can at least partially hide the unsafety from your users, have fun”.</p>

<p><code class="language-plaintext highlighter-rouge">Drop</code> can’t take <code class="language-plaintext highlighter-rouge">self</code> as a mutable reference because mutable references can’t be destructed, as discussed above. But it <em>also</em> can’t take <code class="language-plaintext highlighter-rouge">self</code> by <em>value</em>, because that makes it impossible to drop non-movable types. (There are also minor considerations around recursion, presumably the reason <code class="language-plaintext highlighter-rouge">Drop</code> didn’t take values even <em>before</em> Rust added non-movable types.)</p>

<p>The solution to this dilemma is that the <em>correct</em> type for <code class="language-plaintext highlighter-rouge">Drop</code> to take is a type that currently doesn’t exist - an <em>owned reference</em>, which I’ll write <code class="language-plaintext highlighter-rouge">&amp;own T</code>.</p>

<p><code class="language-plaintext highlighter-rouge">&amp;own T</code> is similar to <code class="language-plaintext highlighter-rouge">&amp;mut T</code>, except that it <em>owns</em> the referenced value. This means that it has no post-conditions like <code class="language-plaintext highlighter-rouge">&amp;mut T</code> does, and you can freely move fields out of the reference, and it will implicitly drop anything remaining when it goes out of scope. However, unlike <code class="language-plaintext highlighter-rouge">Box&lt;T&gt;</code>, <code class="language-plaintext highlighter-rouge">&amp;own T</code> does not own the <em>memory</em>, meaning you can take an <code class="language-plaintext highlighter-rouge">&amp;own T</code> reference to values on the stack when you need to drop them, and even recursively take <code class="language-plaintext highlighter-rouge">&amp;own T</code> references to fields.</p>

<h3 id="owned-reference-example">Owned reference example</h3>

<p>So what would a <em>correct</em> version of <code class="language-plaintext highlighter-rouge">Drop</code> look like? Let’s look at an example.</p>

<p>First, let’s start with a simple struct with some fields and methods:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">MyStrings</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span>
<span class="p">}</span>
<span class="k">impl</span> <span class="n">MyStrings</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">some_method</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"{} {}"</span><span class="p">,</span> <span class="k">self</span><span class="py">.x</span><span class="p">,</span> <span class="k">self</span><span class="py">.y</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We can implement <code class="language-plaintext highlighter-rouge">Drop</code> like this. <code class="language-plaintext highlighter-rouge">self</code> starts out as an owned reference to the full type, meaning we can call methods on it like normal. Once we move fields out of it, the type of <code class="language-plaintext highlighter-rouge">self</code> changes to the corresponding partial type (recall that Rust already supports partially moved types as an inconceivable type).</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">MyStrings</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="n">own</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// self has type &amp;own MyStrings</span>
     
        <span class="c1">// we can call methods within drop()</span>
        <span class="k">self</span><span class="nf">.some_method</span><span class="p">();</span>
     
        <span class="c1">// now let's move a field</span>
        <span class="k">let</span> <span class="n">_</span> <span class="o">=</span> <span class="k">self</span><span class="py">.x</span><span class="p">;</span>
        <span class="c1">// self now has type &amp;own MyStrings{y}</span>
     
        <span class="c1">// we're too lazy to drop the other field, but it will be dropped implicitly</span>
        <span class="c1">// drop(self.y)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>When an owned reference goes out of scope, all remaining fields are dropped implicitly, not just inside a <code class="language-plaintext highlighter-rouge">drop</code> method, but anywhere an <code class="language-plaintext highlighter-rouge">&amp;own T</code> exists. This is important a) for avoiding leaks while unwinding when an exception is thrown and b) because people will often not explicitly drop everything in a <code class="language-plaintext highlighter-rouge">drop</code> impl.</p>

<h3 id="initialization">Initialization</h3>

<p><code class="language-plaintext highlighter-rouge">Drop</code> isn’t the only place where non-movable types cause a problem. Rust’s entire design is centered around the assumption that you can move anything. You move values to transfer ownership, you move values to change types, you move values to initialize objects, etc. Therefore, making Rust usable for non-movable types requires more changes.</p>

<p>Fortunately, we <em>already</em> have to support partially moved types <em>anyway</em>, and that also conveniently covers the initialization case as well as the destruction case. Initialization is basically the same process as dropping, just in reverse:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">new</span> <span class="o">=</span> <span class="n">MyStrings</span><span class="p">{};</span>
<span class="c1">// new has type MyStrings{}, a partially moved value</span>
<span class="c1">// this has the *memory layout* of MyStrings, but with no fields initialized</span>

<span class="n">new</span><span class="py">.x</span> <span class="o">=</span> <span class="s">"Hello"</span><span class="nf">.to_string</span><span class="p">();</span>
<span class="c1">// new has type MyStrings{x}</span>

<span class="n">new</span><span class="py">.y</span> <span class="o">=</span> <span class="s">"World"</span><span class="nf">.to_string</span><span class="p">();</span>
<span class="c1">// new has type MyStrings{x,y}, which is the same as a fully initialized MyStrings</span>
</code></pre></div></div>

<h2 id="safe-transmute">Safe transmute</h2>

<p>However, there’s still one problem - in-place transmutes between different <em>base</em> types.</p>

<p>Recall that our future state machine enum looks something like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">MyFuture</span> <span class="p">{</span>
    <span class="nf">Initial</span><span class="p">(</span><span class="n">State0</span><span class="p">),</span>
    <span class="nf">Await1</span><span class="p">(</span><span class="n">State1</span><span class="p">),</span>
    <span class="nf">Await2</span><span class="p">(</span><span class="n">State2</span><span class="p">),</span>
    <span class="n">Final</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Our previous examples with drop and initialization changed the <em>actual</em> type (i.e. with different fields initialized or not), but the <em>base</em> type (which controls memory layout and method resolution) was the same. However, here, each enum variant has a <em>different</em> base type.</p>

<p>Currently in Rust, you always have to move values when converting between different base types. E.g. even just wrapping a value in a newtype (or unwrapping it) requires moving the value. However, the “move and reconstruct” paradigm won’t work here because our enum variants may contain <em>non-movable</em> types. Therefore, we need a way to convert between the different state types <em>in-place</em>.</p>

<p>Therefore, we need to add three things to Rust:</p>

<ul>
  <li>A way to specify that different types have the same memory layout</li>
  <li>A way to specify that certain fields have the same location within the type for different types</li>
  <li>The type system understands this and allows safe transmutes between them.</li>
  <li>Allow updating enums in a way that is aware of this.</li>
</ul>

<h3 id="example">Example</h3>

<p>Suppose we have an async function like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="k">mut</span> <span class="n">s</span><span class="p">:</span> <span class="nb">String</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">r</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">;</span>
    <span class="nf">sub</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="k">let</span> <span class="n">z</span> <span class="o">=</span> <span class="k">if</span> <span class="k">true</span> <span class="p">{</span><span class="n">r</span><span class="nf">.as_bytes</span><span class="p">()}</span> <span class="k">else</span> <span class="p">{</span><span class="s">"hello"</span><span class="nf">.as_bytes</span><span class="p">()};</span>
    <span class="nf">sub</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?}"</span><span class="p">,</span> <span class="n">z</span><span class="p">);</span>
    <span class="nf">sub</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{}"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The corresponding future enum states are as follows, where <code class="language-plaintext highlighter-rouge">SubFut</code> is the name of the anonymous future type returned by the <code class="language-plaintext highlighter-rouge">sub()</code> function.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">State0</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="nb">String</span><span class="p">}</span>
<span class="k">struct</span> <span class="n">State1</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="o">!</span><span class="nv">'a</span> <span class="k">mut</span> <span class="nb">String</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="k">mut</span> <span class="nb">String</span><span class="p">}</span>
<span class="k">struct</span> <span class="n">State2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="o">!</span><span class="nv">'a</span> <span class="k">mut</span> <span class="nb">String</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="p">[</span><span class="nb">u8</span><span class="p">]}</span>
<span class="k">struct</span> <span class="n">State3</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="nb">String</span><span class="p">}</span>

<span class="k">enum</span> <span class="n">MyFuture</span> <span class="p">{</span>
    <span class="nf">Initial</span><span class="p">(</span><span class="n">State0</span><span class="p">),</span>
    <span class="nf">Await1</span><span class="p">(</span><span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="n">State1</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">SubFut</span><span class="p">),</span>
    <span class="nf">Await2</span><span class="p">(</span><span class="n">bind</span> <span class="nv">'a</span> <span class="k">in</span> <span class="n">State2</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">SubFut</span><span class="p">),</span>
    <span class="nf">Await3</span><span class="p">(</span><span class="n">State3</span><span class="p">,</span> <span class="n">SubFut</span><span class="p">),</span>
    <span class="n">Final</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The problem comes when we need to implement the state transitions (within the <code class="language-plaintext highlighter-rouge">poll</code> method). Since <code class="language-plaintext highlighter-rouge">State1</code> and <code class="language-plaintext highlighter-rouge">State2</code> contain a non-movable field (<code class="language-plaintext highlighter-rouge">s</code>), they have to be converted <em>in-place</em>.</p>

<p>I’m not sure what the best way to do this is, but I’m assuming we have some sort of annotation which allows us to mark that these types all use the same memory layout, and that <code class="language-plaintext highlighter-rouge">s</code> is located in the same place in each type, allowing us to safely transmute between them.</p>

<p>The basic transition process for say, state 1 to state 2, is to start with an owned reference to <code class="language-plaintext highlighter-rouge">State1</code>. Then we remove the <code class="language-plaintext highlighter-rouge">r</code> field and use it to compute <code class="language-plaintext highlighter-rouge">z</code>, as per the code between the two await points. This leaves the pointer with type <code class="language-plaintext highlighter-rouge">State1{s}</code>. Then we can safely transmute this to <code class="language-plaintext highlighter-rouge">State2{s}</code>, since <code class="language-plaintext highlighter-rouge">s</code> is guaranteed to be in the same place in both types. Finally, we add the <code class="language-plaintext highlighter-rouge">z</code> field back, to get a full <code class="language-plaintext highlighter-rouge">State2</code>.</p>

<h2 id="safe-enum-updates">Safe enum updates</h2>

<p>There’s still the question of how the compiler knows that enums are being updated in a safe manner.</p>

<h3 id="mut-to-own">&amp;mut to &amp;own</h3>

<p>The first question is how to temporarily violate the type invariants during the update. <code class="language-plaintext highlighter-rouge">poll</code> takes a <em>mutable</em> reference to <code class="language-plaintext highlighter-rouge">self</code>, but in Rust, <code class="language-plaintext highlighter-rouge">&amp;mut T</code> is required to preserve the type invariants of <code class="language-plaintext highlighter-rouge">T</code> at all times (well, there are some minor exceptions, but those are built into the compiler, not something users have direct access to).</p>

<p>You’re not allowed to move out of a mutable reference, because if this were allowed, and an exception were thrown and then caught, someone could access the reference again even though the pointee is now invalid. Therefore, we need to somehow get an owned reference to the enum variant instead.</p>

<p>However, there’s one workaround. You can’t temporarily move out of a <code class="language-plaintext highlighter-rouge">&amp;mut T</code> because that would violate the invariant of <code class="language-plaintext highlighter-rouge">T</code>, but you <em>can</em> move out of a <code class="language-plaintext highlighter-rouge">&amp;mut Option&lt;T&gt;</code>. Basically, we’ve widened the type invariant of the pointee to now include an “invalid” state. That state will never be seen in normal operation (assuming we always put the value back when done with it), but would be seen if an exception is thrown while the value is removed, and then that exception is caught and the reference accessed again.</p>

<p>For normal code, wrapping everything in an <code class="language-plaintext highlighter-rouge">Option</code> means adding a runtime cost and runtime type checks, which is why I ruled it out in previous discussions (e.g. restricting the discussion to “safe, <em>zero-cost</em> Rust”). However, it turns out that the <code class="language-plaintext highlighter-rouge">Future</code> api <em>already</em> effectively forces everything to have an extra “invalid” state anyway, so there’s no additional cost to having one. This is the reason for the extra <code class="language-plaintext highlighter-rouge">Final</code> state in all the enums shown above.</p>

<p>Therefore, when updating the enum state during <code class="language-plaintext highlighter-rouge">poll</code>, we start by setting the tag to <code class="language-plaintext highlighter-rouge">Final</code>, which lets us get ownership over the current contents of the enum. Under normal operation, we would then set it back to a valid state, but if an exception is thrown in the middle and then caught and the future is re-polled, the future would just be in the <code class="language-plaintext highlighter-rouge">Final</code> state (which will panic when polled, like a future typically will when polled after completion).</p>

<h3 id="tracking-self-ness">Tracking self-ness</h3>

<p>The basic process is to start by setting the enum tag to <code class="language-plaintext highlighter-rouge">Final</code>, which gives an <em>owned</em> reference to the former contents of the enum variant, much like how you can take an owned value out of a <code class="language-plaintext highlighter-rouge">&amp;mut Option&lt;T&gt;</code> (except that taking an owned <em>reference</em> is not something that currently exists in Rust).</p>

<p>Then we perform various mutations through the owned reference, which changes its type from <code class="language-plaintext highlighter-rouge">&amp;own State1</code> to <code class="language-plaintext highlighter-rouge">&amp;own State2</code> or whatever. Finally, once the variant pointer is updated to the correct type, we can set the tag of the original enum to match, thus restoring the invariant.</p>

<p>However, the last part is trickier than it sounds. The problem is that even if we have a <code class="language-plaintext highlighter-rouge">&amp;mut MyFuture</code> (with the variant part currently borrowed) and a <code class="language-plaintext highlighter-rouge">&amp;own State2</code> or whatever, the compiler can’t know that it is safe to set the tag back to <code class="language-plaintext highlighter-rouge">Await2</code> <em>because it doesn’t know that the <code class="language-plaintext highlighter-rouge">&amp;own State2</code> actually points to the enum you’re trying to update</em>.</p>

<p>Therefore, we need to add a function-local analysis pass to the compiler to facilitate this. When you borrow the variant of an enum, the compiler will keep track of the relation between the two local variables as long as they stay in the function, and allow a safe update of the enum if the variant pointer has the corresponding type.</p>

<h3 id="another-inconceivable-type">Another inconceivable type?</h3>

<p>Now you might be wondering, isn’t that enum-alias analysis pass yet another shadow type checker? Does this mean we have <em>another</em> inconceivable type to add to the type system?</p>

<p>It <em>is</em> a shadow type checker, but fortunately we don’t have to add it to the type system. The reason is that in order to support safe async functions, we need to be able to name the type of any local variable <em>that is held across an await point</em>. Therefore, we only need to add inconceivable types to the type system <em>if it is possible for them to exist across an await</em>.</p>

<p>As shown earlier, partially moved types and borrowed types can both exist across an await, which is why we have to add them to the type system. However, if we’re adding a <em>new</em> shadow type checker, we can just arbitrarily declare that the analysis stops at awaits, which avoids the need to add any new types to the formal type system.</p>

<p>Fortunately, the only thing we actually <em>need</em> the enum-alias pass for is to support safe enum updates within the <code class="language-plaintext highlighter-rouge">Future::poll</code> method, and <code class="language-plaintext highlighter-rouge">poll</code> is a non-async method, which means it can never contain awaits anyway. Therefore, there’s no problem with restricting our new safe enum update feature to not span awaits.</p>

<h3 id="leak">Leak</h3>

<p>This sort of ad-hoc special analysis is certainly not elegant. In an ideal world, Rust would not have to have any inconceivable types at all, not even ones that don’t cross awaits. And it certainly would be <em>possible</em> to turn this into a general purpose feature that is a first-class part of the type system.</p>

<p>However, doing this the proper way would require the introduction of <em>non-forgettable types</em>. Some people have already been asking for non-forgettable types to be added to Rust anyway for unrelated reasons (via a “<code class="language-plaintext highlighter-rouge">Leak</code>” auto-trait), but the results would not be pretty.</p>

<p>This post is already very long, and non-forgettable types would add much <em>more</em> complexity than anything I’ve covered, since it violates a more central assumption of the language than even non-movable types do. Therefore, for the sake of keeping this proposal <em>merely</em> very long and minimizing the complexity of Rust as much as possible, I think it’s best to just punt on that subject and implement enum alias checking via special compiler magic rather than non-forgettable types.</p>

<p>The “special compiler magic” approach has the downside that it will be impossible to factor parts of the <code class="language-plaintext highlighter-rouge">poll</code> method out into separate helper functions, because the required types won’t exist in the type system and hence can’t be named in the function signature, but I think that’s a small price to pay for leaving this can of worms unopened.</p>

<h2 id="pin-and-move">Pin and Move</h2>

<p>With that out of the way, there’s one last topic to address, <code class="language-plaintext highlighter-rouge">Pin</code>.</p>

<p>You may have noticed a conspicuous lack of <code class="language-plaintext highlighter-rouge">Pin</code> in all my examples. That’s because <code class="language-plaintext highlighter-rouge">Pin</code> was just a hack added due to the inability to introduce a <code class="language-plaintext highlighter-rouge">Move</code> auto-trait in a fully backwards compatible manner. But since the changes I’m proposing require breaking strict backwards compatibility <em>anyway</em> (good luck fixing the type signature of <code class="language-plaintext highlighter-rouge">Drop</code> in a backwards compatible manner!), we might as well assume that <code class="language-plaintext highlighter-rouge">Pin</code> gets replaced by a <code class="language-plaintext highlighter-rouge">Move</code> auto-trait for moveable types while we’re at it.</p>

<p>However, we still need a way to replicate the functions <code class="language-plaintext highlighter-rouge">Pin</code> is currently serving, as it doesn’t work quite the same way that <code class="language-plaintext highlighter-rouge">Move</code> would.</p>

<h3 id="enum-refinements">Enum refinements</h3>

<p>In current Rust, when a <code class="language-plaintext highlighter-rouge">Future</code> is initially created, you can freely move it around. However, you have to pin it before you can <em>poll</em> it, and once polled, it becomes unmovable.</p>

<p>In a <code class="language-plaintext highlighter-rouge">Move</code> world, this is basically saying that the <code class="language-plaintext highlighter-rouge">Initial</code> state of every future enum state machine has to be <code class="language-plaintext highlighter-rouge">Move</code>, but the other states of the enum may be non-<code class="language-plaintext highlighter-rouge">Move</code>. Since <code class="language-plaintext highlighter-rouge">poll</code> takes the enum by <code class="language-plaintext highlighter-rouge">&amp;mut</code>, it can switch between the states and thus the future has to be assumed to be non-movable after polling.</p>

<p>However, Rust’s current design doesn’t support any way to reason like that. Rust’s current type system is designed around the assumption that every value has exactly one type and that type never changes, which means that there is no way to talk about properties that hold now but not in the future. If an enum type implements an auto-trait, that means that <em>every</em> variant of the enum satisfies that trait, not just one variant.</p>

<p>This isn’t just a problem for futures. It often comes up in current Rust with <code class="language-plaintext highlighter-rouge">Copy</code> too, as in “why can’t I copy <code class="language-plaintext highlighter-rouge">None</code>”? For example, the following code will not compile because the array initial value has to be <code class="language-plaintext highlighter-rouge">Copy</code>, but <code class="language-plaintext highlighter-rouge">Option&lt;SomeNotCopyType</code> is not <code class="language-plaintext highlighter-rouge">Copy</code> due to the unused <code class="language-plaintext highlighter-rouge">Some</code> variant.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">SomeNotCopyType</span><span class="p">;</span>

<span class="k">let</span> <span class="n">foo</span><span class="p">:</span> <span class="p">[</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">SomeNotCopyType</span><span class="o">&gt;</span><span class="p">;</span> <span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">None</span><span class="p">;</span> <span class="mi">8</span><span class="p">];</span>
</code></pre></div></div>

<p>Therefore, we need a way to distinguish between “every variant of the enum satisfies this property” and “the <em>current</em> variant of the enum satisfies this property”. The syntax <code class="language-plaintext highlighter-rouge">T: Future + Move</code> already means the former, so we need to come up with different syntax for the latter.</p>

<p>I’m not sure what the best syntax is, so I’ll just go with <code class="language-plaintext highlighter-rouge">T: Future if Move</code>. <code class="language-plaintext highlighter-rouge">T: Future if Move</code> means “<code class="language-plaintext highlighter-rouge">T</code> is (any) future, <em>and</em> the value is <em>currently</em> <code class="language-plaintext highlighter-rouge">Move</code>”, while <code class="language-plaintext highlighter-rouge">T: Future + Move</code> instead means “T is a future type where every variant is <code class="language-plaintext highlighter-rouge">Move</code>” (which would be <code class="language-plaintext highlighter-rouge">Unpin</code> in current Rust).</p>

<p>Since explicit trait implementations can only be done for the enum type as a whole, this sort of “per-variant trait impl” only makes sense for auto-traits and lifetimes. Therefore, the right side is restricted to auto-traits and lifetime bounds. <code class="language-plaintext highlighter-rouge">T: Future if (Move + 'static)</code> would be allowed, but <code class="language-plaintext highlighter-rouge">T: Future if Clone</code> would not.</p>

<p>Additionally, the “if” syntax can also be applied to <em>explicit</em> non-generic enum types. E.g <code class="language-plaintext highlighter-rouge">foo: MyEnum if Copy</code> means <code class="language-plaintext highlighter-rouge">foo</code> has type <code class="language-plaintext highlighter-rouge">MyEnum</code> <em>and</em> its current variant is one that is <code class="language-plaintext highlighter-rouge">Copy</code>.</p>

<h3 id="stable-deref-types">Stable deref types</h3>

<p>In general, every borrowed type will be non-moveable. However, container types such as <code class="language-plaintext highlighter-rouge">Box</code>, <code class="language-plaintext highlighter-rouge">Vec</code>, <code class="language-plaintext highlighter-rouge">String</code>, <code class="language-plaintext highlighter-rouge">Rc</code>, etc. could optionally tell the compiler that borrowing the <em>contents</em> of the container does not cause the container itself to become non-moveable. This is what makes it possible to return data along with a pointer to that data. The outer value will always be moved by Rust’s nature, but this is still safe as long as the <em>borrowed</em> data does not move.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Whew, we’re finally done! We’ve finally seen how to safely implement self-borrows and safe async functions in Hypothetical Future Rust.</p>

<p>To be honest, I think there’s approximately zero chance that this gets implemented in Rust, since the nature of a language with a large ecosystem means that you can’t just break backwards compatibility, and even seemingly trivial changes in Rust have been held up forever due to concerns around stabilization or documentation or whatever.</p>

<p>However, I hope that this post still helps people to think about the nature of the problem. In particular, it’s frustrating to see people say that self-borrows are an inherent impossibility with borrow checking when that limitation is really just a consequence of idiosyncratic choices made by Rust, and if not in current Rust, it certainly could have been supported in an alternate history Rust that made slightly different choices, and likely will be supported in future languages with borrow checking.</p>

<p>Anyway, if you have any comments or suggestions, please let me know by commenting on Reddit.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[One of the first things any Rust programmer learns is that you can’t pass an object and a reference to that object around at the same time. It’s impossible to do, even indirectly. This limitation has been the subject of countless questions on Stack Overflow and posts on Reddit and the Rust forums and anywhere else where Rust programmers might ask for help. It’s so well-known that most people treat it like an axiom, not just a limitation of Rust as it currently exists, but an inherent limitation of borrow checking in general.]]></summary></entry><entry><title type="html">What are GADTs and why do they make type inference sad?</title><link href="/2024/03/03/what-are-gadts-and-why-do-they-make-type-inference-sad.html" rel="alternate" type="text/html" title="What are GADTs and why do they make type inference sad?" /><published>2024-03-03T22:01:00+00:00</published><updated>2024-03-03T22:01:00+00:00</updated><id>/2024/03/03/what-are-gadts-and-why-do-they-make-type-inference-sad</id><content type="html" xml:base="/2024/03/03/what-are-gadts-and-why-do-they-make-type-inference-sad.html"><![CDATA[<p><a href="/2020/07/04/subtype-inference-by-example-part-1-introducing-cubiml.html">Back in 2020</a>, I created <a href="https://github.com/Storyyeller/cubiml-demo">Cubiml</a>, a simple ML-like language that demonstrated how to extend the usual Hindley–Milner type system with subtyping while still having decidable full type inference. One question I got was whether it would be possible to support generalized algebraic data types (GADTs) in Cubiml. I had heard that GADTs break type inference and didn’t see the point, so I didn’t think much of it at the time.</p>

<p>However, I recently got curious and researched GADTs again to figure out what they’re actually used for and to what extent are they compatible with type inference. As it turns out, my initial assumption wasn’t <em>quite</em> right. Strictly speaking, GADTs themselves don’t break type inference, but rather are only <em>useful</em> when combined with features (polymorphic recursion, existential types) that break type inference. For a language like Cubiml which has full type inference and hence can not support polymorphic recursion or existential types, it turns out that GADTs <em>don’t actually add any power</em>. Any program that could be typed in Cubiml with GADTs will <em>also</em> typecheck <em>without</em> GADTs.</p>

<p>In this post, I’ll go over some examples from Real World OCaml to show how GADTs work and how they compare to Cubiml.</p>

<h1 id="but-what-are-gadts-anyway">But what are GADTs, anyway?</h1>

<p>The term “algebraic data type” (ADT) refers to the ability to compose types to form new types. One operation is the <em>product type</em>, where given types <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code>, you form a new type that contains an <code class="language-plaintext highlighter-rouge">A</code> <em>and</em> a <code class="language-plaintext highlighter-rouge">B</code>. These are typically called “structs”, “records”, “tuples”, “objects” or the like, and are present in basically every programming language ever, even C.</p>

<p>The other operation is the <em>sum type</em>, where you can form a type that contains an <code class="language-plaintext highlighter-rouge">A</code> <em>or</em> a <code class="language-plaintext highlighter-rouge">B</code>. These are typically called “tagged unions”, “enums”, or “variants”, but many older languages don’t have sum types at all. Since every language has product types but not every language has sum types, sum types are what people are referring to in practice when they talk about algebraic data types.</p>

<p>For example, in Rust, where sum types are called “enums”, you can define a type that contains a <code class="language-plaintext highlighter-rouge">String</code> <em>or</em> a 32 bit int (<code class="language-plaintext highlighter-rouge">u32)</code> like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">MyEnum</span> <span class="p">{</span>
    <span class="nf">Foo</span><span class="p">(</span><span class="nb">String</span><span class="p">),</span>
    <span class="nf">Bar</span><span class="p">(</span><span class="nb">u32</span><span class="p">),</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This type has two <em>variants</em>, <code class="language-plaintext highlighter-rouge">Foo</code> and <code class="language-plaintext highlighter-rouge">Bar</code>, and values of the type can store either one with a special tag determining which one any given value holds at runtime. You can construct a value of type <code class="language-plaintext highlighter-rouge">MyEnum</code> using either variant, e.g. <code class="language-plaintext highlighter-rouge">MyEnum::Foo("hello".to_owned())</code> or <code class="language-plaintext highlighter-rouge">MyEnum::Bar(1234)</code>.</p>

<p>You can also define a <em>generic</em> enum type. For example, suppose you wanted a <code class="language-plaintext highlighter-rouge">MyEnum&lt;T&gt;</code> that stores either one or two <code class="language-plaintext highlighter-rouge">T</code>s for any type <code class="language-plaintext highlighter-rouge">T</code>. In Rust you would write this as</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nf">Foo</span><span class="p">(</span><span class="n">T</span><span class="p">),</span>
    <span class="nf">Bar</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In OCaml, this would be written as follows. Type parameters in OCaml are backwards compared to most languages, but the syntax is otherwise pretty similar.</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="k">'</span><span class="n">a</span> <span class="n">myenum</span> <span class="o">=</span>
<span class="o">|</span> <span class="nc">Foo</span> <span class="k">of</span> <span class="k">'</span><span class="n">a</span>
<span class="o">|</span> <span class="nc">Bar</span> <span class="k">of</span> <span class="k">'</span><span class="n">a</span> <span class="o">*</span> <span class="k">'</span><span class="n">a</span>
</code></pre></div></div>

<p>And you can construct them via <code class="language-plaintext highlighter-rouge">Foo 5</code>, <code class="language-plaintext highlighter-rouge">Bar (5, 6)</code>, etc.</p>

<h2 id="generalized-algebraic-data-types">Generalized algebraic data types</h2>

<p>So what’s the difference between GADTs and regular ADTs?</p>

<p>Remember how you construct an enum value by naming the variant and then the data? It looks a lot like a function. In Rust, enum variants are a language primitive rather than true functions, but it’s easy to imagine them being like functions. If you wanted to have explicit wrapper functions, you could write something like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">foo</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Foo</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="n">bar</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Bar</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Notice that in both cases, the return type is <code class="language-plaintext highlighter-rouge">MyEnum&lt;T&gt;</code>. But what if you wanted the return type to be something different? For example, what if you wanted the <code class="language-plaintext highlighter-rouge">Foo</code> variant to only be usable if <code class="language-plaintext highlighter-rouge">T</code> is copyable? With the wrapper functions, you could do it like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">foo</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="nb">Copy</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Foo</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>You could even bound <code class="language-plaintext highlighter-rouge">T</code> to be a specific type. For example, you could make <code class="language-plaintext highlighter-rouge">bar</code> only usable for ints like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">bar</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="nb">u32</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Bar</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, in this case, we only changed the signature of the <em>wrapper functions</em>. The underlying enum constructors have no such restrictions. For example, you can still write <code class="language-plaintext highlighter-rouge">Bar("hello", "world")</code> if you want to, and the Rust compiler won’t stop you because the <code class="language-plaintext highlighter-rouge">Bar</code> variant itself still accepts arbitrary types. Only the <code class="language-plaintext highlighter-rouge">bar</code> wrapper function was restricted to ints.</p>

<p>In Rust, there is no way to apply a custom function signature to the underlying enum constructors, but in OCaml, <em>you can</em>. And <em>that</em> is what GADTs are! Here’s how you would modify the OCaml example so that <code class="language-plaintext highlighter-rouge">Bar</code> only accepts ints:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="k">'</span><span class="n">a</span> <span class="n">myenum</span> <span class="o">=</span>
<span class="o">|</span> <span class="nc">Foo</span> <span class="k">of</span> <span class="k">'</span><span class="n">a</span>
<span class="o">|</span> <span class="nc">Bar</span> <span class="o">:</span> <span class="kt">int</span> <span class="o">*</span> <span class="kt">int</span> <span class="o">-&gt;</span> <span class="kt">int</span> <span class="n">myenum</span>
</code></pre></div></div>

<p>Additionally, the compiler knows that the only way to construct an enum is via one of the constructors, and thus the invariants established by the constructor signatures are considered part of the type itself, and can be assumed to hold when you match on the resulting value later. It’s a convenient way to compress what could be very complicated invariants into a single type name.</p>

<p>So what are GADTs actually used for, and how do they compare to what is possible in Cubiml? Let’s look at some examples from <a href="https://dev.realworldocaml.org/gadts.html">Real World OCaml</a>.</p>

<h1 id="example-1-associated-types">Example 1: Associated types</h1>

<p>We’ll start with the easiest example, faking associated types.</p>

<p>Suppose you want to have a function that searches a list, but where the user can customize the behavior when the element is not found. Specifically, you may want it to either a) throw an exception, b) return an option, or c) return a default value. In Rust, this is idiomatically handled by returning <code class="language-plaintext highlighter-rouge">Option</code> and letting the caller call <code class="language-plaintext highlighter-rouge">unwrap</code> or <code class="language-plaintext highlighter-rouge">unwrap_or</code> on it if they want to, but if you were to cram this all into a single function for some reason, you’d probably do it using associated types. However, OCaml doesn’t have Rust’s trait system, so instead they use GADTs to simulate associated types.</p>

<p>Here’s the example code. First, they define a GADT with three variants and two type parameters. The first type parameter is just the element type of the list, but the second type parameter is a dummy type parameter that will be used to control the return type of the find function, much like an associated type.</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">module</span> <span class="nc">If_not_found</span> <span class="o">=</span> <span class="k">struct</span>
  <span class="k">type</span> <span class="p">(</span><span class="n">_</span><span class="o">,</span> <span class="n">_</span><span class="p">)</span> <span class="n">t</span> <span class="o">=</span>
    <span class="o">|</span> <span class="nc">Raise</span> <span class="o">:</span> <span class="p">(</span><span class="k">'</span><span class="n">a</span><span class="o">,</span> <span class="k">'</span><span class="n">a</span><span class="p">)</span> <span class="n">t</span>
    <span class="o">|</span> <span class="nc">Return_none</span> <span class="o">:</span> <span class="p">(</span><span class="k">'</span><span class="n">a</span><span class="o">,</span> <span class="k">'</span><span class="n">a</span> <span class="n">option</span><span class="p">)</span> <span class="n">t</span>
    <span class="o">|</span> <span class="nc">Default_to</span> <span class="o">:</span> <span class="k">'</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="k">'</span><span class="n">a</span><span class="o">,</span> <span class="k">'</span><span class="n">a</span><span class="p">)</span> <span class="n">t</span>
<span class="k">end</span>
</code></pre></div></div>

<p>And here’s the <code class="language-plaintext highlighter-rouge">flexible_find</code> function, which takes in an instance of <code class="language-plaintext highlighter-rouge">If_not_found.t</code> to control the return behavior:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">rec</span> <span class="n">flexible_find</span>
 <span class="o">:</span> <span class="k">type</span> <span class="n">a</span> <span class="n">b</span><span class="o">.</span> <span class="n">f</span><span class="o">:</span><span class="p">(</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="kt">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">a</span> <span class="kt">list</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="p">)</span> <span class="nn">If_not_found</span><span class="p">.</span><span class="n">t</span> <span class="o">-&gt;</span> <span class="n">b</span> <span class="o">=</span>
 <span class="k">fun</span> <span class="o">~</span><span class="n">f</span> <span class="kt">list</span> <span class="n">if_not_found</span> <span class="o">-&gt;</span>
  <span class="k">match</span> <span class="kt">list</span> <span class="k">with</span>
  <span class="o">|</span> <span class="bp">[]</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="k">match</span> <span class="n">if_not_found</span> <span class="k">with</span>
    <span class="o">|</span> <span class="nc">Raise</span> <span class="o">-&gt;</span> <span class="n">failwith</span> <span class="s2">"No matching item found"</span>
    <span class="o">|</span> <span class="nc">Return_none</span> <span class="o">-&gt;</span> <span class="nc">None</span>
    <span class="o">|</span> <span class="nc">Default_to</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="p">)</span>
  <span class="o">|</span> <span class="n">hd</span> <span class="o">::</span> <span class="n">tl</span> <span class="o">-&gt;</span>
    <span class="k">if</span> <span class="n">f</span> <span class="n">hd</span>
    <span class="k">then</span> <span class="p">(</span>
      <span class="k">match</span> <span class="n">if_not_found</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nc">Raise</span> <span class="o">-&gt;</span> <span class="n">hd</span>
      <span class="o">|</span> <span class="nc">Return_none</span> <span class="o">-&gt;</span> <span class="nc">Some</span> <span class="n">hd</span>
      <span class="o">|</span> <span class="nc">Default_to</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="n">hd</span><span class="p">)</span>
    <span class="k">else</span> <span class="n">flexible_find</span> <span class="o">~</span><span class="n">f</span> <span class="n">tl</span> <span class="n">if_not_found</span>
</code></pre></div></div>

<p>And here are the examples of calling it:</p>
<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">flexible_find</span> <span class="o">~</span><span class="n">f</span><span class="o">:</span><span class="p">(</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">)</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span><span class="mi">2</span><span class="p">;</span><span class="mi">5</span><span class="p">]</span> <span class="nc">Return_none</span><span class="p">;;</span>
<span class="o">-</span> <span class="o">:</span> <span class="kt">int</span> <span class="n">option</span> <span class="o">=</span> <span class="nn">Base</span><span class="p">.</span><span class="nn">Option</span><span class="p">.</span><span class="nc">None</span>
<span class="n">flexible_find</span> <span class="o">~</span><span class="n">f</span><span class="o">:</span><span class="p">(</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">)</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span><span class="mi">2</span><span class="p">;</span><span class="mi">5</span><span class="p">]</span> <span class="p">(</span><span class="nc">Default_to</span> <span class="mi">10</span><span class="p">);;</span>
<span class="o">-</span> <span class="o">:</span> <span class="kt">int</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">flexible_find</span> <span class="o">~</span><span class="n">f</span><span class="o">:</span><span class="p">(</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">)</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span><span class="mi">2</span><span class="p">;</span><span class="mi">5</span><span class="p">]</span> <span class="nc">Raise</span><span class="p">;;</span>
<span class="nc">Exception</span><span class="o">:</span> <span class="p">(</span><span class="nc">Failure</span> <span class="s2">"No matching item found"</span><span class="p">)</span><span class="o">.</span>
<span class="n">flexible_find</span> <span class="o">~</span><span class="n">f</span><span class="o">:</span><span class="p">(</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">)</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span><span class="mi">2</span><span class="p">;</span><span class="mi">20</span><span class="p">]</span> <span class="nc">Raise</span><span class="p">;;</span>
<span class="o">-</span> <span class="o">:</span> <span class="kt">int</span> <span class="o">=</span> <span class="mi">20</span>
</code></pre></div></div>

<h2 id="what-about-cubiml">What about Cubiml?</h2>

<p>Cubiml doesn’t have exceptions, so we can’t translate the “Raise” variant for reasons unrelated to the type system. However, we can still have a function that either returns an option or default value. Here’s the same code, translated into Cubiml:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">rec</span> <span class="n">flexible_find</span> <span class="o">=</span> <span class="k">fun</span> <span class="p">{</span><span class="n">f</span><span class="p">;</span> <span class="kt">list</span><span class="p">;</span> <span class="n">not_found</span><span class="p">}</span> <span class="o">-&gt;</span>
    <span class="k">if</span> <span class="kt">list</span> <span class="o">==</span> <span class="n">null</span> <span class="k">then</span>
        <span class="k">match</span> <span class="n">not_found</span> <span class="k">with</span>
        <span class="o">|</span> <span class="nt">`Default_to</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span>
        <span class="o">|</span> <span class="nt">`Return_none</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="nt">`None</span> <span class="p">{}</span>
    <span class="k">else</span>
        <span class="k">if</span> <span class="n">f</span> <span class="kt">list</span><span class="o">.</span><span class="n">h</span> <span class="k">then</span>
            <span class="k">match</span> <span class="n">not_found</span> <span class="k">with</span>
            <span class="o">|</span> <span class="nt">`Default_to</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="kt">list</span><span class="o">.</span><span class="n">h</span>
            <span class="o">|</span> <span class="nt">`Return_none</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="nt">`Some</span> <span class="kt">list</span><span class="o">.</span><span class="n">h</span>
        <span class="k">else</span>
            <span class="n">flexible_find</span> <span class="p">{</span><span class="n">f</span><span class="p">;</span> <span class="kt">list</span><span class="o">=</span><span class="kt">list</span><span class="o">.</span><span class="n">t</span><span class="p">;</span> <span class="n">not_found</span><span class="p">}</span>
</code></pre></div></div>

<p>And we can call it like this:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">flexible_find</span> <span class="p">{</span><span class="n">f</span><span class="o">=</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">;</span> <span class="kt">list</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">5</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="n">null</span><span class="p">}}};</span> <span class="n">not_found</span><span class="o">=</span><span class="nt">`Return_none</span> <span class="p">{}}</span>
<span class="nt">`None</span><span class="p">{}</span>

<span class="o">&gt;&gt;</span> <span class="n">flexible_find</span> <span class="p">{</span><span class="n">f</span><span class="o">=</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">;</span> <span class="kt">list</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">5</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="n">null</span><span class="p">}}};</span> <span class="n">not_found</span><span class="o">=</span><span class="nt">`Default_to</span> <span class="mi">10</span><span class="p">}</span>
<span class="mi">10</span>

<span class="o">&gt;&gt;</span> <span class="n">flexible_find</span> <span class="p">{</span><span class="n">f</span><span class="o">=</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">;</span> <span class="kt">list</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">20</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="n">null</span><span class="p">}}};</span> <span class="n">not_found</span><span class="o">=</span><span class="nt">`Return_none</span> <span class="p">{}}</span>
<span class="nt">`Some</span> <span class="mi">20</span>

<span class="o">&gt;&gt;</span> <span class="n">flexible_find</span> <span class="p">{</span><span class="n">f</span><span class="o">=</span><span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">;</span> <span class="kt">list</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">2</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="p">{</span><span class="n">h</span><span class="o">=</span><span class="mi">20</span><span class="p">;</span> <span class="n">t</span><span class="o">=</span><span class="n">null</span><span class="p">}}};</span> <span class="n">not_found</span><span class="o">=</span><span class="nt">`Default_to</span> <span class="mi">10</span><span class="p">}</span>
<span class="mi">20</span>
</code></pre></div></div>

<p>Now let’s try another example.</p>

<h1 id="example-2-polymorphic-ast-evaluation">Example 2: Polymorphic AST evaluation</h1>

<p>This is The Canonical Example Of GADTs. If you find any example of GADTs on the internet, there’s a 90% chance that it will be exactly this example or a slight variation on it.</p>

<p>So what is The Canonical Example Of GADTs? The challenge is that we have a simple expression tree that we want to build an evaluation function for. The trick however is that some subexpressions may evaluate to booleans while others may evaluate to integers.</p>

<p>Here’s the OCaml approach without GADTs, just using ordinary enums:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">value</span> <span class="o">=</span>
  <span class="o">|</span> <span class="nc">Int</span> <span class="k">of</span> <span class="kt">int</span>
  <span class="o">|</span> <span class="nc">Bool</span> <span class="k">of</span> <span class="kt">bool</span>

<span class="k">type</span> <span class="n">expr</span> <span class="o">=</span>
  <span class="o">|</span> <span class="nc">Value</span> <span class="k">of</span> <span class="n">value</span>
  <span class="o">|</span> <span class="nc">Eq</span> <span class="k">of</span> <span class="n">expr</span> <span class="o">*</span> <span class="n">expr</span>
  <span class="o">|</span> <span class="nc">Plus</span> <span class="k">of</span> <span class="n">expr</span> <span class="o">*</span> <span class="n">expr</span>
  <span class="o">|</span> <span class="nc">If</span> <span class="k">of</span> <span class="n">expr</span> <span class="o">*</span> <span class="n">expr</span> <span class="o">*</span> <span class="n">expr</span>

<span class="k">let</span> <span class="k">rec</span> <span class="n">eval</span> <span class="n">expr</span> <span class="o">=</span>
  <span class="k">match</span> <span class="n">expr</span> <span class="k">with</span>
  <span class="o">|</span> <span class="nc">Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
  <span class="o">|</span> <span class="nc">If</span> <span class="p">(</span><span class="n">c</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="k">match</span> <span class="n">eval</span> <span class="n">c</span> <span class="k">with</span>
     <span class="o">|</span> <span class="nc">Bool</span> <span class="n">b</span> <span class="o">-&gt;</span> <span class="k">if</span> <span class="n">b</span> <span class="k">then</span> <span class="n">eval</span> <span class="n">t</span> <span class="k">else</span> <span class="n">eval</span> <span class="n">e</span>
     <span class="o">|</span> <span class="nc">Int</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="k">raise</span> <span class="nc">Ill_typed</span><span class="p">)</span>
  <span class="o">|</span> <span class="nc">Eq</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="k">match</span> <span class="n">eval</span> <span class="n">x</span><span class="o">,</span> <span class="n">eval</span> <span class="n">y</span> <span class="k">with</span>
     <span class="o">|</span> <span class="nc">Bool</span> <span class="n">_</span><span class="o">,</span> <span class="n">_</span> <span class="o">|</span> <span class="n">_</span><span class="o">,</span> <span class="nc">Bool</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="k">raise</span> <span class="nc">Ill_typed</span>
     <span class="o">|</span> <span class="nc">Int</span> <span class="n">f1</span><span class="o">,</span> <span class="nc">Int</span> <span class="n">f2</span> <span class="o">-&gt;</span> <span class="nc">Bool</span> <span class="p">(</span><span class="n">f1</span> <span class="o">=</span> <span class="n">f2</span><span class="p">))</span>
  <span class="o">|</span> <span class="nc">Plus</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="k">match</span> <span class="n">eval</span> <span class="n">x</span><span class="o">,</span> <span class="n">eval</span> <span class="n">y</span> <span class="k">with</span>
     <span class="o">|</span> <span class="nc">Bool</span> <span class="n">_</span><span class="o">,</span> <span class="n">_</span> <span class="o">|</span> <span class="n">_</span><span class="o">,</span> <span class="nc">Bool</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="k">raise</span> <span class="nc">Ill_typed</span>
     <span class="o">|</span> <span class="nc">Int</span> <span class="n">f1</span><span class="o">,</span> <span class="nc">Int</span> <span class="n">f2</span> <span class="o">-&gt;</span> <span class="nc">Int</span> <span class="p">(</span><span class="n">f1</span> <span class="o">+</span> <span class="n">f2</span><span class="p">))</span>
</code></pre></div></div>

<p>The problem with this code is that <code class="language-plaintext highlighter-rouge">eval</code> just returns an enum (<code class="language-plaintext highlighter-rouge">value</code>) containing either an int or boolean. Even if you know for sure that your expression is an integer expression, the compiler won’t know that and you’ll have to do a runtime check to extract the int. Additionally, the eval function itself has a lot of runtime type checks. It would be nice if we could rule out invalid expressions at compile time instead.</p>

<p>The first problem can be solved by having a pair of mutually recursive functions, one for evaluating integer expressions (which will hence always return an int) and one for evaluating boolean expressions. Real World OCaml doesn’t provide this version, but it isn’t hard to write:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> 
    <span class="k">rec</span> <span class="n">eval_i</span> <span class="n">expr</span> <span class="o">=</span>
      <span class="k">match</span> <span class="n">expr</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nc">Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="k">match</span> <span class="n">v</span> <span class="k">with</span>
        <span class="o">|</span> <span class="nc">Int</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
        <span class="o">|</span> <span class="nc">Bool</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="k">raise</span> <span class="nc">Ill_typed</span><span class="p">)</span>
      <span class="o">|</span> <span class="nc">If</span> <span class="p">(</span><span class="n">c</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">-&gt;</span>
        <span class="k">if</span> <span class="n">eval_b</span> <span class="n">c</span> <span class="k">then</span> <span class="n">eval_i</span> <span class="n">t</span> <span class="k">else</span> <span class="n">eval_i</span> <span class="n">e</span>
      <span class="o">|</span> <span class="nc">Eq</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span>
        <span class="k">raise</span> <span class="nc">Ill_typed</span>
      <span class="o">|</span> <span class="nc">Plus</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span>
        <span class="p">(</span><span class="n">eval_i</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">eval_i</span> <span class="n">y</span><span class="p">)</span>

    <span class="ow">and</span> <span class="n">eval_b</span> <span class="n">expr</span> <span class="o">=</span>
      <span class="k">match</span> <span class="n">expr</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nc">Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="k">match</span> <span class="n">v</span> <span class="k">with</span>
        <span class="o">|</span> <span class="nc">Bool</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
        <span class="o">|</span> <span class="nc">Int</span> <span class="n">_</span> <span class="o">-&gt;</span> <span class="k">raise</span> <span class="nc">Ill_typed</span><span class="p">)</span>
      <span class="o">|</span> <span class="nc">If</span> <span class="p">(</span><span class="n">c</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">-&gt;</span>
        <span class="k">if</span> <span class="n">eval_b</span> <span class="n">c</span> <span class="k">then</span> <span class="n">eval_b</span> <span class="n">t</span> <span class="k">else</span> <span class="n">eval_b</span> <span class="n">e</span>
      <span class="o">|</span> <span class="nc">Eq</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> 
        <span class="p">(</span><span class="n">eval_i</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">eval_i</span> <span class="n">y</span><span class="p">)</span>
      <span class="o">|</span> <span class="nc">Plus</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> 
        <span class="k">raise</span> <span class="nc">Ill_typed</span>

</code></pre></div></div>

<p>This is a lot better, but it still has runtime type checks and it also requires duplicating the logic for the <code class="language-plaintext highlighter-rouge">If</code> case. With GADTs, we can merge everything into a single polymorphic eval function while also improving type safety:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">_</span> <span class="n">expr</span> <span class="o">=</span>
  <span class="o">|</span> <span class="nc">Value</span> <span class="o">:</span> <span class="k">'</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="k">'</span><span class="n">a</span> <span class="n">expr</span>
  <span class="o">|</span> <span class="nc">Eq</span> <span class="o">:</span> <span class="kt">int</span> <span class="n">expr</span> <span class="o">*</span> <span class="kt">int</span> <span class="n">expr</span> <span class="o">-&gt;</span> <span class="kt">bool</span> <span class="n">expr</span>
  <span class="o">|</span> <span class="nc">Plus</span> <span class="o">:</span> <span class="kt">int</span> <span class="n">expr</span> <span class="o">*</span> <span class="kt">int</span> <span class="n">expr</span> <span class="o">-&gt;</span> <span class="kt">int</span> <span class="n">expr</span>
  <span class="o">|</span> <span class="nc">If</span> <span class="o">:</span> <span class="kt">bool</span> <span class="n">expr</span> <span class="o">*</span> <span class="k">'</span><span class="n">a</span> <span class="n">expr</span> <span class="o">*</span> <span class="k">'</span><span class="n">a</span> <span class="n">expr</span> <span class="o">-&gt;</span> <span class="k">'</span><span class="n">a</span> <span class="n">expr</span>

<span class="k">let</span> <span class="k">rec</span> <span class="n">eval</span> <span class="o">:</span> <span class="k">type</span> <span class="n">a</span><span class="o">.</span> <span class="n">a</span> <span class="n">expr</span> <span class="o">-&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="k">function</span>
  <span class="o">|</span> <span class="nc">Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
  <span class="o">|</span> <span class="nc">If</span> <span class="p">(</span><span class="n">c</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="k">if</span> <span class="n">eval</span> <span class="n">c</span> <span class="k">then</span> <span class="n">eval</span> <span class="n">t</span> <span class="k">else</span> <span class="n">eval</span> <span class="n">e</span>
  <span class="o">|</span> <span class="nc">Eq</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">eval</span> <span class="n">x</span> <span class="o">=</span> <span class="n">eval</span> <span class="n">y</span>
  <span class="o">|</span> <span class="nc">Plus</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">eval</span> <span class="n">x</span> <span class="o">+</span> <span class="n">eval</span> <span class="n">y</span>
</code></pre></div></div>

<blockquote>
  <p>Note: I modified this example from the version in Real World OCaml by removing the unnecessary value enum.</p>
</blockquote>

<h2 id="meanwhile-in-cubiml">Meanwhile in Cubiml</h2>

<p>So what about Cubiml? We can translate the mutual recursion version into Cubiml as follows:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span>
    <span class="k">rec</span> <span class="n">eval_i</span> <span class="o">=</span> <span class="k">fun</span> <span class="n">expr</span> <span class="o">-&gt;</span>
      <span class="k">match</span> <span class="n">expr</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nt">`Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
      <span class="o">|</span> <span class="nt">`If</span> <span class="n">v</span> <span class="o">-&gt;</span>
        <span class="p">(</span><span class="k">if</span> <span class="n">eval_b</span> <span class="n">v</span><span class="o">.</span><span class="n">c</span> <span class="k">then</span> <span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">t</span> <span class="k">else</span> <span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>
      <span class="o">|</span> <span class="nt">`Plus</span> <span class="n">v</span> <span class="o">-&gt;</span>
        <span class="p">(</span><span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

    <span class="ow">and</span> <span class="n">eval_b</span> <span class="o">=</span> <span class="k">fun</span> <span class="n">expr</span> <span class="o">-&gt;</span>
      <span class="k">match</span> <span class="n">expr</span> <span class="k">with</span>
      <span class="o">|</span> <span class="nt">`Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
      <span class="o">|</span> <span class="nt">`If</span> <span class="n">v</span> <span class="o">-&gt;</span>
        <span class="p">(</span><span class="k">if</span> <span class="n">eval_b</span> <span class="n">v</span><span class="o">.</span><span class="n">c</span> <span class="k">then</span> <span class="n">eval_b</span> <span class="n">v</span><span class="o">.</span><span class="n">t</span> <span class="k">else</span> <span class="n">eval_b</span> <span class="n">v</span><span class="o">.</span><span class="n">e</span><span class="p">)</span>
      <span class="o">|</span> <span class="nt">`Eq</span> <span class="n">v</span> <span class="o">-&gt;</span>
        <span class="p">(</span><span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">eval_i</span> <span class="n">v</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<p>This version still has to duplicate the <code class="language-plaintext highlighter-rouge">If</code> case, but it at least has no runtime type checks. Interestingly, the same example works with minor modifications in OCaml as well. As it turns out, you don’t need GADTs to eliminate the runtime type checks here in the first place. That problem was self-inflicted all along!</p>

<p>However, the mutual recursion version still has one downside, which is that the <code class="language-plaintext highlighter-rouge">If</code> case has to be duplicated between the two functions. It would be nice if there were a way to merge these two functions into a single function and avoid the duplication. In this toy example where we only have ints and booleans, manually splitting the function into a separate copy per type is not that big a deal, but in a more realistic example where you want your AST to evaluate to <em>arbitrary</em> types, it is completely infeasible.</p>

<h1 id="polymorphic-recursion">Polymorphic Recursion</h1>

<p>What we want is a single <code class="language-plaintext highlighter-rouge">eval</code> function that sometimes returns a bool and sometimes returns an int, and can call itself recursively, with the recursive calls possibly returning <em>different types</em>. This means that we need the eval function to not only be polymorphic at the top level, but to be <em>recursively</em> polymorphic, with every recursive call instantiating itself with new types. Unfortunately, there is no way to do this in Cubiml, because such polymorphic recursion makes type inference undecidable.</p>

<p>Classic Hindley–Milner type inference uses <em>let polymorphism</em>, where let-bound variables are made polymorphic and will be duplicated with fresh type parameters every time they are referenced. However, within a recursive function definition, the recursive calls are just an ordinary monomorphic variable. The recursive definition <em>as a whole</em> is still polymorphic (i.e. duplicated for each <em>outside</em> caller), but within any given instance, the <em>recursive</em> calls have to all use a single type.</p>

<p>In the first example with <code class="language-plaintext highlighter-rouge">flexible_find</code>, the polymorphic choices (which type of list and which <code class="language-plaintext highlighter-rouge">not_found</code> behavior to use) were fixed at the top level. For any given call top-level call to <code class="language-plaintext highlighter-rouge">flexible_find</code>, all recursive calls would use the same types, and therefore it doesn’t require polymorphic recursion.</p>

<p>While type inference with let polymorphism is technically decidable, it is already EXPTIME-complete, i.e. it requires exponential-worst case time to check. Roughly speaking, the reason for this is because it is possible to write functions which simulate a step of arbitrary computation <em>at the type level</em>. Let polymorphism then lets you instantiate and compose an exponential number of copies of the function and thus simulate an exponentially large number of steps of an arbitrary computation, and hence type inference inherently requires at least exponential time in the worst case.</p>

<p>However, if you allow recursive calls to also be polymorphic, then you can instantiate not just an exponentially large number of copies of the function but an <em>infinite</em> number of copies. And this means you can simulate <em>infinite</em> steps of arbitrary computation, and hence type inference is Turing Complete and thus undecidable.</p>

<p>If polymorphic recursion is undecidable, how does OCaml get away with it? The answer is that OCaml requires explicit type annotations. Recall the previous code example:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">rec</span> <span class="n">eval</span> <span class="o">:</span> <span class="k">type</span> <span class="n">a</span><span class="o">.</span> <span class="n">a</span> <span class="n">expr</span> <span class="o">-&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="k">function</span>
  <span class="o">|</span> <span class="nc">Value</span> <span class="n">v</span> <span class="o">-&gt;</span> <span class="n">v</span>
  <span class="o">|</span> <span class="nc">If</span> <span class="p">(</span><span class="n">c</span><span class="o">,</span> <span class="n">t</span><span class="o">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="k">if</span> <span class="n">eval</span> <span class="n">c</span> <span class="k">then</span> <span class="n">eval</span> <span class="n">t</span> <span class="k">else</span> <span class="n">eval</span> <span class="n">e</span>
  <span class="o">|</span> <span class="nc">Eq</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">eval</span> <span class="n">x</span> <span class="o">=</span> <span class="n">eval</span> <span class="n">y</span>
  <span class="o">|</span> <span class="nc">Plus</span> <span class="p">(</span><span class="n">x</span><span class="o">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">eval</span> <span class="n">x</span> <span class="o">+</span> <span class="n">eval</span> <span class="n">y</span>
</code></pre></div></div>

<p>Notice the <code class="language-plaintext highlighter-rouge">: type a. a expr -&gt; a</code> part. That’s a mandatory type annotation. If you remove it, the code won’t compile.</p>

<p>There are two ways to think about type annotations. One way to think about them as just optional weakenings or restatements of what the compiler could already infer by itself. Cubiml has full type inference, which means that type annotations are never necessary. Any code that compiles with type annotations will still compile <em>without</em> the type annotations.</p>

<p>However, full type inference is inherently limited to type systems where inference is decidable. As usual, there is no free lunch. The more powerful you make your type system, the more work it takes to infer. And in the real world, programmers often want to statically verify non-inferrable properties of their code, which means that real world programming languages invariably give up on full type inference.</p>

<p>The second way to look at type annotations is as a <em>load-bearing</em> part of the code, the compiler’s way of getting assistance from the programmer. Rather than being optional hints, type annotations are required in order for the code to even compile. In exchange, the programmer can use non-inferrable features like polymorphic recursion because the compiler only has to be able to <em>check</em> the proofs of correctness (i.e types), rather than to <em>figure out</em> the proofs itself.</p>

<h1 id="example-3-existential-types">Example 3: Existential types</h1>

<p>So far, in all the examples we’ve seen, the enum type itself has been <em>more</em> polymorphic than the constructors. I.e. the constructors are used to implicitly <em>add constraints</em> to the enum. However, what happens if you do the opposite, where the type is <em>less</em> polymorphic than the constructors?</p>

<p>Suppose you want an enum that can store a value and a function to convert that value to a string. Going back to the GADT pseudo-Rust syntax used before, you might write something like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nf">Stringable</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="p">),</span>
<span class="p">}</span>
<span class="k">fn</span> <span class="n">stringable</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">F</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="o">&gt;</span>
<span class="k">where</span>
    <span class="n">F</span><span class="p">:</span> <span class="nf">FnOnce</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span><span class="p">,</span>
<span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Stringable</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>However, this has the problem that <code class="language-plaintext highlighter-rouge">MyEnum</code> is too polymorphic. For any given value of <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">F</code>, <code class="language-plaintext highlighter-rouge">MyEnum&lt;T, F&gt;</code> can only hold <em>one specific</em> element and function type. What we want is a <em>single</em> <code class="language-plaintext highlighter-rouge">MyEnum</code> type that can hold <em>any</em> stringable value. To do this, we need to erase the type and use runtime dispatch. In Rust, this is done using trait objects (written <code class="language-plaintext highlighter-rouge">dyn Trait</code>). We can fix the example by adding a wrapper trait object like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">trait</span> <span class="n">Stringable</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">to_string</span><span class="p">(</span><span class="k">self</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">Self</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="o">&gt;</span> <span class="n">Stringable</span> <span class="k">for</span> <span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
<span class="k">where</span>
    <span class="n">F</span><span class="p">:</span> <span class="nf">FnOnce</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span><span class="p">,</span>
<span class="p">{</span>
    <span class="k">fn</span> <span class="nf">to_string</span><span class="p">(</span><span class="k">self</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">Self</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
        <span class="k">self</span><span class="na">.1</span><span class="p">(</span><span class="k">self</span><span class="na">.0</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">enum</span> <span class="n">MyEnum</span> <span class="p">{</span>
    <span class="nf">Stringable</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Stringable</span><span class="o">&gt;</span><span class="p">),</span>
<span class="p">}</span>
<span class="k">fn</span> <span class="n">stringable</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">F</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">MyEnum</span>
<span class="k">where</span>
    <span class="n">T</span><span class="p">:</span> <span class="k">'static</span><span class="p">,</span>
    <span class="n">F</span><span class="p">:</span> <span class="p">(</span><span class="nf">FnOnce</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span><span class="p">)</span> <span class="o">+</span> <span class="k">'static</span><span class="p">,</span>
<span class="p">{</span>
    <span class="nn">MyEnum</span><span class="p">::</span><span class="nf">Stringable</span><span class="p">(</span><span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">((</span><span class="n">v</span><span class="p">,</span> <span class="n">f</span><span class="p">)))</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Notice that our “constructor” function <code class="language-plaintext highlighter-rouge">stringable</code> is now polymorphic in its parameters but has a non-polymorphic return type (<code class="language-plaintext highlighter-rouge">MyEnum</code>). That’s because it erases the input types and converts it to a vtable so that callers can look up the appropriate function at runtime later without knowing which concrete type any given instance of <code class="language-plaintext highlighter-rouge">MyEnum</code> contains. This is known as an <em>existential type</em>.</p>

<p>OCaml works similarly, except that existential types are a lot more flexible than in Rust. In particular, Rust has no way to express existential type constraints between multiple values, so we’re forced to bind <code class="language-plaintext highlighter-rouge">T</code> and <code class="language-plaintext highlighter-rouge">F</code> together at the point of construction and only expose a pre-selected set of operations (<code class="language-plaintext highlighter-rouge">Stringable::to_string</code> in this case). However, OCaml does not have this limitation. In OCaml, callers can still access and manipulate the fields, even without knowing what types they are.</p>

<p>In OCaml, you can create existential types using GADTs like this:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">stringable</span> <span class="o">=</span>
  <span class="nc">Stringable</span> <span class="o">:</span> <span class="p">{</span> <span class="n">value</span><span class="o">:</span> <span class="k">'</span><span class="n">a</span><span class="p">;</span> <span class="n">to_string</span><span class="o">:</span> <span class="k">'</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="kt">string</span> <span class="p">}</span> <span class="o">-&gt;</span> <span class="n">stringable</span>

<span class="k">let</span> <span class="n">print_stringable</span> <span class="p">(</span><span class="nc">Stringable</span> <span class="n">s</span><span class="p">)</span> <span class="o">=</span>
  <span class="nn">Stdio</span><span class="p">.</span><span class="n">print_endline</span> <span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">to_string</span> <span class="n">s</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</code></pre></div></div>

<p>There’s no inherent reason for existential types to be tied to GADTs, but in OCaml they are, so people often think of them as part of the GADT package (you can also use existential types via objects or first class modules in OCaml).</p>

<h2 id="what-about-cubiml-1">What about Cubiml?</h2>

<p>Unfortunately, existential types <em>also</em> make type inference undecidable, so Cubiml doesn’t have them either. This shouldn’t be too surprising because existentially quantified types are the mirror image of universally quantified types (i.e. polymorphic types), and those also make type inference undecidable. (Technically, you can infer them for let-bound variables at the cost of exponential time as described above, but they aren’t a first-class part of the type system and can’t be used for regular variables.)</p>

<p>One way to understand why existential types are a problem for type inference is to consider the fact that in order to <em>use</em> a value with an existential type, your code has to be capable of working with any type that the value <em>could</em> be. That means that any code which uses the value has to be polymorphic, and thus any recursive function which needs to use a value of existential type will have the same problems with polymorphic recursion explained previously.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In retrospect, it’s not surprising that GADTs don’t add any power to Cubiml. GADTs are just a way of supplying custom type annotations to enum constructors. However, <em>type annotations in general</em> don’t add any power to Cubiml. Cubiml has full type inference, which means that the compiler will always infer the most general possible type and type annotations are never necessary. Anything you can do with type annotations in Cubiml can also be done <em>without</em> type annotations. Therefore, GADTs only make sense in a language like OCaml or Haskell that <em>doesn’t</em> have full type inference.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Back in 2020, I created Cubiml, a simple ML-like language that demonstrated how to extend the usual Hindley–Milner type system with subtyping while still having decidable full type inference. One question I got was whether it would be possible to support generalized algebraic data types (GADTs) in Cubiml. I had heard that GADTs break type inference and didn’t see the point, so I didn’t think much of it at the time.]]></summary></entry><entry><title type="html">Identifying Rust’s collect::&amp;lt;Vec&amp;gt;() memory leak footgun</title><link href="/2024/01/17/identifying-the-collect-vec-memory-leak-footgun.html" rel="alternate" type="text/html" title="Identifying Rust’s collect::&amp;lt;Vec&amp;gt;() memory leak footgun" /><published>2024-01-17T15:57:00+00:00</published><updated>2024-01-17T15:57:00+00:00</updated><id>/2024/01/17/identifying-the-collect-vec-memory-leak-footgun</id><content type="html" xml:base="/2024/01/17/identifying-the-collect-vec-memory-leak-footgun.html"><![CDATA[<p>Over the weekend, I was working on a personal Rust project when I ran into an excessive memory usage problem. After an evening of trial and error, I found a workaround to fix the memory usage, but I still didn’t understand how the issue was even possible, so I then spent another evening digging through the source code of the Rust standard library to understand the root cause.</p>

<p>This is the story of how I identified the bug. (TLDR: <code class="language-plaintext highlighter-rouge">collect::&lt;Vec&lt;_&gt;&gt;()</code> will sometimes reuse allocations, resulting in <code class="language-plaintext highlighter-rouge">Vec</code>s with large excess capacity, even when the length is exactly known in advance, so you need to call <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> if you want to free the extra memory.)</p>

<h1 id="background">Background</h1>

<p>The project I’m working on involves building a sparse weighted graph and then doing various calculations on the graph. I finally finished the initial version of the code Monday afternoon and tried running it, only for it to exhaust my computer’s 32gb of RAM before getting anywhere. Specifically, the final graph was supposed to have around three million nodes, but during graph construction, the process memory already shot up to over 18gb by the time it reached 300k nodes, and it would use up the entire RAM soon afterwards, slowing everything to a crawl and forcing me to kill the process.</p>

<p>At first, I assumed that the computations I was trying to do were just too big and my project was impossible, but I didn’t give up just yet, and spent the rest of the evening trying to figure out which parts were using so much memory and whether there was any way to optimize them.</p>

<h1 id="narrowing-down-the-memory-leak">Narrowing down the memory leak</h1>

<p>There were several places in the code where I used <a href="https://en.wikipedia.org/wiki/Memoization">memoization</a>, so I initially suspected those of being the cause of the exploding memory usage. I modified the graph construction function to stop after 300k nodes (when memory usage reached 18gb as seen via <code class="language-plaintext highlighter-rouge">top</code>, large but not quite enough to kill the computer), and added <code class="language-plaintext highlighter-rouge">println!</code>s to log the estimated total sizes of the memoized results. However, they were only in the 100mb range, nowhere near enough to explain the observed memory usage.</p>

<p>Next I tried running graph construction <em>twice</em> (but with it set to stop early at 300k nodes each time) to try to narrow down the cause. My main function looked like this (with <code class="language-plaintext highlighter-rouge">denom</code> and <code class="language-plaintext highlighter-rouge">optimistic</code> being parameters for the algorithm).</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">denom</span> <span class="o">=</span> <span class="mi">257</span><span class="p">;</span>
<span class="k">let</span> <span class="n">optimistic</span> <span class="o">=</span> <span class="k">false</span><span class="p">;</span>
<span class="k">let</span> <span class="n">graph</span> <span class="o">=</span> <span class="nf">build_graph</span><span class="p">(</span><span class="n">denom</span><span class="p">,</span> <span class="n">optimistic</span><span class="p">);</span>
<span class="k">let</span> <span class="n">graph</span> <span class="o">=</span> <span class="nf">build_graph</span><span class="p">(</span><span class="n">denom</span><span class="p">,</span> <span class="n">optimistic</span><span class="p">);</span>
</code></pre></div></div>

<p>I carefully watched the process memory usage while this ran, to see if it would stop at 18gb or not. I thought that perhaps the memoization was using a lot more memory than expected due to memory fragmentation exploding the heap.</p>

<p>Since the code is deterministic, calling <code class="language-plaintext highlighter-rouge">build_graph</code> twice won’t result in any new results being memoized, and thus memory usage should stop at 18gb, even when it is run twice. Instead, memory usage continued to rapidly increase during the second <code class="language-plaintext highlighter-rouge">build_graph</code> call, which made no sense.</p>

<p>Fortunately, I then tried dropping <code class="language-plaintext highlighter-rouge">graph</code> in between:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">graph</span> <span class="o">=</span> <span class="nf">build_graph</span><span class="p">(</span><span class="n">denom</span><span class="p">,</span> <span class="n">optimistic</span><span class="p">);</span>
<span class="nn">std</span><span class="p">::</span><span class="nn">mem</span><span class="p">::</span><span class="nf">drop</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="k">let</span> <span class="n">graph</span> <span class="o">=</span> <span class="nf">build_graph</span><span class="p">(</span><span class="n">denom</span><span class="p">,</span> <span class="n">optimistic</span><span class="p">);</span>
</code></pre></div></div>

<p>Suddenly, this time process memory usage dropped from 18gb to ~500mb after the first <code class="language-plaintext highlighter-rouge">build_graph</code> call, before going back up to 18gb. Clearly, the memory was somehow being wasted by <code class="language-plaintext highlighter-rouge">graph</code> itself. As before, I tried printing out the size of the graph, but it was nowhere near enough to explain the memory usage.</p>

<p>However, my <code class="language-plaintext highlighter-rouge">graph</code> data structure consists of <code class="language-plaintext highlighter-rouge">Vec</code>s, and Vec can use more memory than the size would indicate since they preallocate a buffer with up to 2x capacity in order to make insertion amortized O(1) time. I changed it to log the total <em>capacity</em> rather than <em>length</em> and suddenly the estimated size of the graph was 18gb. Bingo! I added <code class="language-plaintext highlighter-rouge">shrink_to_fit()</code> calls (which remove the excess capacity) into the graph construction code and suddenly the memory problems disappeared.</p>

<h1 id="wait-but-why">Wait, but why?</h1>

<p>I’d finally identified the <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> workaround late Monday night and planned to continue work on the project the following weekend. I mentioned my experience to my coworkers at work the following morning, as a PSA about the importance of <code class="language-plaintext highlighter-rouge">shrink_to_fit</code>, but they didn’t believe me, and when I thought about it more, I couldn’t believe it myself either.</p>

<p>First off, <code class="language-plaintext highlighter-rouge">Vec</code> only grows the buffer by 2x at a time, which means that (ignoring the initial allocation for small vecs), the capacity will always be at most double the length (assuming you don’t remove elements), so the memory waste from excess capacity should always be at most 2x, but I was seeing over 200x.</p>

<p>Second, the memory leak was coming from the edge lists of the graph, which I was storing as <code class="language-plaintext highlighter-rouge">Vec&lt;Vec&lt;(u32, u32)&gt;&gt;</code> (a table with one <code class="language-plaintext highlighter-rouge">Vec</code> storing the edge list for each node). When I called <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> on the edge lists before inserting them, the memory problem disappeared. However, the final step for producing the edge lists was a <code class="language-plaintext highlighter-rouge">vec.into_iter().map(..).collect()</code> call to convert them to the appropriate format. Since <code class="language-plaintext highlighter-rouge">collect</code> allocates a fresh vector and the length is exactly known, it only allocates exactly enough space for the elements and there should never be <em>any</em> excess capacity at all, let alone 200x excess capacity.</p>

<h1 id="the-vec-source-code">The Vec source code</h1>

<p>Clearly, my assumptions about the implementation of <code class="language-plaintext highlighter-rouge">Vec</code> were incorrect somehow, and so out of curiosity, after work Tuesday evening, I dug into the <code class="language-plaintext highlighter-rouge">Vec</code> source code to try to figure out what was going on. There are several layers of indirection and specialization, but it didn’t take long to trace through all the relevant code (or so I thought).</p>

<p>When you call <code class="language-plaintext highlighter-rouge">collect()</code>, it calls <code class="language-plaintext highlighter-rouge">FromIterator::from_iter</code>. <a href="https://github.com/rust-lang/rust/blob/c58a5da7d48ff3887afe4c618dc04defdee3dab5/library/alloc/src/vec/mod.rs#L2791"><code class="language-plaintext highlighter-rouge">Vec</code>’s <code class="language-plaintext highlighter-rouge">FromIterator</code> impl</a> in turn calls <code class="language-plaintext highlighter-rouge">SpecFromIter</code>, an internal trait.</p>

<p><a href="https://github.com/rust-lang/rust/blob/c58a5da7d48ff3887afe4c618dc04defdee3dab5/library/alloc/src/vec/spec_from_iter.rs"><code class="language-plaintext highlighter-rouge">SpecFromIter</code></a> has a specialization for <code class="language-plaintext highlighter-rouge">IntoIter</code> (i.e. if you call <code class="language-plaintext highlighter-rouge">vec.into_iter().collect()</code> with no intervening iterator adapters, it will just return the original vec instead of creating a new one). Otherwise, it calls a second internal trait, <code class="language-plaintext highlighter-rouge">SpecFromIterNested</code>.</p>

<p><a href="https://github.com/rust-lang/rust/blob/c58a5da7d48ff3887afe4c618dc04defdee3dab5/library/alloc/src/vec/spec_from_iter_nested.rs"><code class="language-plaintext highlighter-rouge">SpecFromIterNested</code></a> in turn has two implementations, one for general iterators and one for <code class="language-plaintext highlighter-rouge">TrustedLen</code> iterators (the relevant case here). However, the implementations are pretty much what you would expect. It just reserves a capacity equal to the iterator’s <code class="language-plaintext highlighter-rouge">size_hint</code>, with no sign of anything that could result in excess capacity.</p>

<p>I also checked the Vec allocation code and confirmed that it only grows the buffer by 2x each time.</p>

<h1 id="logging-before-and-after">Logging before and after</h1>

<p>Having reached a dead end in the source code, I tried adding logging to my code (and commenting out the <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> again) to see how bad the problem was. I logged the length and capacity of the edge lists before and after the final <code class="language-plaintext highlighter-rouge">into_iter().map().collect()</code> step, as well as a cumulative total of the length and capacity. (<code class="language-plaintext highlighter-rouge">get_cull_all</code> here is the function that calculates the edge lists, while <code class="language-plaintext highlighter-rouge">main_edges</code> is the final list of edge lists.)</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="nf">get_cull_all</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">max_denom</span> <span class="k">as</span> <span class="nb">u128</span><span class="p">,</span> <span class="n">optimistic</span><span class="p">);</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"precol {} {}"</span><span class="p">,</span> <span class="n">res</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">res</span><span class="nf">.capacity</span><span class="p">());</span>

<span class="k">let</span> <span class="k">mut</span> <span class="n">res</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">res</span>
    <span class="nf">.into_iter</span><span class="p">()</span>
    <span class="nf">.map</span><span class="p">(|(</span><span class="n">ds2</span><span class="p">,</span> <span class="n">p</span><span class="p">)|</span> <span class="p">(</span><span class="n">cull_map</span><span class="nf">.get</span><span class="p">(</span><span class="n">ds2</span><span class="p">),</span> <span class="n">p</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">))</span>
    <span class="nf">.collect</span><span class="p">();</span>

<span class="n">main_len_tot</span> <span class="o">+=</span> <span class="n">res</span><span class="nf">.len</span><span class="p">();</span>
<span class="n">main_cap_tot</span> <span class="o">+=</span> <span class="n">res</span><span class="nf">.capacity</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"{} {} tot {} {}"</span><span class="p">,</span> <span class="n">res</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">res</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">main_len_tot</span><span class="p">,</span> <span class="n">main_cap_tot</span><span class="p">);</span>
<span class="c1">// res.shrink_to_fit();</span>
<span class="nd">assert!</span><span class="p">(</span><span class="n">main_edges</span><span class="nf">.len</span><span class="p">()</span> <span class="o">==</span> <span class="n">id</span><span class="p">);</span>
<span class="n">main_edges</span><span class="nf">.push</span><span class="p">(</span><span class="n">res</span><span class="p">);</span>
</code></pre></div></div>

<p>This produced output like</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>precol 46 11400
46 34200 tot 10410429 2330729253
precol 54 11340
54 34020 tot 10410483 2330763273
precol 2 5520
2 16560 tot 10410485 2330779833
</code></pre></div></div>

<p>The cumulative wasted space up to 300k nodes was 2330779833/10410485 or over <strong>223x</strong> wasted space. This also confirmed that the edge lists had significant excess capacity following the <code class="language-plaintext highlighter-rouge">collect()</code> calls. In fact, the capacity of the new vec produced by <code class="language-plaintext highlighter-rouge">collect()</code> was always exactly three times the capacity of the original vec, regardless of length.</p>

<h1 id="playground">Playground</h1>

<p>Having confirmed that <code class="language-plaintext highlighter-rouge">collect()</code> was somehow producing vecs with excess capacity despite this seemingly being impossible per the source code, I next tried to reproduce the issue on the Rust playground. I wasn’t able to reproduce the 3x increases that I experienced in my code, but I did notice something interesting.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">v</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">];</span>
<span class="n">v</span><span class="nf">.push</span><span class="p">(</span><span class="mi">4</span><span class="p">);</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">());</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">());</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.iter</span><span class="p">()</span><span class="nf">.copied</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">());</span>    
</code></pre></div></div>

<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=547a67d6857b726120f73e03efd703ed">Running this</a> prints out</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>len 4 cap 6
len 4 cap 6
len 4 cap 4
</code></pre></div></div>

<p>So the vecs do have excess capacity here, even on the playground, although only a little bit. Furthermore, the excess capacity goes away if you use <code class="language-plaintext highlighter-rouge">iter().copied()</code> instead of <code class="language-plaintext highlighter-rouge">into_iter()</code>. Unfortunately, that part sidetracked me for a while, because I thought the <code class="language-plaintext highlighter-rouge">IntoIter</code> specialization of <code class="language-plaintext highlighter-rouge">SpecFromIter</code> might be related. It <em>shouldn’t</em> be, because the iterator here is <code class="language-plaintext highlighter-rouge">Map&lt;IntoIter&gt;</code> rather than <code class="language-plaintext highlighter-rouge">IntoIter</code> itself, but I couldn’t see anything else related and spent a long time staring at the source code, willing an answer to materialize.</p>

<p>Since the original issue didn’t show up on the playground, I thought it might be version-specific. In my own code, I was using the nightly compiler so I could use <code class="language-plaintext highlighter-rouge">Vec::is_sorted</code>, but fortunately, I was just using that for a couple asserts, so after commenting those out, I was able to switch to the beta compiler (1.76), where the exact same behavior occurred. As for stable, I was unable to try stable (1.74) because of compiler errors due to an unrelated issue with <code class="language-plaintext highlighter-rouge">impl Trait</code>. (As it turned out, the issue is only present in beta and not stable, so this was an unfortunate miss.) I also confirmed that the issue reproduced in non-release builds, so it wasn’t optimization related.</p>

<h1 id="vec-type-changes">Vec type changes</h1>

<p>I continued attempting to narrow down and reproduce my issue on the playground. After some more trial and error, I discovered that mapping a vec to a <em>smaller</em> type resulted in excess capacity, even on the playground, but <em>only</em> on beta and nightly, not stable.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">v</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">];</span>
<span class="n">v</span><span class="nf">.push</span><span class="p">(</span><span class="mi">1u128</span><span class="p">);</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {} v={:?}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">v</span><span class="p">);</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span> <span class="k">as</span> <span class="nb">u64</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {} v={:?}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">v</span><span class="p">);</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {} v={:?}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">v</span><span class="p">);</span>  
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span> <span class="k">as</span> <span class="nb">u8</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {} v={:?}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">v</span><span class="p">);</span>  
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span> <span class="k">as</span> <span class="nb">u16</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"len {} cap {} v={:?}"</span><span class="p">,</span> <span class="n">v</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">v</span><span class="nf">.capacity</span><span class="p">(),</span> <span class="n">v</span><span class="p">);</span>     
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>len 5 cap 8 v=[1, 2, 3, 4, 1]
len 5 cap 16 v=[1, 2, 3, 4, 1]
len 5 cap 32 v=[1, 2, 3, 4, 1]
len 5 cap 128 v=[1, 2, 3, 4, 1]
len 5 cap 5 v=[1, 2, 3, 4, 1]
</code></pre></div></div>

<p>Furthermore, the capacity increased proportionately to the type size reduction. In this example, going from <code class="language-plaintext highlighter-rouge">u128</code> to <code class="language-plaintext highlighter-rouge">u64</code> to <code class="language-plaintext highlighter-rouge">u32</code>, etc. doubles the capacity each time. On the other hand, <em>increasing</em> the type size as in the last example (<code class="language-plaintext highlighter-rouge">u8</code> -&gt; <code class="language-plaintext highlighter-rouge">u16</code>) immediately removes the excess capacity.</p>

<h1 id="allocation-reuse">Allocation reuse</h1>

<p>Since the capacity was increasing in proportion to the decrease in element size, that implied that the size of the backing array for the new vec was suspiciously the same as that of the old vec. I hypothesized that it was somehow reusing the memory from the old vec as an optimization. This also explains why it only happens with <code class="language-plaintext highlighter-rouge">into_iter()</code> and why using <code class="language-plaintext highlighter-rouge">iter().copied()</code> eliminates the excess capacity. When using <code class="language-plaintext highlighter-rouge">iter()</code>, the old vec isn’t dropped, and so its memory can’t be reused. In my code, the last step prior to insertion maps the edge lists from <code class="language-plaintext highlighter-rouge">(u64, u128)</code> to <code class="language-plaintext highlighter-rouge">(u32, u32)</code>, which is a third the size, hence why the capacity always increased by 3x after the conversion.</p>

<p>The other thing this implied is that while <code class="language-plaintext highlighter-rouge">collect()</code> was tripling the capacity of the vec, the actual memory use was unchanged, which meant that <code class="language-plaintext highlighter-rouge">collect()</code> alone wasn’t the cause of the memory leak. Rather, it was merely <em>failing to decrease</em> the existing memory usage. In order to understand how this could have exploded the process memory usage, a bit of explanation of my code is in order.</p>

<p>My edge list calculation logic internally uses <code class="language-plaintext highlighter-rouge">u128</code> for increased precision before truncating the weights to <code class="language-plaintext highlighter-rouge">u32</code> at the end. Furthermore, in some cases, it generates a list of potential edges and then filters out most of them prior to returning, which leads to a large amount of excess capacity. As an extreme example, the last iteration in the log output shown above had a length of 2 but a capacity of 5520.</p>

<p>Ordinarily, that wouldn’t have been a problem, since the <code class="language-plaintext highlighter-rouge">into_iter().map().collect()</code> line used to pack them into <code class="language-plaintext highlighter-rouge">(u32, u32)</code>s would allocate a new vector with only the exact amount of space required. However, thanks to the allocation reuse optimization added in Rust 1.76*, the new vec shared the backing store of the input vec, and hence had a capacity of 16560, meaning it was using 132480 bytes of memory to store only 16 bytes of data.</p>

<p>Since the edge list calculation logic is run for one node at a time in sequence, the fact that it temporarily uses 132kb of memory would normally not be a problem at all. However, the new <code class="language-plaintext highlighter-rouge">collect()</code> optimization meant that that internal storage was being preserved in the final vec which got inserted into the list of edge lists, thus keeping around that 132kb of obsolete memory forever. Multiply that by 300k nodes and suddenly you’ve leaked the computer’s entire RAM.</p>

<p>* <em>Technically, Rust will sometimes reuse the allocation even on stable, as shown by the initial len=4,cap=6 example on the playground. Rust 1.76 merely made the optimization smarter so it triggers in more cases.</em></p>

<h1 id="the-source-code">The source code</h1>

<p>Now that I knew I was looking specifically for a commit added in Rust 1.76, it wasn’t hard to look through the recent changes to the <code class="language-plaintext highlighter-rouge">Vec</code> source code on Github and find <a href="https://github.com/rust-lang/rust/commit/13a843ebcbe536257a8442bf5c26b227d1c2f7c9">the likely culprit</a>. It turns out that there’s <a href="https://github.com/rust-lang/rust/blob/c58a5da7d48ff3887afe4c618dc04defdee3dab5/library/alloc/src/vec/in_place_collect.rs">an entire 412 line file dedicated to implementing this optimization</a> that I overlooked previously.</p>

<p>How was this possible? One of the more annoying features of Rust is that Trait impls can be added <em>anywhere in the same crate</em>, not just in the files where you would logically expect them to be, and there’s no way to find hidden impls other than doing a full code search.</p>

<p>In this case, the <code class="language-plaintext highlighter-rouge">SpecFromIter</code> trait was defined in <a href="https://github.com/rust-lang/rust/blob/c58a5da7d48ff3887afe4c618dc04defdee3dab5/library/alloc/src/vec/spec_from_iter.rs">spec_from_iter.rs</a>, along with two implementations of that trait, so I naturally assumed that that was all the implementations there were. I had no way to guess that there was actually a <em>third</em> implementation that was hidden in a completely different file (in_place_collect.rs).</p>

<p>Technically speaking, there was one slight hint. <code class="language-plaintext highlighter-rouge">spec_from_iter.rs</code> contains the following comment:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">/// Specialization trait used for Vec::from_iter</span>
<span class="cd">///</span>
<span class="cd">/// ## The delegation graph:</span>
<span class="cd">///</span>
<span class="cd">/// ```text</span>
<span class="cd">/// +-------------+</span>
<span class="cd">/// |FromIterator |</span>
<span class="cd">/// +-+-----------+</span>
<span class="cd">///   |</span>
<span class="cd">///   v</span>
<span class="cd">/// +-+-------------------------------+  +---------------------+</span>
<span class="cd">/// |SpecFromIter                  +----&gt;+SpecFromIterNested   |</span>
<span class="cd">/// |where I:                      |  |  |where I:             |</span>
<span class="cd">/// |  Iterator (default)----------+  |  |  Iterator (default) |</span>
<span class="cd">/// |  vec::IntoIter               |  |  |  TrustedLen         |</span>
<span class="cd">/// |  SourceIterMarker---fallback-+  |  +---------------------+</span>
<span class="cd">/// +---------------------------------+</span>
<span class="cd">/// ```</span>
</code></pre></div></div>

<p>This comment lists the two impls found in the file as well as a seemingly missing third impl for “SourceIterMarker”. I actually did try googling “SourceIterMarker” at one point, but the only thing that came up was <em>that same comment in spec_from_iter.rs</em>, and since there was no sign of a third impl in the file, I assumed that it was just a mistake or outdated comment. In retrospect, I should have done a full code search for “SourceIterMarker” on Github, just in case it had sneakily been hidden in a separate file.</p>

<h1 id="boxt">Box&lt;[T]&gt;</h1>

<p>As mentioned previously, adding a call to <code class="language-plaintext highlighter-rouge">shrink_to_fit()</code> prior to storing the edge lists in the final graph eliminated the memory leak issue. This is fine as a quick hack, but it is not the proper solution. The <em>real</em> fix is to call <code class="language-plaintext highlighter-rouge">into_boxed_slice()</code> instead.</p>

<p>The basic problem is that <code class="language-plaintext highlighter-rouge">Vec</code>s are optimized for the case of a <em>mutable</em> list where you’re planning to <em>add and remove</em> elements in the future. However, people also commonly use them for <em>fixed-length</em> list data, even though this is not what Vecs are designed for, simply because Vec is the easiest and most <em>intuitive</em> way to store list data in Rust. The <em>proper</em> data structure for fixed-length lists is <code class="language-plaintext highlighter-rouge">Box&lt;[T]&gt;</code> rather than <code class="language-plaintext highlighter-rouge">Vec&lt;T&gt;</code>, but it takes a lot of Rust experience to even <em>know</em> about that as an option, and the syntax looks weirder.</p>

<p>In Java, immutable strings are called <code class="language-plaintext highlighter-rouge">String</code> while mutable strings (the equivalent of Rust’s <code class="language-plaintext highlighter-rouge">String</code>) are called <code class="language-plaintext highlighter-rouge">StringBuilder</code> instead. This nudges people towards the appropriate behavior because you would look really foolish if you stored something named “StringBuilder” in long-term immutable data structures. Meanwhile in Rust, almost nobody uses <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code> over <code class="language-plaintext highlighter-rouge">String</code>.</p>

<p>Of course, I’m not saying that Rust should have called <code class="language-plaintext highlighter-rouge">Vec</code> “ListBuilder” or anything. Mutable array lists are an <strong>extremely</strong> commonly needed component of algorithms and data structures, so it’s important to keep the name short and memorable. It’s just a little unfortunate that a side effect of Rust’s design nudges people towards <em>also</em> using <code class="language-plaintext highlighter-rouge">Vec</code> even for fixed-length data.</p>

<p>As it turns out, I actually was already using <code class="language-plaintext highlighter-rouge">Box&lt;[T]&gt;</code> for the saved results in one of the functions where I used memoization. My main motivation was to avoid wasting an extra word to store capacity on the <em>value</em> side, but as a side effect, this conveniently also made it immune to any potential excess capacity bugs. (The other place where I used memoization did just use <code class="language-plaintext highlighter-rouge">Vec</code>s out of laziness, but fortunately it didn’t end up mattering much there.)</p>

<h1 id="packed-arrays">Packed arrays</h1>

<p>Another possible optimization which I plan to try out later is to avoid storing separate lists in the first place. Instead, have a single “arena” Vec and store the data for <em>all</em> the lists <em>continguously</em> in that Vec and just pass around an (index, length) pair into that vec instead of real <code class="language-plaintext highlighter-rouge">Vec</code>/<code class="language-plaintext highlighter-rouge">Box&lt;[]&gt;</code>, etc.</p>

<p>This design is only sometimes usable (you can’t free or pass around individual lists independently of the arena vec this way) and is much more intrusive in terms of code design (you have to somehow pass a reference to the arena vec through all your code). However, in addition to making you automatically immune to excess capacity bugs, it also avoids the potential memory fragmentation issue that having lots of little individually allocated lists could cause. Additionally, it lets you represent your lists as only <code class="language-plaintext highlighter-rouge">(u32, u32)</code> assuming the total length is less than 2³², a 2x saving on the value side as well, albeit at the cost of increased bounds checks.</p>

<p>This trick has limited applicability, but it is perfect for cases like memoization (where the results live forever and are stored in a single place) or the edge list of a graph data structure (where you can store the backing vec as part of the graph) assuming you don’t need to add or remove edges after creation.</p>

<h1 id="conclusion">Conclusion</h1>

<p>This was a surprising and annoying bug to investigate, but at least I learned a lot about Rust in the process. I had no idea that the standard library was doing this kind of optimization under the hood (and since this is code-based, it happens even in debug builds). It’s also an illustration of how an optimization in one place can lead to bugs downstream by violating programmers’ expectations.</p>

<p>Anyway, I hope that writing about my experience can help other people avoid this footgun in the future, or at least teach people something interesting about Rust.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Over the weekend, I was working on a personal Rust project when I ran into an excessive memory usage problem. After an evening of trial and error, I found a workaround to fix the memory usage, but I still didn’t understand how the issue was even possible, so I then spent another evening digging through the source code of the Rust standard library to understand the root cause.]]></summary></entry><entry><title type="html">How I came second out of 999 in the Salem Center prediction market tournament without knowing anything about prediction markets, and what I learned along the way - Part 2</title><link href="/2023/08/28/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-2.html" rel="alternate" type="text/html" title="How I came second out of 999 in the Salem Center prediction market tournament without knowing anything about prediction markets, and what I learned along the way - Part 2" /><published>2023-08-28T00:58:00+00:00</published><updated>2023-08-28T00:58:00+00:00</updated><id>/2023/08/28/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-2</id><content type="html" xml:base="/2023/08/28/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-2.html"><![CDATA[<style>
blockquote {font-style: initial;}
blockquote em {font-style: italic;}
</style>

<p>Last August, the Salem Center at the University of Texas <a href="https://www.cspicenter.com/p/introducing-the-salemcspi-forecasting">announced a year-long prediction market tournament</a> in partnership with the Center for the Study of Partisanship and Ideology in an attempt to find people who are good at predicting the future. Despite having absolutely no experience with prediction markets, I decided to give it a try and amazingly managed to place second out of nearly a thousand participants.</p>

<p>This post is divided into two parts. The <a href="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html">first part</a> begins with a brief description of how the tournament worked, then the overall lessons I learned while participating in the contest. The second part (what you’re reading) is a detailed chronological account of the contest from my perspective, explaining the notable events and how my strategy changed over time.</p>

<p>To avoid hindsight bias and show what I was thinking at the time, this post is largely composed of all the journal entries I wrote about the Salem contest over the last year. Warning, I wrote a <strong>lot</strong> about the contest during the periods when I was most actively participating, and as a result, this post will be <em>very</em> long.</p>

<blockquote>
  <p>Quotes from my journal will look like this,</p>
</blockquote>

<p>While after-the-fact notes look like this. For the first two and a half months, I didn’t even mention the contest in my journal at all, so I’ve described what happened after the fact like this. I’ve also added graphs for each month (or half month), showing how the positions changed over that period.</p>

<h1 id="august">August</h1>

<p>The contest began on August 7th (first non-Salem Center bet was at 06:02:59), but I didn’t find out about the contest until August 16th, after seeing it <a href="https://astralcodexten.substack.com/p/mantic-monday-81522">mentioned on the blog Astral Codex Ten</a>. At the time, I had absolutely no experience with prediction markets or Manifold, but figured I should give it a try and see if I can win anyway.</p>

<p>When I joined, I assumed that I would discover a clever hack to shoot to the top, or perhaps write a high-frequency trading bot or something, since it seemed unlikely that I’d win playing normally. But for the time-being, I had to make my initial bets.</p>

<h2 id="initial-bets-aug-16">Initial bets (Aug 16)</h2>

<p>The only market I had an obvious edge in was “Will Elon Musk Buy Twitter?”. From months of reading Matt Levine, I was convinced that Musk would be forced to acquire Twitter, but the market was only trading at 45.6%. (And before anyone asks, no I did not buy any real-money Twitter stock.)</p>

<p>However, <a href="https://www.cspicenter.com/p/introducing-the-salemcspi-forecasting">the contest rules</a> said that you had to “spend at least $50 on each of 20 different markets”. Therefore, I foolishly split the starting $1000 by betting $50 each on 20 different markets, even though I only had a strong contrarian opinion on one. In retrospect, I should have put everything on Twitter, and then if/when I won, I would have had plenty of money to spare and could easily put $50 on 19 other markets later with the winnings, but I didn’t think of that until later.</p>

<p>I didn’t bother trying to find undervalued markets, and ignored the market prices and just bet on whichever outcome I thought was most likely in each market. For the ones I didn’t know anything about, I spent a couple minutes at most researching each market.</p>

<p>However, I did put a <em>little</em> strategy into my choices. Specifically, I chose most of the markets that would be resolving earlier than the Musk Twitter market, reasoning that I could reinvest my winnings into Twitter for additional profit. For the rest, I focused primarily on the markets that would be resolving earliest, though I did bet on a few longer term markets that seemed more interesting.</p>

<p>Here were my initial 20 bets:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-08-16 12:12:14 Will Elon Musk Buy Twitter?
  $50 for 102.323 YES shares (market price 45.62% -&gt; 46.93%)
2022-08-16 12:13:53 Biden at 40% Approval on Labor Day Weekend?
  $50 for 67.950 YES shares (market price 71.21% -&gt; 71.81%)
2022-08-16 12:14:58 Republicans Favored in Senate on Labor Day Weekend?
  $50 for 61.737 NO shares (market price 20.87% -&gt; 20.47%)
2022-08-16 12:16:11 US GDP Growth 1% or More in 2022 Q3?
  $50 for 137.790 NO shares (market price 66.89% -&gt; 65.25%)
2022-08-16 12:22:38 Will Russia control Kherson on 10/31/22?
  $50 for 75.707 YES shares (market price 63.20% -&gt; 64.16%)
2022-08-16 12:23:59 Over 100,000 Monkeypox Cases in 2022?
  $50 for 114.178 NO shares (market price 59.60% -&gt; 57.88%)
2022-08-16 12:24:57 Biden Cancels Student Debt in 2022?
  $50 for 77.816 NO shares (market price 38.65% -&gt; 37.68%)
2022-08-16 12:26:25 Will Donald Trump Be Indicted for a Crime in 2022?
  $50 for 85.407 NO shares (market price 44.52% -&gt; 43.48%)
2022-08-16 12:27:52 Will Russia Control Kramatorsk on 12/31/22?
  $50 for 88.098 NO shares (market price 46.39% -&gt; 45.23%)
2022-08-16 12:29:19 COVID Falls Below 20,000 Cases in 2022?
  $50 for 244.537 YES shares (market price 17.85% -&gt; 19.82%)
2022-08-16 12:33:38 Will Republicans Win Michigan 3rd District?
  $50 for 82.751 NO shares (market price 42.59% -&gt; 41.58%)
2022-08-16 12:34:24 Will Trump Announce in 2022?
  $50 for 110.999 NO shares (market price 58.19% -&gt; 56.83%)
2022-08-16 12:35:14 Will Republicans Win the Senate?
  $50.0 for 79.949 NO shares (market price 39.68% -&gt; 39.00%)
2022-08-16 12:35:36 Will Republicans Win the Senate in Ohio?
  $50 for 62.870 YES shares (market price 77.45% -&gt; 78.12%)
2022-08-16 12:36:44 US GDP Growth over 4% in any Quarter 2022?
  $50 for 63.458 NO shares (market price 23.56% -&gt; 22.40%)
2022-08-16 12:37:09 Russia Annex Territory in 2022?
  $50 for 100.236 NO shares (market price 53.35% -&gt; 52.08%)
2022-08-16 12:37:41 Will Republicans win the House of Representatives?
  $50 for 69.889 YES shares (market price 68.83% -&gt; 69.95%)
2022-08-16 12:38:52 Will Republicans Win the Senate in Arizona?
  $50 for 76.913 NO shares (market price 37.83% -&gt; 36.96%)
2022-08-16 12:39:59 Republicans Favored by Summer 2023?
  $50.0 for 121.577 NO shares (market price 61.68% -&gt; 60.36%)
2022-08-16 12:40:38 Will Donald Trump Be Indicted for a Crime by July 2023?
  $50 for 107.675 NO shares (market price 56.79% -&gt; 55.48%)
</code></pre></div></div>

<p>The whole process only took 28 minutes, and then there was nothing left to do but wait and hope my genius was rewarded and they all magically came up in my favor.</p>

<h2 id="first-blood-aug-24">First blood (Aug 24)</h2>

<p>Spoiler: They didn’t. On August 24th, the first market resolved, “Biden Cancels Student Debt in 2022?”. I didn’t expect him to actually cancel student debt, so I lost my first $50 there.</p>

<h2 id="early-chaos">Early chaos</h2>

<p>After my initial 20 bets, I didn’t make any more trades on Salem until September. However, I did come across comments talking about the chaos in the first few days of the contest (before I started).</p>

<p>As it turns out, at the start of the contest, the markets had extremely low liquidity, which, combined with a rush of inexperienced players who didn’t understand the inner workings of Manifold, led to chaos as people would come in and bet large amounts on a market and the market price would swing it up to 99% or below 1% due to the lack of liquidity.</p>

<p><img src="https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c7de71a-0a8f-4870-b35c-7d4ff3d0ff89_727x531.png" /></p>

<p>Here you can see that the “Chinese Military Action against Taiwan?” market swung up to 99.0% on the second day of the contest. The only reason it stopped at 99.0% is because one savvy player had put a limit order at 99.0% in order to profit from just such a mistake. This led to massive profits for the few players who were able to exploit the wild price swings of the first few days.</p>

<p>As a result <a href="https://www.cspicenter.com/p/salem-tournament-5-days-in">Salem did two things</a>. First, they increased the liquidity pool for each market from $100 to $2000. Roughly speaking, this means that any given trade would move the market by 1/20th as much as before.</p>

<p>Additionally, they announced that they would subtract out first-day gains from player’s scores for the purposes of rankings on the leaderboard. Players who managed to “unfairly” profit from the early chaos would still have an advantage, because they would have a lot more money to invest, making it much easier to gain more money in the future. However, the fixed score adjustment would at least give players who weren’t there early and didn’t luck out a fighting chance.</p>

<p>This all happened before I even heard about the contest, and I was a bit disheartened when I found out about it, since it seemed like I had missed my chance and the contest would be decided by who was in the right place at the right time in the first few days.</p>

<h2 id="august-standings">August standings</h2>

<p>Here’s a graph of my score and rank over the course of August. My score varied from a low of 941.9 to a high of 1044.0 and is plotted on the left axis, while my rank varied from 32nd to 445th and is plotted on the right axis.</p>

<p><img src="/img/salem2/aug.png" alt="Graph of my score and rank in August" /></p>

<p>Since I didn’t actually make any bets in August after I started, all this variation is due to market movement over time changing my “portfolio value” at market prices. You can, however, see a big dip on August 24th, when I lost on the student debt cancellation market.</p>

<h1 id="september">September</h1>

<p><img src="/img/salem2/sept.png" alt="Graph of my score and rank in September" /></p>

<p>September was quiet, and went pretty much the same as August, with my balance jumping around randomly due to market movements.</p>

<p>The one notable event came on September 2nd, when the next two markets resolved in my favor (“Republicans Favored in Senate on Labor Day Weekend?” and “Biden at 40% Approval on Labor Day Weekend?”), and I duly reinvested the winnings in the Twitter Acquisition market.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-09-02 21:21:58 Will Elon Musk Buy Twitter?
  $129 for 307.863 YES shares (market price 37.66% -&gt; 41.28%)
</code></pre></div></div>

<p>Conveniently, the market price was now down to 37.66%, even lower than my initial purchase in mid-August.</p>

<p>There was actually a third market that also resolved on September 2nd, “Over 400,000 Jobs in August?”, but I didn’t know that at the time, since I never bet on that market and hence didn’t get an email about the resolution.</p>

<h1 id="october">October</h1>

<p><img src="/img/salem2/oct.png" alt="Graph of my score and rank in October" /></p>

<p>October began with another bit of bad news when “Russia Annex Territory in 2022?” resolved YES on October 3rd. I couldn’t believe that Putin would formally annex more of Ukraine, and thus lost my $50 there.</p>

<p>I didn’t know it at the time, due to only checking Salem when I got a market resolution email, but there was a huge jump in my score and rank the next morning on October 4th as the Twitter Acquisition market suddenly went from 48.1% to 84.6%.</p>

<h2 id="october-27th">October 27th</h2>

<p>The next two market resolutions came on October 27th. (Or rather, the next two resolutions <em>for me</em>. “Fewer than 300,000 Jobs Any Month in 2022?” resolved on October 6th, but I wasn’t in that market.)</p>

<p>The first, “US GDP Growth 1% or More in 2022 Q3?” went against me, as at the time I was pessimistic about the economy at the time and bet NO. Then came the important market, “Will Elon Musk Buy Twitter?”, where I made my first big profit.</p>

<p>I wasn’t sure what to do next, so for the time being, I just reinvested all my money in “Will Russia control Kherson on 10/31/22?”. I noticed that it was still only at 89%, despite the fact that it would be resolving in just 3-4 days, and after the months of slow progress in Kherson, I couldn’t imagine anything changing overnight, so it seemed like safe, easy money to me.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-10-27 18:25:49 Will Russia control Kherson on 10/31/22?
  $410 for 453.868 YES shares (market price 88.86% -&gt; 89.97%)
</code></pre></div></div>

<p>This was the first of several markets I invested in which seemed like safe short term bets to earn a little bit of extra money, which I thought of almost like an “interest rate”.</p>

<h1 id="november-1-15">November 1-15</h1>

<p>The first two and a half months of the contest were very quiet for me, but everything changed in early November.</p>

<p><img src="/img/salem2/nov.png" alt="Score graph" /></p>

<h2 id="initial-plans">Initial plans</h2>

<p>By late October, I had grown alarmed at how much time and thought I was devoting to the Salem contest when I was unlikely to actually have any chance of winning. At the time, I had no idea what my rank was or how far away the top players were, but I assumed they were significantly higher, and thus that I’d have to double my money to even have a shot at the leaderboard.</p>

<p>Therefore, I came up with a plan. I would bet everything on Democrats in the midterms, and either lose everything, in which case I would stop participating in the contest and stop wasting my time, or else win big and thus hopefully be a serious contender in the contest.</p>

<p>However, for the time being, I invested my free money in one last “risk-free” market for a quick 10% return, “Biden at 40% Approval on Election Day?”, which would conveniently be resolving the morning of election day, just in time for me to bet on the midterms.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-10-31 22:18:12 Biden at 40% Approval on Election Day?
  $530 for 587.881 YES shares (market price 88.49% -&gt; 89.96%)
</code></pre></div></div>

<h2 id="election-day-november-8th">Election day (November 8th)</h2>

<p>At 06:53 on November 8th (morning of Election Day), right before I made my election bets, my score (portfolio value at market prices) was up to $1252.69, a 25% gain over the starting $1000. I didn’t know it at the time, but I was in 74th place, with 1st place at $5554 and 20th place at $1603.</p>

<p>The final “deluxe” forecast from 538 gave Republicans a 59% chance to win the Senate. (It later turned out that <a href="https://fivethirtyeight.com/features/how-a-data-processing-error-changed-our-deluxe-forecast/">there was a minor data error</a> with the Deluxe model, and it would have given Republicans 55% using the correct data, but noone knew that at the time.)</p>

<p>However, prediction markets were much more bullish on Republicans than 538, and Salem was no exception, with Republicans at 73.4% to win the Senate at the time. I had heard that prediction markets long had a noticeable pro-Republican bias, as most vividly demonstrated by the fact that they gave Trump a significant chance of winning in 2020 <em>even after Biden had been sworn in as president</em>.</p>

<p>I’d read Richard Hanania’s <a href="https://www.richardhanania.com/p/the-problem-with-polling-might-be">The Problem with Polling Might Be Unfixable</a>, which argued that polls might have a systematic pro-Democrat bias that is impossible to correct for. It seemed plausible, given that Trump outperformed the polls in 2016 and 2020, and even in 2018, when the polls were spot-on overall, Democrats lost a lot of close Senate races. I didn’t think that that conclusion could really be drawn from just two data points, when there is so much noise and when pollsters are constantly adjusting their methods to attempt to correct for identified bias. But the argument seemed plausible, and I figured if it happened a <em>third</em> time, it would be looking pretty good.</p>

<p>On the other hand, there were also reasons to think that 538 might be <em>underestimating</em> the Democrats’ chances. I’d been following Paul Krugman on Twitter, who argued that Biden’s approval ratings had been closely tracking gas prices up and down.</p>

<p>With gas prices falling in late October, a continuation of this trend would presumably lead to a steady increase in Democratic support, and since polls are a lagging indicator, that would imply that the polls were slightly underestimating Democrats. (As it turns out, it appears that gas prices ticked <em>up</em> slightly in the week before the election). But overall, I didn’t really know much, and figured that 538’s estimate was the best predictor, or perhaps slightly more to account for the chance of Hanania being right.</p>

<p>As it turns out, I was actually right about the prediction markets being heavily biased towards Republicans, but it’s not like I can really pretend to have called this. After all, if you think something has a 60% chance of happening and the market price is at 73%, that’s still normally not a reason to go all in on NO. And I did go to bed thinking Republicans were more likely to win than not.</p>

<p>The real <em>main</em> reason I went all in on Democrats is that I <em>already</em> had some small bets on them, and so it made sense to double down. (And of course, the odds were <em>much</em> better as well - there wasn’t much money to be made betting on Republicans anyway!)</p>

<p>Back in mid-August when I started the contest, things were looking good for the Democrats, and thus when I placed my initial $50 bets, I bet on Democrats in nearly every midterm contest (I did still have Republicans to take the House of Representatives and the Ohio Senate seat.) By late October, the polls had reversed, and if I had started in October rather than August, I probably would have bet on the Republicans instead. But fortunately, that didn’t happen.</p>

<p>Anyway, I sold all my initial $50 bets that weren’t already invested in the various midterm markets, and combined with the winnings from Twitter and the Kherson/Approval “interest”, I had $997 in free cash to invest.</p>

<p>I decided to split my big bet between two markets in an attempt to reduce slippage, and chose “Will Republicans Win the Senate?” and “Will Republicans Win the Senate in Nevada?”, since based on the coverage I’d read, I thought that Nevada was the individual race where Democrats had the best chances. (I was particularly worried about Fetterman’s chances, which turned out to be the opposite of correct.)</p>

<p>At the time, I had no idea how the liquidity or market making worked. I didn’t know anything about Manifold’s automated market making algorithm, and assumed that the markets just functioned based on crossing orders with people betting the other way somehow. I guessed that liquidity would be roughly proportional to the “total amount bet” display and initially tried to split the bets proportionately, but then gave up on that and split the money roughly equally, $522 on the Senate and $475 on Nevada.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-11-08 06:53:48 Will Donald Trump Be Indicted for a Crime by July 2023?
  $-40.1908112464 for -107.675 NO shares (market price 59.59% -&gt; 60.85%)
2022-11-08 06:54:02 Republicans Favored by Summer 2023?
  $-46.261929156 for -121.577 NO shares (market price 58.69% -&gt; 60.29%)
2022-11-08 06:54:10 US GDP Growth over 4% in any Quarter 2022?
  $-53.8043951876 for -63.458 NO shares (market price 13.66% -&gt; 14.16%)
2022-11-08 06:55:04 COVID Falls Below 20,000 Cases in 2022?
  $-29.8252755891 for -244.537 YES shares (market price 13.90% -&gt; 12.76%)
2022-11-08 06:55:18 Will Russia Control Kramatorsk on 12/31/22?
  $-65.4022055518 for -88.098 NO shares (market price 23.49% -&gt; 24.13%)
2022-11-08 06:55:28 Will Donald Trump Be Indicted for a Crime in 2022?
  $-55.1746640661 for -85.407 NO shares (market price 32.60% -&gt; 33.49%)
2022-11-08 06:55:38 Over 100,000 Monkeypox Cases in 2022?
  $-101.981483177 for -114.178 NO shares (market price 9.60% -&gt; 9.84%)
2022-11-08 06:56:17 Will Trump Announce in 2022?
  $-16.7367339772 for -110.999 NO shares (market price 83.28% -&gt; 83.82%)
2022-11-08 06:59:15 Will Republicans Win the Senate?
  $522.0 for 1477.001 NO shares (market price 73.41% -&gt; 59.55%)
2022-11-08 07:00:11 Will Republicans Win the Senate in Nevada?
  $475 for 1261.301 NO shares (market price 70.93% -&gt; 57.39%)
</code></pre></div></div>

<p>Despite splitting my bet between two markets, they still moved the markets significantly (73-&gt;60% and 71-&gt;57%), and people quickly pushed the market price back up, so I could have gotten a lot better prices if I had split my bets up into multiple purchases and waited for the market price to bounce back in between. But of course I didn’t know that at the time, and wasn’t trying to put much effort into something I didn’t expect to pay off anyway.</p>

<p>… and then it was time to wait and forget about Salem and isolate myself from the news.</p>

<h2 id="election-night">Election night</h2>

<p>As usual, I completely avoided the news on election night and didn’t check the results until the following morning in order to minimize pointless stress. I also mentioned the Salem contest in my journal for the very first time:</p>

<blockquote>
  <p><strong>08.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:15</strong> - …I deliberately avoided the news this evening. I’m planning to check during the day tomorrow to avoid pointless angsting, since it’s not like we can do anything about it anyway other than just wait. I do know that Republicans won the senate in Ohio because the Salem Contest Manifold markets thing sent me an email about the market resolution, so that rules out a massive <em>blue</em> wave, but that’s it.</p>
</blockquote>

<p>Note: The first market to resolve that night was actually “Democratic Governor in Texas or Florida?”, but I didn’t bet on that one and hence didn’t get an email for it. Besides the Ohio Senate, the only other resolution email I got was “Will Republicans Win Michigan 3rd District?”, which resolved NO at 3:30am that night.</p>

<p>I didn’t know this at the time, but the first couple hours of results on election night were apparently favorable for Republicans, so it’s a really good thing I wasn’t following the results live. The Salem markets naturally swung R during this time, causing my score to reach a low of 843.6 and briefly sent me all the way down to 681st place, my lowest rank during the entire competition.</p>

<h2 id="november-9th">November 9th</h2>

<blockquote>
  <p><strong>09.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:08</strong> - … I also got another email from Salem saying that Republicans did not win the Michigan 3rd district.</p>
</blockquote>

<blockquote>
  <p><strong>09:19</strong> - … Anyway, with all the layoff drama, I figured I might as well go ahead and check in on the election results as well. Looks like things are very close, though Republicans still have a slight edge. But even the fact that it is close is a really good night for the Democrats. It was about the best that could be expected, given how dire things had been looking for the last month.</p>
</blockquote>

<p>When I finally checked in on Salem on Wednesday (the 9th), I kicked myself for not betting on Fetterman, as that market had already resolved overnight. But of course, there was no way to know that in advance.</p>

<p>The next mention of Salem in my journal wasn’t until the 12th, when I finally got around to describing it in detail and recounted pretty much the same history described here, as well as the post-election night bets:</p>

<blockquote>
  <p><strong>12.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:20</strong> - … Anyway, I should explain the Salem Center thing now. In early August, the Salem Center at the University of Texas launched a prediction market contest on Manifold. Everyone starts with $1000 of virtual money and can bet on various prediction markets. They’re looking for a new research fellow and said they would choose between the top 5 finishers of the contest.</p>
</blockquote>

<blockquote>
  <p>I found out about the contest on ACX and decided to give it a try just for fun. I don’t know much about prediction markets and didn’t plan to put much effort into it, but I figured I might as well try and maybe I’d manage to get into the top five anyway. Obviously, I don’t actually want the job, but I thought it would be cool if I won just for bragging rights.</p>
</blockquote>

<blockquote>
  <p>The original rules required you to spend at least $50 on 20 different markets in an attempt to prevent people from just getting lucky on one or two bets. Of course, they quickly changed the rules to be a lot more subjective, saying they would carefully consider everyone’s patterns of betting, etc. to avoid abuse of the system or people just getting lucky.</p>
</blockquote>

<blockquote>
  <p>Anyway, the only market I was really confident on that the market was seriously undervaluing was Musk to acquire Twitter, but I foolishly decided to just split the starting $1000 equally between 20 markets, just randomly betting on whichever side seemed most likely to me in each case, and planning to reinvest the proceeds of early resolving markets back into Twitter. In retrospect, I realized that I should have just put everything into Twitter, and then once I’d massively increased my bank roll, throwing 20 into 19 other markets would be a lot less onerous. Oh well.</p>
</blockquote>

<blockquote>
  <p>As it turns out, of the five markets to resolve pre-Twitter, I only won two (Biden approval 40+% on Labor Day - YES and Republicans favored in Senate on 538 on Labor Day - NO) and lost three (Biden Cancels Student Debt in 2022? - NO, US GDP Growth 1% or More in 2022 Q3? - NO, and Russia Annex Territory in 2022? - NO). So I was able to double down on Twitter, but not that much.</p>
</blockquote>

<blockquote>
  <p>After Twitter resolved, I reinvested into short term high probability bets to eke out a few extra bucks (first Will Russia control Kherson on 10/31/22? - YES, then Biden at 40% Approval on Election Day? - YES).</p>
</blockquote>

<blockquote>
  <p>When it resolved on Election Day morning, my “portfolio value” was up to around 1250-1280, but figured I had no chance of winning like that and that I might as well gamble everything on a risky bet, since I wasn’t going to win anyway otherwise. Therefore, I sold all my non-election related bets and split everything between NO on Will Republicans Win the Senate? and Will Republicans Win the Senate in Nevada?.</p>
</blockquote>

<blockquote>
  <p>I remember that I bought the latter from 71% down to 60%, but it almost immediately started going back up again (lots of people betting on election morning). All of the Salem markets were significantly more pro-R than even 538’s last forecast. I know other prediction markets were also more R leaning than 538, especially PredictIt, but PI has a notorious pro-R bias. At least it further increased the margins on my bets.</p>
</blockquote>

<blockquote>
  <p>As mentioned, two of my original bets (Will Republicans Win the Senate in Ohio? - YES and Will Republicans Win Michigan 3rd District? - NO) resolved on election night, but then nothing until Thursday night. Wednesday evening, I finally checked in on Salem again for the first time in a day and a half and saw that I was up to 2075, and in 15th place on the leaderboard.</p>
</blockquote>

<blockquote>
  <p>I was shocked, since I didn’t think that even doubling my money would be enough to get onto the leaderboard. Of course, I’m probably much farther from the top 5. In order to discourage people from gambling everything on risky bets to improve their ranking, the leaderboard does not actually show anyone’s value, just the names and ranking, and just for the top 20.</p>
</blockquote>

<blockquote>
  <p>I was tempted to sell to lock in my gains, but balked at the massive slippage it would entail, which is just as well. Instead, I just plowed the winnings from Michigan and Ohio into another sure-win market (Michigan Abortion Rights Landslide? (60+% of the vote) - NO) that hadn’t resolved yet for some reason (7% at the time) to earn a few extra bucks.</p>
</blockquote>

<blockquote>
  <p>After I got back from Safeway last night, I saw the first resolution since election night, (Will Republicans Win the Senate in Arizona?) and put the money into another sure-win, (Another Polling Miss in the Midwest and Pennsylvania?, aka 3+% pro-R average polling miss in midwest + PA), which was down to 4%, just like the Michigan abortion market.</p>
</blockquote>

<blockquote>
  <p>Anyway, the Michigan abortion and polling miss markets finally closed this morning, and there weren’t any sure-wins left, so I put the money into Nevada Senate (buying it from 10% down to 9%), as I realized that if I lose my big bets, I’m toast anyway, so I might as well double down. My portfolio value is currently up to $2916, and I’m now 12th on the leaderboard.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-11-09 19:24:53 Michigan Abortion Rights Landslide?
  $146 for 156.282 NO shares (market price 7.38% -&gt; 7.11%)
2022-11-11 20:31:14 Another Polling Miss in the Midwest and Pennsylvania?
  $77 for 80.017 NO shares (market price 4.20% -&gt; 4.14%)
2022-11-12 07:48:27 Will Republicans Win the Senate in Nevada?
  $236 for 259.092 NO shares (market price 10.14% -&gt; 9.41%)
</code></pre></div></div>

<blockquote>
  <p><strong>12.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>18:34</strong> - My big bets on Salem just resolved, leaving only one small bet (R to take house, ironically enough). Each market shows the top 5 bettors in total profit as well as a “proven correct” and “smartest money” listing with unclear methodology. I got “smartest money” in both.</p>
</blockquote>

<blockquote>
  <p>For Republicans to take Senate overall, it says “Robert Grosse bought S$522 of NO from 73% to 60% 4 days ago Robert Grosse made S$955!”, but then I’m listed in 4th under Top Bettors with a total profit of only $984 (first was John Gross-Whitaker with 1271). Presumably the discrepancy is because I also put $50 in back in August, which had gone down in value as the Rs rose in the polls. The “smartest money” section must be showing my total profit  <em>since the big bet on election day</em>, including the re-appreciation of the original 50, while the top bettors must be counting total money won from when the bet was placed, rather than Tuesday.</p>
</blockquote>

<p>Note: Smartest Money actually just shows the profit for the one specific bet that was chosen, so the initial $50 had nothing to do with it. And 955 &lt; 984 anyway. I’m not sure why I thought otherwise.</p>

<blockquote>
  <p>On the Nevada Senate market, the smartest money said “Robert Grosse bought S$475 of NO from 71% to 57% 4 days ago Robert Grosse made S$786!” (which incidentally shows that I didn’t quite remember the odds at time of my purchase correctly). Meanwhile I’m 2nd under Top Bettors with total profit $809 (First is David Hassett at 1566). Presumably this time, the total profit is higher because the smartest money isn’t counting the extra bit I put in last night? It’s interesting to try to reverse engineer what it is saying like that.</p>
</blockquote>

<blockquote>
  <p>Anyway, I’m now at 3134 portfolio value (3077 cash) and up to 10th in the rankings. John Gross-Whitaker is at 15th while David Hassett is up at 6th, which makes sense given his massive winnings in Nevada. Anyway, I’m planning to just leave things be for a while while I decide what to do next, since I actually have a good shot and there aren’t any easy wins left now that the elections are over.</p>
</blockquote>

<h2 id="november-13th">November 13th</h2>

<p>I didn’t notice this at the time, but I was briefly up to 9th place from 16:13 to 17:35 on the 13th. However, I ended the first half of the month in 11th place.</p>

<h1 id="november-16-30">November 16-30</h1>

<p><img src="/img/salem2/nov2.png" alt="Score graph" /></p>

<p>With Election Week almost over, the second half of November was <em>much</em> quieter than the first half. (There were around three times as many bets in the first half of the month as in the second.) However, there were still a few notable events, and one major lesson I learned the hard way.</p>

<blockquote>
  <p><strong>16.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:12</strong> - P.S. Yesterday evening, I got another resolution email from Salem, for “Will Trump Announce in 2022?”. Which is odd, since I of course sold everything. It claimed my investment was 33 and my payout 0. In reality, I put in 50 at the start and sold for 18 on election day, so presumably a bug causes it to think the difference was still invested for the purpose of the email sending. I guess this means I’m going to be getting resolution emails for every market I’ve ever participated in as well. Or at least the ones where I sold for a loss.</p>
</blockquote>

<p>Note: I’m still a bit baffled by this one. I assume that a rounding bug resulted in me still having an infinitesimal fraction of a share, and so it mistakenly thought I was still invested in the market and thus the email still triggered. But if so, it somehow didn’t even show up in the API, because the logs show that I bought and sold exactly 110.998594394 shares each time.</p>

<p>Perhaps it really does just email everyone on resolution if you’ve ever invested in the market, even if you later sold everything. I don’t think I ever fully sold out of a market again without buying back in like this anyway, so I wouldn’t know.</p>

<blockquote>
  <p><strong>08:55</strong> - I decided to go ahead and throw all my money into the “Republicans to take House” market in Salem. Of course, lots of other people already had the same idea, and I purchased it from 99.3 to 99.4%, with a profit of 18 off of 3077 if I win. It looks like it shows 0.1% increments once it goes above 98%, something I’d never seen before. The 3rd place, Connor Pitts, put over 6k into it last night, and I’m sure the others have large amounts as well. I’m also down to 11th in the rankings. Oh well.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-11-16 16:43:49 Gay Marriage Bill in 2022?
  $3166.0 for 3198.238 YES shares (market price 98.69% -&gt; 99.00%)
</code></pre></div></div>

<h2 id="the-gay-marriage-fiasco">The gay marriage fiasco</h2>

<p>As mentioned, I had earned “interest” in late October by betting on near-certain markets that would be resolving shortly, and continued doing so with a succession of unresolved markets on Election Week following the midterms. Naturally once the House market finally resolved, there was the question of what to do next with my money. In the afternoon, I noticed that “Gay Marriage Bill in 2022?” had spiked and decided to pile in. Unfortunately, this turned out to be a huge mistake, as described in <a href="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html">the previous post</a>.</p>

<blockquote>
  <p><strong>22:28</strong> - Late this afternoon, I checked in on Manifold again, since the House had finally been called earlier. I noticed a market, “Gay marriage bill in 2022” which had suddenly shot up and was at 98.7%, usually a sign of a near-sure win, so after reading a news article for confirmation, I threw everything in. As usual, Connor Pitts was there 35 minutes before me with his 6.5k stack. I’m also down to 12th place now.</p>
</blockquote>

<blockquote>
  <p>Of course, now that I’m in the big leagues, the people ahead of me are all the ones who actually know what they are doing and are willing to spend time obsessively checking the news to quickly pounce on easy wins (and have much larger bankrolls besides). My plan was (and is) to wait until this weekend and figure out the state of things and decide what to do going forward. I figured that with all the election stuff out of the way, things would be pretty static, so it’s disappointing that I’ve already dropped two ranks again. Oh well, hopefully I’ll figure out some sort of clever quant trading strategy and zoom up the ranks.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-11-16 16:43:49 Gay Marriage Bill in 2022?
  $3166.0 for 3198.238 YES shares (market price 98.69% -&gt; 99.00%)
</code></pre></div></div>

<blockquote>
  <p><strong>19.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>15:18</strong> - … My goal for the day was to start investigating the Salem Center Manifold stuff to try to figure out how things worked, what the rankings were, and come up with a strategy to advance. Naturally, I … didn’t get to Manifold until after 3pm.</p>
</blockquote>

<blockquote>
  <p>When I got in, I noticed that the Gay Marriage Bill market was down to 95%. The top ranked player, Johnny Ten-Numbers, has been buying it down and started a discussion asking why everyone was so confident, saying that “ The current leaderboard numbers 3, 4, 8, 10 and 12 have pretty much bet their entire fortunes” (the last being me of course). I suppose if it does somehow fail, at least I’ll be in good company! To be honest, I saw everyone rushing in and assumed it would be resolving shortly. One of the commenters (zubbybadger, not ranked) said they think it will pass in the first week of December. Of course if I had known it would take so long to resolve, I wouldn’t have jumped in, just for the sake of having liquidity in the intervening weeks. Oh well.</p>
</blockquote>

<p>It’s funny to see Zubby talked about like a nobody at this point, since he ended up winning the entire contest.</p>

<blockquote>
  <p>Anyway, after seeing that, I figured I should write this journal entry, so I haven’t actually started researching Manifold yet. Not that it will matter <em>too</em> much if there’s nothing I can do until mid-December anyway.</p>
</blockquote>

<h2 id="learning-about-manifold">Learning about Manifold</h2>

<p>When I first started the contest, I had no idea how Manifold actually worked, but after getting catapulted onto the leaderboard following the midterms, I realized I actually had a chance and should start actually trying, and as alluded to in the above journal entry, the first step was to research how Manifold actually worked.</p>

<p>Previously, I had assumed that the market prices were somehow determined by crossing YES and NO bets. However, a bit of googling revealed that Manifold actually uses an algorithm for <strong>automated market making</strong>, a concept I had never heard of before. You can find the details online if you want, but the bottom line is that it means that market price changes in response to bets are determined by a simple fixed algorithm, rather than relying on users to make the market and cross orders manually. One consequence of this is that there’s always a little bit of potential profit available even at extremes, such as when the outcome of the market is already certain and it just hasn’t resolved yet.</p>

<p>The other prong of my research was to write a script to scrape the public bet histories and reverse engineer everyone’s portfolios and scores, and thus the leaderboard.</p>

<blockquote>
  <p><strong>20.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>16:07</strong> - … Anyway, yesterday evening, I (finally) got around to the Manifold thing and worked on that for an hour or two. The page for each market shows a complete list of bets, with the player, amount, and approximate probabilities (e.g. “Spencer Henderson bought S$168 of YES from 52% to 56% 8 hours ago”), although it doesn’t show the shares received. I had assumed that I would just have to scrape those pages and then approximate the number of shares received based on the start and end probabilities, which would at least let me estimate the current standings and portfolio of each player.</p>
</blockquote>

<blockquote>
  <p>Fortunately, it didn’t come to that. As it turns out, the page source shows much more detailed data, including the exact amount of shares received for each bet (as well as the exact start and end probabilities, whether it was a limit order and if so how and when it was filled, etc.). Even better, Manifold also has an API to get this data so I didn’t have to scrape it all by hand. After some trial and error, I wrote a Python script to use the api to get the data for each market, and then added up all the bets to get the current holdings of each player and their current total market value.</p>
</blockquote>

<blockquote>
  <p>At least as of yesterday evening when I scraped the data, the current standings are 1st - 8924, 5th - 5334, 10th - 3255 (and me at 3034 in 12th - of course there’s lots of people close behind me as well.) It will be a tall order to triple my money relative to Johnny Ten Numbers, but hopefully I’ll figure out a way to do that.</p>
</blockquote>

<blockquote>
  <p>I also discovered in the process that the market probabilities as well as share amounts and money are arbitrary decimals and it just all gets rounded in the UI, which makes sense and explains a lot. The API also has options to place and cancel bets as well as just fetching data, which would allow things that are impossible through the normal website such as setting a limit order at an arbitrary decimal price, though I doubt it will ever matter much.</p>
</blockquote>

<p>Note: The API doesn’t actually let you do this.</p>

<blockquote>
  <p>My plan for today was to further dig through the data to a) figure out how the trading fees work and b) look at the holdings of the top players and their bet histories to try to understand what strategies they might be using. As usual, I was hoping to get started early, but it is already 4:21pm and I haven’t started yet. Oh well.</p>
</blockquote>

<blockquote>
  <p><strong>21.11.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:07</strong> - I spent a while looking through all the markets and the top players’ portfolios, but I still haven’t come up with a plausible strategy yet. I’m now down to 13th, though I’d be in 11th if the Gay Marriage Bill market magically resolved. One notable discovery is that Mike Aniello, then 11th, has most of his money on Republicans to win the Georgia Senate seat and would be instantly catapulted near the top two if that actually happens.</p>
</blockquote>

<blockquote>
  <p>I also spent considerable time trying to reverse engineer the fee formula, looking at the before and after numbers for a couple bets and trying every combination I could think of, but nothing matched up. Eventually, it occurred to me that Manifold is open source and I could just look up the code, which I did. So that was pretty embarrassing. Oh well.</p>
</blockquote>

<p>My plan to figure out a good strategy by looking at what the top players were doing was a complete bust, but one nice side effect of the Python script is that, as alluded to above, I could also ask it to calculate what the leaderboard would be under hypothetical scenarios if a market magically immediately resolved a certain way.</p>

<h2 id="the-desktop">The Desktop</h2>

<p>To be clear, I didn’t exactly have real time information from the script. I’d been using a Chromebook as my main computer for many years, and had a Linux desktop that I only sometimes booted up on the weekends for the purpose of programming projects like this, and thus all my Salem stuff was on that desktop and only accessible on the weekends. When I work from home, I use the same monitor, keyboard, and mouse, and thought it was a hassle to constantly plug and unplug the various computers and move the monitors around, so I only bothered to fire up my personal desktop on the weekends.</p>

<p>Additionally, the script took a minute or two to fetch updated data from the API, so I only occasionally bothered to do so. So I only checked in on the Salem standings via my script every week or two, but it was still better than not having the information at all, I guess. Initially, the script wasn’t of much use, but I continued tweaking it and adding functionality over the course of the rest of the contest, and I made a lot more use of it later in the contest.</p>

<blockquote>
  <p><strong>01.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:11</strong> - I forgot to mention that yesterday, I went to Salem Markets again and noticed a new comment from ussgordoncaptain (current #8) on the gay marriage market explaining that “I wagered it thinking this was a simple resolution hop event not looking hard enough, sadly at this point it’s too hard to sell out”, so exactly what happened to me as well. At least I’m in good company. I’m also back up to #11, but that’s probably just random variations in the market values, since not much happened last week.</p>
</blockquote>

<h1 id="december">December</h1>

<p>December was again quiet for me, up until the last week.</p>

<p><img src="/img/salem2/dec.png" alt="Score graph" /></p>

<h2 id="the-ga-senate-runoff-dec-6">The GA Senate Runoff (Dec 6)</h2>

<p>The main event of December was the GA Senate runoff election on the 6th. Unfortunately, I had foolishly locked up my money in the Gay Marriage market weeks ago and thus couldn’t actually do anything on Salem other than watch helplessly. But that didn’t stop me from trying anyway:</p>

<blockquote>
  <p><strong>04.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>19:11</strong> - I also spent a while this evening looking into the Salem/Manifold stuff some more. I realized that I am effectively in 12th place rather than 11th, because the current 12th, Asher Gabara, is hot on my heels and has a big bet on Warnock besides. On the other hand, if Walker somehow manages to win (and the gay marriage bill goes through), I’d be in 10th. But of course I wouldn’t hope for a tragedy just for the sake of gaining a few points in a pointless competition.</p>
</blockquote>

<blockquote>
  <p>I also discovered that Andy Martin, a newcomer to the leaderboard (currently 14th) is all in on “China Reaches 100,000 Covid Cases by Winter”, which seems increasingly likely (hence their rise through the ranks).</p>
</blockquote>

<blockquote>
  <p><strong>05.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:07</strong> - When I looked into Salem last night, it showed one player (Max) with a <em>negative</em> balance, which shouldn’t be possible, thus indicating a likely bug in my code. But it’s probably not too serious, since everything else makes sense, probably just improper handling of open limit orders or something like that.</p>
</blockquote>

<blockquote>
  <p><strong>06.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:50</strong> - After work (and to be honest, even before, starting around 4pm), I checked in on 538 to watch the election results come in. If the outcome became clear before the markets on Salem adjusted, it might have made sense for me to sell part of my stock in Gay Marriage, even at a loss, to play the GA senate market.</p>
</blockquote>

<blockquote>
  <p>However, Johnny Ten Numbers (the longtime first-ranked player) bought Gay Marriage down to 92% (with just $60), and GA Senate from 15% down to only 6% (with $3000) early on, ruling out any possibility of profit there, unless Walker somehow won out of nowhere and noone got the news before I did. I was especially frustrated to see Johnny betting big on the senate since the profit on that one bet alone would be way bigger than anything I’d get on gay marriage even if/when it passes, and bigger than most wins I could plausibly hope for in the future. Incidentally, there was also bad news on that front, as the House was supposed to vote on the Gay Marriage bill today, but it was delayed for unclear reasons.</p>
</blockquote>

<blockquote>
  <p>It didn’t take long after 5 to decide that there was negligible chance of Walker suddenly winning, and I stopped paying attention to the news and markets.</p>
</blockquote>

<h2 id="some-bankman-fraud-dec-12">Some Bankman Fraud (Dec 12)</h2>

<p>On December 12th, Sam Bankman-Fried was indicted, leading to huge profits to whoever was fortunate enough to see the news first and bought up the market on Salem. (It looks like Ussgordoncaptain was first, with Johnny and then Josiah Neeley joining in later).</p>

<p>This didn’t affect me, since my money was still locked up, and in any case the whole spike and resolution happened in the space of an hour and I only found out about it well afterwards. However, this was presumably the cause of the huge jump in 8th place on December 12th in the graph above.</p>

<h2 id="gay-marriage-dec-13">Gay Marriage (Dec 13)</h2>

<p>On December 13th, the Gay Marriage market <em>finally</em> resolved, thus unlocking my money after nearly a month of forced inaction. However, I didn’t actually have any plans at the time and just left my money in cash for the time being.</p>

<h2 id="disillusionment-dec-18">Disillusionment (Dec 18)</h2>

<blockquote>
  <p><strong>18.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:36</strong> - … Later this evening, I checked in on Salem/Manifold again. I’m now down to 13th, but more significantly, the top 5 now all have more than double my money, and Johnny is up to over 12k. I was reluctantly forced to come to the conclusion that I just don’t have any chance and it is best if I just stopped even wasting time thinking about it entirely. It’s especially frustrating because it feels like the kind of thing that I should be good at, with my math and programming skills. I think that maybe if I had been more experienced and had even gotten around to programming a trading bot like I wanted to, I might have had a chance, but I never got around to it and it is obviously too late now. Oh well.</p>
</blockquote>

<h2 id="final-bets-dec-19">Final Bets (Dec 19)</h2>

<blockquote>
  <p><strong>20.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:44</strong> - … I spent the rest of the evening on Salem, despite my decision to abandon it just the night before. I decided to go back and divided my money up between the five near-certain markets that will be resolving at year end (e.g. Recognition of Taliban in 2022, Trump indicted of crime in 2022, etc.). I figured that there’s a chance I might decide to get really into it in January and actually write and set up a trading bot, maybe just to see how I’d do out of curiosity or see if I can get back into the top 10 at least even though there’s no prize for that. The year-end markets were already down to 3-4%, but even a 3% return should help slightly reduce the ground I’m constantly losing to the higher ranks until January.</p>
</blockquote>

<p>Note: The entry is dated December 20th, but I was writing about what happened the previous day on the 19th:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022-12-19 20:43:04 Will Donald Trump Be Indicted for a Crime in 2022?
  $500 for 519.404 NO shares (market price 4.32% -&gt; 3.91%)
2022-12-19 20:47:31 Over 100,000 Monkeypox Cases in 2022?
  $500 for 515.150 NO shares (market price 3.35% -&gt; 3.15%)
2022-12-19 20:48:24 Recognition of the Taliban in 2022?
  $100 for 102.165 NO shares (market price 2.56% -&gt; 2.12%)
2022-12-19 20:50:40 New Iran Nuclear Deal in 2022?
  $500 for 519.283 NO shares (market price 4.25% -&gt; 3.94%)
2022-12-19 20:53:19 Will Russia Control Kramatorsk on 12/31/22?
  $500 for 515.891 NO shares (market price 3.51% -&gt; 3.29%)
2022-12-19 20:55:36 COVID Falls Below 20,000 Cases in 2022?
  $500 for 515.633 NO shares (market price 3.46% -&gt; 3.24%)
</code></pre></div></div>

<h2 id="limit-orders">Limit Orders</h2>

<p>In addition to throwing most of my money into risk-free interest rate markets before I left for Christmas vacation on the 21st, I crucially also experimented with <strong>limit orders</strong> for the first time.</p>

<p>I was aware that the top players were using limit orders, but had no idea how they worked and hadn’t bothered to try them out myself yet. The first thing I discovered is that they don’t lock up your money like I had assumed. I had assumed that when you place a limit order, it also reserves an equivalent amount of your cash in order to ensure that the limit order can be filled when applicable.</p>

<p>However, it turns out that that isn’t the case, and you can place <em>multiple</em> limit orders with the same amount of money, and so I did. I put one limit order at a little above market price for each of the five near-certain markets, and then randomly decided to place a large way-out-of-the-money limit on China COVID as well for fun. Fortunately, fate smiled upon me and I got very lucky with that limit order.</p>

<blockquote>
  <p><strong>28.12.22</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:01</strong> - When I accidentally checked the Salem markets again this morning, I was surprised to see a balance of -$100. Before I went on vacation, I had 3098, and I put 500 into each of the five near-certain markets that would be resolving at the end of year, and left the remaining 598 as dry powder.</p>
</blockquote>

<blockquote>
  <p>I tried entering a limit order for the first time, putting one down for Trump Indictment at 10% for 598 (it was 4% at the time) to hopefully profit in case someone did a big dumb order pushing the price way up. Then I tried putting in similar limit orders on a couple other markets. I had assumed that putting in a limit order locked up the relevant capital, but apparently not. It let me put in multiple limit orders backed by the same money. For fun, I also put one for 598 at 70% on the China COVID market. It was 39% at the time, and it is riskier and doesn’t resolve until the end of February so I left more of a margin. I didn’t think anyone would ever put in such a huge order to actually hit it, but figured I should do it just for fun.</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s where things stood for a week, but then yesterday, I decided to put another 100 down on Trump Indictment (NO), since the deadline was approaching and I figured I should try to lock in at least 4% while I still could, leaving me with 498 in free cash.</p>
</blockquote>

<blockquote>
  <p>It turns out that not long after that, Dylan Levi King, formerly around 20th place, apparently went crazy and put 2,486 (presumably their entire stack) into YES on China COVID, buying it up to 72%, and thus filling my huge-way-out-of-the-money limit order, a huge lucky break for me.</p>
</blockquote>

<blockquote>
  <p>When I saw that it let you put in multiple limit orders with the same money (and even spend the money afterwards), I had assumed that it would just only fill limit orders up to your available money. However, that is not the case. My entire limit order was filled, bringing my free cash balance down to -100.</p>
</blockquote>

<blockquote>
  <p>Even weirder is that four hours after Dylan Levi King’s initial splurge, they sold everything and went all in on NO instead, bringing it down to just 16%. And then I got a second, more minor lucky break, as they had just happened to decide to buy it back up to 61% <em>again</em>, only ~30 minutes before I happened to check this morning.</p>
</blockquote>

<blockquote>
  <p>Users had already bought it down to 52% when I saw it, but I decided that at that price, it made sense to sell some of my stacks in the Dec 31 markets and get more China shares, even though selling incurs huge losses, and I also had to fill in the 100 deficit first. And thus I put 498 more in, buying down to 39% (it is currently at 27%, but it seems very unlikely at this point, and in any case, I’m pretty much committed to assuming it resolves NO).</p>
</blockquote>

<blockquote>
  <p>Anyway, Dylan’s generous donation very luckily hitting the one limit order I put out catapulted me up to 9th in the rankings, and it might be even higher once the China market resolves at the end of February. So that was extremely fortunate. Another break like that and I’d have a decent shot of the top 5, though it’s hard to expect lightning to strike twice.</p>
</blockquote>

<h1 id="january-1-15">January 1-15</h1>

<p><img src="/img/salem2/jan1.png" alt="Score graph" /></p>

<p>Thanks to the lucky break in the China COVID market courtesy of Dylan Levi King, I ended December up in 9th place, and thus when I returned from Christmas vacation in January, I felt like I had a real chance and started participating on Salem far more actively than before.</p>

<p>Initially, I tried to make lightning strike twice, by placing limit orders way above/below market prices in various markets, hoping that a dumb whale would donate money to me like Dylan Levi King happened to do over Christmas in the China COVID market. However, that strategy ended up not working and even backfired in several cases when the markets suddenly shifted for legitimate reasons, so I was forced to abandon that tactic.</p>

<p>Instead, I started checking the Salem website frequently, several times a day in the morning and evening, in hopes of just happening to be the first person to check the website after a massive dumb-money price swing that I could profit off of by trading against.</p>

<p>The other big event of early January was the Q4 GDP &gt;= 4% market. I thought it was massively undervalued, since the Atlanta Fed’s GDPNow website was predicting first 3.9% and later up to 4.1%. It seemed crazy to me that the market price would be as low as 12% when GDPNow was forecasting 4.1% GDP growth, and I bought it up to 25%, and was continually surprised when it failed to spike following the GDPNow updates and in fact went back down.</p>

<p>I found the schedule for GDPNow forecast updates and made a point of checking the website when each update was scheduled, because at the time, I assumed that other people would be checking and trading based on the same website, and thus I could profit by doing it first. However, it seems that hardly anyone else was doing so, as the markets stubbornly kept going back down, and also didn’t seem to react at all in the hours following the GDPNow updates. I guess everyone else had different preferred news sources.</p>

<blockquote>
  <p><strong>10.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:24</strong> - I guess I should talk about Salem as well. I’ve been a lot more active in Salem for the last week. Sadly, I actually lost ground as far as “portfolio value” goes in that time, due mainly to getting caught out with a bad limit order.</p>
</blockquote>

<blockquote>
  <p>It started Tuesday morning last week when I saw GDPNow update to 3.9% and bought the Q4 GDP &gt;= 4% market from 9% up to 18%. I got cold feet later, especially after the Thursday update dropped down to 3.8%, but I managed to cash out a little part with a limit at 20%. This morning, the latest update jumped up to 4.1%, and I bought the market up to 25% and left a limit order there (and thus bought more when people pushed it back down). So far, it has been sold back down to 20%. It’s so nerve-wracking, especially since it’s just an “expected value” bet - the actual resolution is very far from certain.</p>
</blockquote>

<blockquote>
  <p>The big hit came yesterday though. Since December, I’d started putting in a lot more limit orders to try to profit in the unlikely event of a wild price move. I put in $444 at 44% on Russia to control Bakhmut at a time when it was in the 20s and there seemed to be no chance of it actually happening, but yesterday, the probability jumped up with the news of Russia’s renewed assault, and my limit order unfortunately got filled. That’s one of the risks of limit orders - there’s always a chance of new information when someone is betting, even if it seems unlikely a-priori. Which is incidentally a reason why I never put any limits on something like “DeSantis to run for President” - conditional on the probability shooting up, it is very likely due to new information.</p>
</blockquote>

<blockquote>
  <p>I put in a corresponding YES limit on Bakhmut at 43% this morning, hoping that people would push it back down slightly and cash me out, but instead, it kept going up. I upped my limit to 46% this afternoon, but the market is now up to 51%. I’m regretting not buying a bit with quick orders, but of course hindsight is 20-20, and it is frustratingly hard to find actual news from Ukraine.</p>
</blockquote>

<blockquote>
  <p>The one semi-bright spot for the time being is the China COVID market. I got really worried yesterday morning when the latest report was 14k cases, uncomfortably close to 100k. During the day, someone bought it up to 62%, but as I was panicking, I didn’t try to buy it back down (people since took it back down to 37%, so at least the others are more confident than me). Today, there was no report at all, and I have no idea what to make of that.</p>
</blockquote>

<blockquote>
  <p>Anyway, playing Manifold is surprisingly nerve-wracking, even though there are no real stakes other than bragging rights, and I only got to the position I am in now by being pretty lucky in the first place. Still, I really want to win.</p>
</blockquote>

<blockquote>
  <p><strong>11.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:52</strong> - As far as Manifold goes, not much is new, except that three days ago, back when I was panicking about the China market, I put in a YES limit for $340 at 34%, and after the spike later that day, the market has continued falling, and this evening someone pushed it all the way down to 34% and bought out my limit, thus cashing out 1000/2868 of my shares.</p>
</blockquote>

<blockquote>
  <p>I don’t understand why the rest of the market is so confident, and I also don’t understand why the page I was looking at (from the China CDC) hasn’t reported <em>any</em> regular daily reports since the 8th. But I guess my risk in that market is reduced now. Of course, the paradox of these things is that you always feel bad about limit sales, no matter how they happen. When the market finally moves enough to hit your limit, it suddenly feels like they know something and you’re just leaving profit on the table by cashing out. Oh well. On the Bakhmut front, I upped my limit to 52%, but still no takers. On the Q4 GDP, someone pushed the market back up from 20% to 25%. I haven’t put in any new orders, so it doesn’t directly affect me, but it’s nice to have a vote of confidence that at least I’m not the <em>only</em> person who thinks it should be higher.</p>
</blockquote>

<blockquote>
  <p><strong>14.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>10:57</strong> - On the Salem front, China COVID jumped back up to 27% (from 21%) overnight, Bakhmut jumped back up to 48% (from 45), and GDP 4+% is down to 15%.</p>
</blockquote>

<blockquote>
  <p><strong>11:19</strong> - I also installed the Twitter app on my phone and created an account and followed @realDonaldTrump so I can get a notification and hopefully buy up the “Donald Trump back on Twitter” market first in the unlikely event that he ever tweets again. I’ve steadfastly refused to create an account on Twitter all these years, even though the UI makes it really annoying to browse without an account, but I figure I should take any edge I can get on Salem. At least I can uninstall it again on March 31st when the market ends.</p>
</blockquote>

<blockquote>
  <p><strong>15.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:24</strong> - Saturday evening, the China COVID market suddenly jumped to 37%, though the two people responsible are clueless IMO. In fact, one of them is the guy who literally joined the contest just to try to persuade Salem to resolve the market YES (after finding out about it due to a linked market on regular Manifold and getting angry about it) and has been commenting endlessly on that topic ever since. However, I declined to take advantage because I was down to only $500 in free cash and wanted to preserve it in case something else comes up, and thus the profit opportunity fell to others (it fell back to 29% this morning). It’s a further layer of irony, as I FOMO’d into China at low prices only to regret it after seeing the US market, and then I regretted plowing so much into the US market because I didn’t have the spare cash left to take advantage when fools mispriced the China market. Oh well.</p>
</blockquote>

<blockquote>
  <p>Speaking of Manifold, this evening I got on the computer and ran the scripts again to see what would happen if I won the GDP 4% market or not. If it resolved YES today, I would be in 6th place, and just a hair’s breadth from fifth. If it resolved NO on the other hand, I’d still be in 9th, but just barely above 10th. It’s a little nerve wracking to have so much riding on what is essentially a coin flip even under the most optimistic scenarios. But to be fair, I only got as far as I did in the first place with an incredible amount of luck, and even if I lose, I’ll still be on the leaderboard at least. It seems like a decent gamble for something that will near-guarantee me top 5 if it pays off.</p>
</blockquote>

<blockquote>
  <p>I woke up to an email from Twitter this morning, with a digest containing a bunch of rightwing tweets from random accounts I didn’t follow. When I set up Twitter, I followed Donald Trump and also followed Paul Krugman as a test to make sure the notifications were actually working. I was disappointed to discover that I did not get any sort of notification on my phone or any notification when Krugman tweeted yesterday, and did somehow get an email with a digest of people I’m not even following. You had one job, Twitter!</p>
</blockquote>

<blockquote>
  <p>Fortunately, after looking around in settings more, I discovered that I had accidentally turned on Do Not Disturb on my phone. I turned it off and also set Twitter notifications to bypass DnD for good measure. I also of course went through the Twitter settings menus and unchecked everything I could that wasn’t specifically “tweets from people you follow”. Sadly, there’s no settings option for “spam from random people you aren’t following”. I later got a notification for a (re)tweet by Krugman, so I assume it works now, and unfollowed him.</p>
</blockquote>

<h1 id="january-16-31">January 16-31</h1>

<p><img src="/img/salem2/jan2.png" alt="Score graph" /></p>

<p>For the first half of January, up until around the 18th, things were looking pretty good for me as my frenetic betting had slowly increased my score. Unfortunately, the second half of the month was just one setback after another, followed by one last blow at the end of the month so significant that I was convinced that I’d been knocked out of the contest for good.</p>

<h2 id="china-gdp">China GDP</h2>

<p>The first setback was a minor loss from my limit orders in the China GDP market.</p>

<blockquote>
  <p><strong>16.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:04</strong> - Well today was a chaotic day on Salem, though it fortunately mostly worked out for me in the end. There are two thinly traded markets for China 2022 GDP 4% and World GDP 3% respectively, and I’d of course frequently seen them and eyed them as a potential new source of profit, but I wasn’t able to turn up any information in a cursory search, even basic stuff like when the numbers are expected to be reported (but it sounded like this would happen in June).</p>
</blockquote>

<blockquote>
  <p>Anyway, five days ago, I put a small $50 limit for YES at 50% (and another at 21%) on the China market, which was at 64% at the time and had recently been in the 70s. With no information and expected resolution not until June, I didn’t want to risk much, but I figured I should put some way out-of-the-money limits down to try to catch fat finger/whales.</p>
</blockquote>

<blockquote>
  <p>The China GDP market was at 61% last night, and thus I was surprised when I checked again this morning and saw it down to 48% (and thus my first limit was hit). It continued falling through the day, and when I checked again tonight it was all the way down to 20%. Most of the selling over the last day was due to one person, Iraklis Tsatsoulis, who posted a comment three hours ago linking to a news story that China just reported a 2022 GDP of 3%.</p>
</blockquote>

<blockquote>
  <p>I quickly sold my shares (for $58, thus a total loss of $42) and then decided to put $300 more in buying NOs. I got 355 NO shares, so assuming it resolves no and you ignore the time value (i.e. opportunity cost) of money, I’ll actually profit slightly overall. It’s a big risk putting in half my bankroll, but I’m hoping that it will resolve imminently, given the report of an official GDP release. And either way, I still have $333 in free cash left now.</p>
</blockquote>

<blockquote>
  <p>I am kind of groaning that I didn’t do enough research to actually figure anything out about the market and catch the fall ahead of time myself, but at least I’m in good company. In fact, Johnny put 375 into YES on the way down, and the Kalshi market was completely taken by surprise as well (Iraklis suggests that the Salem market was completely out of whack due to people trusting Kalshi too much - of course I don’t look at prediction markets myself except occasionally when people link them in the comments on Salem, but I relied on it by proxy by assuming the current market was sane. On the other hand, it makes me a little more optimistic that Kalshi might be wrong about the US Q4 GDP as well. The Kalshi market only goes up to 3.5%, but when I looked recently it had a forecast of only 15% for 3.5 (now up to 30%). I assume the reason the Q4 GDP market has been so much lower than I thought reasonable was because other Salem members were relying on Kalshi. It makes no sense otherwise for the market to go as low as 12% (now back up to 15%) when GDPNow is forecasting 4.1% GDP.</p>
</blockquote>

<blockquote>
  <p>But that wasn’t the only excitement on Salem today either. This morning, I finally gave up on cashing out my Bakhmut position at the 43% limit with the market languishing at just under 48, and so I put in a new limit to cash out at 48%. I was really surprised when I checked again in the afternoon and saw that it was down to 42% and that instead of getting (most of) my money back, I suddenly had an equal number of <em>YES</em> shares. Presumably, I forgot to cancel the 43% limit. Oops. I put in a NO limit at 48 to cash out just in case, and tonight someone bought it back up to 48% and cashed me out, so all’s well that ends well, I guess.</p>
</blockquote>

<blockquote>
  <p>I also noticed this afternoon that Johnny had almost bought up the rest of the 25% limit on the US COVID market a day after I put in the 1050, so I felt a lot better about my decision to commit so much then. I worried that it was an opportunity that wouldn’t last forever and I was vindicated much faster than expected. Tonight I bought the last $36 of the limit, and discovered that the other limits were all gone too. Up to this afternoon, the same person who put the giant limit at 25% also had limits at 24%, 22%, and 20%, but they suddenly canceled all of them.</p>
</blockquote>

<h2 id="q4-gdp">Q4 GDP</h2>

<p>The next big setback was in the Q4 GDP 4% market, where I had a larger bet, thanks to the odds seemingly being so good. On the 18th however, the bear consensus was justified when the GDPNow forecast suddenly dropped from 41.% to 3.5%.</p>

<p>There were also some worries in the Trump Twitter and China COVID markets that I’d forgotten about because they were ultimately insignificant. It’s interesting looking back at my journal entries and seeing what I wrote about at the time vs what I remember now.</p>

<blockquote>
  <p><strong>18.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:32</strong> - Well, the morning didn’t start with good news on the Salem front. Patrick commented, pointing out that the Chinese CDC has now officially released an update mentioning 1.27 million cases of COVID in hospitals. It appears to be a snapshot rather than a report of <em>new</em> cases, but it is still concerning, since there is a risk John Hopkins decides to average those into the case numbers somehow anyway.</p>
</blockquote>

<blockquote>
  <p>Also, I noticed the Donald Trump Twitter market spiking up. I quickly checked that he hadn’t actually tweeted, and then decided to throw $200 in (69-&gt;63%). Then I googled it to see what the fuss was about and found a new article that says Trump is planning to tweet again and has been talking about it for weeks. I wish I’d done them in the reverse order. Of course, there’s still a chance that he doesn’t tweet before April, but I wouldn’t have taken those odds if I’d known. I really need to learn how to stop FOMOing into things (or the reverse in this case, I guess). Also, the China GDP market is back up to 11% (other people cashing out).</p>
</blockquote>

<blockquote>
  <p><strong>08:17</strong> - I spent the morning reading the latest Magic spoilers on Reddit to distract myself, and when I checked back the Trump Twitter market was down to 61% and I had managed to partially cash out with my 62% limit, so that was nice. Of course, the real risks are the Q4 GDP and China Covid markets, since those are the ones I have large positions in (well, I also have a huge position in the US Covid market, but I’m not worried about that one). But I can’t really do anything except just wait and hope for the best.</p>
</blockquote>

<blockquote>
  <p><strong>08:36</strong> - Johnny just left a comment saying that he thinks the new CDC report is actually evidence in favor of NO, because it is the first report that doesn’t explicitly list new cases at all, consistent with China’s plan to stop reporting those. I sure hope he’s right. He also pointed out that OWID has now been updated with a string of 0s for the last few days (previously it just stopped at Jan 10th). But of course it’s theoretically possible that they decide to put that 1.27 million in somehow anyway, even though it is a completely different type of data.</p>
</blockquote>

<blockquote>
  <p><strong>11:10</strong> - I couldn’t get Salem out of my mind and just checked again, and then discovered more bad news - this morning’s GDPNow update is down to only 3.5%. I’m still planning to hold it just in case, but I guess I need to resign myself to the fact that I’m probably effectively in 10th now and top 5 is a longshot again. Hopefully, this means I can stop worrying about it as much now, but I doubt it will actually happen that way.</p>
</blockquote>

<blockquote>
  <p><strong>21:52</strong> - As far as Salem goes, the silver lining is that checking at 11am at least let me cancel the limit orders I had on Q4 GDP at 12 and 10% before they were hit, and thus I avoided throwing another $90 into the fire. On the other hand, I discovered this evening that a $50 limit at YES 45% for Donald Trump Indicted that I placed 11 days ago was now filled (it was 62% at the time I placed the limit.) I went through every single market on Salem and canceled all the random old limit orders I had placed in early January.</p>
</blockquote>

<blockquote>
  <p>I had been hoping to replicate my stroke of luck with Dylan Levi King in the China COVID market in late December, but instead, the majority of the limits I placed ended up being harmful when they were hit. Oh well. At least I can be glad that I’m not KDM, who had a $250 order at 50% filled for Donald Trump Indictment placed 12 days ago.</p>
</blockquote>

<p>Note: I sold the Trump Indictment shares on January 30th at 52.46% for a profit of $8.29, so that one ended up working out for me at least.</p>

<blockquote>
  <p>I also finally gave in and quick-sold the China GDP (11-&gt;12%) and put most of the money into the “new general state mask mandate by end of Feb” market (18%). I definitely regret not quick selling at 7% last night though. It’s so hard to predict when other players will buy or sell, and how much.</p>
</blockquote>

<blockquote>
  <p>Anyway, on to real, non-Salem news. I’ve been spending way too much time and effort on that lately anyway, though it is hard to cut back. …</p>
</blockquote>

<h2 id="biden-approval">Biden approval</h2>

<p>The next hammer to drop was in the Biden Approval market. I’d assumed that it was practically a sure thing, since there were only weeks left, and his approval rating had a large margin above 42%. However, the approval rating suddenly dropped unbelievably quickly, so fast that even the articles on the 538 website couldn’t keep up with the news.</p>

<p>I ended up refreshing the 538 poll tracker frequently throughout the day, hoping to be the first person to trade off any movements in the polling average. However, this ended up being counterproductive, as I <em>still</em> somehow managed to lose money on every trade.</p>

<p>The most ironic part is that the market ended up resolving YES after all, but it didn’t help me since I sold out near the bottom. I think Josiah, who was heavy on YES but didn’t sell out, did better. But all that was still a week and a half in the future, and with a lot more bad news to come.</p>

<blockquote>
  <p><strong>20.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:52</strong> - I’ve still been checking Salem several times a day, even though I’ve largely just been a passive bystander recently. Today was pretty dramatic though, with the sudden decline of Biden’s fortunes in the “Biden Approval 42% on Feb 1st” market, which peaked at 92% two days ago and was at 88% just a day ago.</p>
</blockquote>

<blockquote>
  <p>When I checked around 11 this morning, it was already down to 74%, and Biden’s approval rating on 538’s average (which the market uses for resolution) was down to 42.9%, from a recent peak of 44.1%. Fortunately, though I’d thought it was nearly a sure thing, I hadn’t put much in yet, just 75 at 86%, 50 at 87, and 100 at 79% over the last couple weeks, all via limit orders.</p>
</blockquote>

<blockquote>
  <p>Personally, I thought there is an obvious tendency in politics to overhype every little scandal and figured that the classified document thing wouldn’t hurt Biden much or that he would probably bounce back by February if it did. When I checked around 11, I was amazed how rapidly the price had fallen and figured people were getting ahead of themselves. I initially put a limit at 70-something, but then on second thought canceled it a minute later and just put a small limit at 61% for only $24, due to liquidity issues plus uncertainty over how much the polls would drop. I figured that the current market drop would naturally bounce back as people fought the overcorrection and it would never even come close to my limit.</p>
</blockquote>

<blockquote>
  <p>I checked again around 4pm and was shocked to see it down to 56%, and even more shocked when I checked 538 and saw the polling average down to only 42.2%. I never thought it could move so fast - it looks like two polls were added this afternoon with Biden at only 38%!</p>
</blockquote>

<blockquote>
  <p>Anyway, the good news is that I only had a couple hundred in the market, and not <em>quite</em> bought at the peak, so my losses are a lot lower than they could have been. I checked the leaderboard this afternoon to see if I had fallen to 10th yet, and was surprised to see myself in <em>8th</em> instead. Josiah Neeley, who has long been sitting just above me at 8th, had suddenly fallen to 10th. Based on the bet history, it looks like he put a lot of money into Biden approval, explaining the sudden drop. As much as I’ve had a lot of losses in all my trading these last few weeks, at least I can be glad that I’m not him (or Connor, who fell from 3rd to 6th).</p>
</blockquote>

<blockquote>
  <p>ussgordoncaptain (currently 7th) also put a bunch in, but not enough to drop a rank, apparently. Meanwhile, zubbybadger (previously 7th, IIRC) has suddenly shot up to 3rd. He was the first person to start selling Biden approval last night and sold a lot of it at high prices. Later, Johnny came in and also sold a lot and presumably claimed a lot of profit as usual as well, but I’ve given up worrying about him, since he is so far ahead and so active that there’s no stopping him, and my goal was just top five anyway, so profits he claims at least aren’t going to the other top players.</p>
</blockquote>

<blockquote>
  <p>When I checked again just now, Biden approval was down to 49% and Josiah was all the way down to 12th. It wasn’t just the Biden thing though - it looks like this evening, Josiah also suddenly sold a large amount of Trump Back On Twitter and bought a large amount of Russia Bakhmut, which of course not only incurs fees and massive slippage, but traders also pushed each market back up/down a few % from the peak after his trades, further eroding his current market value (but of course, it could yet pay off for him if he managed to guess right on the outcomes.) This incidentally also cashed out my remaining Trump Twitter No shares with a limit at 63%. I set the limits aggressively enough that I probably made minimal profit, but what really matters is that that little chunk of money is back out of the market again.</p>
</blockquote>

<p>As alluded to previously, I was desperately short of uninvested cash in late January, so getting cashed out was very welcome.</p>

<blockquote>
  <p>Anyway, I haven’t been affected much beyond watching my positions continue to rack up minor losses, but watching people shoot up, first with Iraklis on China GDP and then with zubby on Biden, I can’t help but get jealous and wonder why it wasn’t me who was able to capitalize on those rare breaks. Of course, there are a lot of players and only a few can get lucky like that, and people’s luck can easily change (much like I got a big lucky break when Dylan sent me cheap China COVID shares last month and then I had a bunch of smaller bets go bad last week.) In particular, Iraklis is already back down to 17th place. I’ve noticed him doing some questionable trades, rushing into markets at low prices and panicking back out when they go up (like China COVID), which is presumably what eroded his standings.</p>
</blockquote>

<blockquote>
  <p>Incidentally, a major silver lining is that if Trump actually does return to Twitter, as now seems plausible, I’ll have a decent chance of being the one to ride the rocket thanks to the app notification. Not a sure thing of course, since others could have easily done the same thing, and the market in aggregate is usually way faster and more knowledgeable than me, hence how I kept getting caught out earlier when people were trading on stories or developments I hadn’t heard of. But it is a chance at least, and Josiah helpfully pushed up the potential profit by selling.</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s way too much discursion on something that is meaningless in the big picture, and where I have only a small chance of winning anyway. But oh well. Now for the regularly scheduled journal entry: …</p>
</blockquote>

<blockquote>
  <p><strong>21.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:42</strong> - I checked Salem a lot less often than usual, and instead have just been refreshing the 538 Biden approval page every couple hours, which is much faster and accomplishes almost the same thing. However, the 538 average hasn’t been updated since those two polls Friday afternoon that dropped it to 42.2. Salem has also been pretty quiet, with just one minor event of note.</p>
</blockquote>

<blockquote>
  <p>I checked Salem a little before 2 and just happened to notice that only 17 minutes before, zubbybadger had suddenly sold “Biden Cabinet Official Out by Summer?” up from 55% to 69%. At first I thought it was a sudden news break and checked, but only saw a fresh story saying that the Chief of Staff (which is not one of the positions covered by the resolution criteria) was departing. I thought maybe zubby just wanted to free up money for another market, but checked around the other active markets and didn’t see any new bets and after a little while, just forgot about it again.</p>
</blockquote>

<blockquote>
  <p>The lucky timing would have made it a lucky break that I happened to be the first to notice the swing, except there was no actual news development to capitalize on. And of course, I didn’t want to push the market back down because a NO won’t resolve until June. I was puzzled and thought maybe zubby was confused and didn’t read the resolution criteria carefully, but if they really thought resolution was imminent, they should have put everything they had into it.</p>
</blockquote>

<blockquote>
  <p>In an even more remarkable coincidence, I checked Salem again just before writing this, and saw a new comment posted by zubby literally seconds before (9:41pm), explaining their trade, saying “NYT story had Walsh and Vilsack in the mix for Chief of Staff. I didn’t want to be holding the bag.” So that’s one mystery resolved.</p>
</blockquote>

<h2 id="the-paradox">The Paradox</h2>

<p>I checked my script again and discovered a counterintuitive phenomenon I dubbed “the Paradox”. I was currently in 8th place, but would end up in 9th place no matter how the markets resolved.</p>

<blockquote>
  <p><strong>22.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>16:43</strong> - No real action on Salem since Friday. This afternoon, I fired up the desktop and checked what the standings would be under a few hypotheticals. Assuming GDP 4% resolves NO, I’d still be in 8th place, but only barely above 9-11th, and 5th would be 1.60x me. I also calculated the rankings under all four possibilities for the GDP 1% and Biden Approval markets (assuming GDP 4% is NO as well). Paradoxically, in all four cases, I would drop to 9th place, even though I’m 8th before they resolve. Of course, <em>which</em> person takes my spot at 8th depends on what exactly happens - Josiah if Biden hits 42% and Krum-Dawg Millionaire if he doesn’t. However, my gap from the top 5 varies based on the scenario, from 1.68x if both resolve NO, to only 1.42x if they both resolve YES. It’s a bit frustrating that all my math and programming skills and the script and so on haven’t actually helped me find a winning strategy at all. It just lets me see in more detail just how badly I’m failing or not.</p>
</blockquote>

<h2 id="the-final-week">The final week</h2>

<p>The last week of the month brought a steady stream of more bad news on the Biden Approval and GDP &gt;4% fronts, with the latter resulting in my largest single loss of the entire contest.</p>

<blockquote>
  <p><strong>23.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:30</strong> - I checked 538 and Salem first thing after getting up like usual this morning, and 538 had coincidentally finally updated just minutes before, with Biden down to 42.1%. Oddly, I remembered the last two polls Friday afternoon having an adjusted approval of 38%, but now the three most recent polls were adjusted to 39%, 40%, and 41% respectively. Still, the average going down seems like a bad sign. Noone had traded on it on Salem yet, and I decided to sell a tiny amount (30 shares) at 49%, just in case. Of course, thanks to transaction fees, selling at 49% is effectively more like selling at 46%. In early January, I was trying very hard to avoid transaction fees, which probably cost me a lot sometimes, but then again, I think the other players are too cavalier about the fees. Still, there’s no way to avoid it if you want to trade on fresh information, since you can’t exactly place a limit and wait for someone to trade the other way.</p>
</blockquote>

<blockquote>
  <p><strong>21:54</strong> - This morning, ussgordoncaptain put $2425 into US GDP 1%, bumping it from 90% up to 94%. It had been stuck at 90% for such a long time that I assumed it would stay that way right up until resolution, with the discount reflecting genuine uncertainty rather than just time value of money. I’d planned to put my spare money there at the end myself earlier, back before the GDPNow estimate suddenly dropped to 3.5% and released the updated blue chip estimate and I got worried about the possibility of &lt;1% GDP. But it sees ussgordoncaptain doesn’t share my hesitation.</p>
</blockquote>

<blockquote>
  <p>I continued checking 538 periodically throughout the day, but there were only two more updates, at 10:30am and 3:37pm (going by the update time listed on the site). The former bumped Biden back up to 42.2%, but I decided to just wait and see, since there is still a lot of risk and transaction fees make it impossible to profit off minor swings (49-&gt;43% and back). David Hassett however, didn’t share my hesitation and bought it from 43% back up to 51%.</p>
</blockquote>

<blockquote>
  <p>The second update (well third update of the day) in the afternoon dropped a third poll, but the average stayed steady at 42.2%. There was no real action for most of the day, but when I checked again just now, I discovered that two hours ago, zubby had suddenly bought it up to 63%.</p>
</blockquote>

<blockquote>
  <p>Either way, it’s ironic that the only result of me obsessively checking 538 so frequently is that I was actually worse off than if I had done nothing, due to panic selling a little at low prices this morning. Oh well. If it had kept going down, I would have been praising my attentiveness and regretting not selling more. It’s still ironic though.</p>
</blockquote>

<blockquote>
  <p>The other notable action of the day was from 11-12 when Iraklis suddenly started buying China COVID up to 35% for no apparent reason. I initially assumed there must have been a new development, but I checked the OWID page (still showing all zeros) and the relevant discussion about how to handle the data on Github, and googled for news stories, but there was no discernible reason for the spike. If anything, it seems like things are looking more favorable for NO than ever.</p>
</blockquote>

<blockquote>
  <p>I couldn’t shake the feeling I was missing something and was low on cash (only 341), but I very nervously quick-bought $41 of NO and put in a limit at 39% for another $30. When I checked tonight, someone named David Lawrence (not a name I’ve ever seen on leaderboards) had pushed it up to 40%, filling my limit. I checked all the above mentioned again, but still no new developments. I just have no idea what people are thinking. I guess it means more profit opportunity for me (but not that much, since others have been pushing it down aggressively too - currently 36%), but it is very nerve-wracking.</p>
</blockquote>

<blockquote>
  <p><strong>22:24</strong> - There was one other notable action on Salem that I missed before, because it was in “Trump the Favorite in Summer 2023?”, a market I haven’t paid much attention to due to lack of good information and July 31st resolution date. For some reason, it jumped from 42% to 55% this morning. Of course, markets with a very distant resolution are naturally less liquid, and one person selling could just be to free liquidity, but for both David Hassett and Johnny to suddenly sell it up at the same time suggests there must be <em>some</em> reason. I’ve always wondered sometimes where people are getting their information when there are massive market movements with no discernible cause. Oh well, it’s not like I’m even in that market. Really, I need to start preparing for bed again.</p>
</blockquote>

<blockquote>
  <p><strong>24.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:37</strong> - … As usual, I checked 538 after getting up, and as usual, it had recently updated this morning (6:25). The new data bumped the average up to 42.3%, and I decided to put another $70 down on the market (63-&gt;64% - noone had traded since last night). I think Biden is a lot safer now that we’ve had three consecutive updates that were neutral or favorable, including polls taken over recent days, the period where it seemed like he had had a sudden drop in support late last week. Of course, I’m probably jinxing it now. I’m also surprised that Johnny still hasn’t tried to buy the China COVID market back down from 36%. I’m guessing he’s short of liquidity and will do so after the markets resolve tomorrow. Or maybe he just gets up late in the morning, but usually he’s really active about stuff like this. I suspect that both David and Johnny’s sales of “Trump favorite in summer” yesterday morning were just to free up liquidity.</p>
</blockquote>

<blockquote>
  <p>Update: I just idly checked 538 again (7:48) and it showed as updated at 7:33, but I don’t see any new polls listed and the average is still 42.3%. Still, that must be at least a <em>very slightly</em> good sign.</p>
</blockquote>

<blockquote>
  <p><strong>13:54</strong> - I just checked 538 every once in a while this morning, but just now, I checked Salem again, and was shocked to see China COVID up to 40%, driven by Iraklis and another no-namer. As usual, I checked, and still no sign of any news developments. I really wish I knew what people were thinking. It’s a shame that I’m so short on cash that I don’t want to buy it back down right now. Speaking of which, not a single person has traded Biden Approval since I bought it up to 64% this morning, to my great surprise. I guess it shows how hard it can be to predict other people’s trades. The market swung a lot more than I expected from the updates yesterday morning, and much less (not at all) since then.</p>
</blockquote>

<blockquote>
  <p><strong>25.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:01</strong> - When I checked 538 this morning, it had, as usual, just updated, this time going back down to 42.1%. It seems like every time I make a transaction, the polling average immediately goes the other way. This update is less concerning (famous last words) than the first Monday morning update since at least Biden isn’t in freefall now. It seems more like he’s hovering just at 42% and it’s practically a coinflip where things will end up. There’s not much time left for a change in the news cycle and reversion to mean like I was hoping, but hopefully the Pence document story will help him out.</p>
</blockquote>

<blockquote>
  <p>I decided to just stay put in the market, since it seems silly to immediately sell shares I just bought yesterday at the same price and eat transaction fees. Unlike yesterday, <em>this</em> time around, other people decided to trade on the news. Specifically, zubbybadger just sold it from 64% back down to 59%.</p>
</blockquote>

<blockquote>
  <p>In other Salem news, overnight David and Johnny tried to push the China COVID market back down a bit and Iraklis keeps buying it back up (currently at 38%). It’s a shame I don’t have enough liquidity to participate myself.</p>
</blockquote>

<blockquote>
  <p><strong>18:56</strong> - I was mostly occupied with actual work today, and didn’t bother checking Salem, though I did keep refreshing 538 periodically (it updated at 12 and 3pm, but with no new polls and the average stayed the same.) Thus I was shocked when I checked Salem again after work and saw China COVID was now up to 41%, since Iraklis had only been buying it up to 38-40%, and there had been a limit order wall at 40.</p>
</blockquote>

<blockquote>
  <p>What really surprised me though is that it wasn’t Iraklis buying it up, it was Sam Dittmer, who had previously been on the NO side, and constantly arguing (alongside me) against Patrick’s comments, explaining why they don’t make sense and the market should resolve NO. So seeing Sam suddenly do a 180 was pretty concerning. I checked and there were some new comments on the Github issue, with one non-Patrick user expressing support for randomly throwing the 1.2 million into the stats and a new post from the Chinese CDC which still doesn’t include any new confirmed case numbers, but does include graphs of the number of tests and test positivity rate over the last month or two (unsurprisingly a peak in December which has since fallen). Perhaps that is what changed Sam’s mind.</p>
</blockquote>

<blockquote>
  <p>In any case, at least Johnny is still putting up the good fight. This afternoon, Sam bought it up to 50, but Johnny pushed it back to 41 (with minor help from another no-name). Now, however, Sam has bought it back up to 48.</p>
</blockquote>

<blockquote>
  <p>Looking around, I see that Sam bought Bakhmut from 43 down to 37. And Johnny sold a bunch of “Oil at $100/Barrel During Winter?” (9-&gt;10%), presumably to fund the fight over the China COVID market. It seems that even the massively rich Johnny has limited liquidity. Incidentally, I’ve long been puzzled by the oil market, since it was at 9% for the last week and a half (and 10% before that, etc.) even though it doesn’t resolve until March 1st and there are several sure-thing markets resolving Feb 28 with much better prices (e.g. “COVID Peak of over 300,000 by End of Winter?” is at 16% right now). Not that you can really profit off other people doing a bad job of considering opportunity costs like that. Incidentally, the COVID 300k market was at 14% for the last week, until Iraklis sold it up to 16% yesterday, presumably to fund <em>his</em> China COVID buying. It’s weird how everyone is suddenly dropping everything over that.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s hard to stop thinking about Salem right now, which is why I wrote this instead of continuing to try to study Japanese just now. It’s ironic because there’s basically nothing I can actually do right now anyway, since I want to preserve my last $200 in case Trump suddenly tweets or something. But tomorrow, I’ll hopefully get $216 freed up from the GDP 1% market.</p>
</blockquote>

<blockquote>
  <p>It’s also an especially momentous night because I’ll finally find out tomorrow whether my lottery ticket in the GDP 4% market paid off or not. I’ve been doing my best to avoid even thinking about it and I don’t actually expect it to happen, but it’s hard to stop dreaming. Perhaps the weirdest possible outcome is that my long-shot bet in GDP 4% pays off, but then the seemingly near certain China COVID market resolves YES. In that case, it would be pretty much a wash for me, but some of the other players who were betting the other way would get hurt. But that scenario is doubly improbable. The funny part is that I feel like I should go all in China COVID, because if I lose that, I’m toast anyway now, with such a large stake there. But we’ll see what happens.</p>
</blockquote>

<h2 id="the-leaderboard-discrepancies">The leaderboard discrepancies</h2>

<p>Amidst all the bad news, I also noticed a strange discrepancy between the rankings predicted by my Python script and what the leaderboard on the actual website showed. I spent considerable time trying to debug it, but I ultimately didn’t figure it out until my return in March.</p>

<blockquote>
  <p><strong>25.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:00</strong> - Around 8:40, I fired up the desktop to run my Python script again and see what the standings would be under the various hypothetical scenarios. It showed that, as I suspected, Johnny has now fully invested everything (as have Iraklis and a bunch of other top users). According to the script, I would be in 7th place in the fantasy scenario where GDP 4% and China COVID both resolve YES. (I’d be 5th place if the lottery ticket strikes gold and China COVID goes the other way). Also, the China COVID market is now up to 54% after yet another purchase by Iraklis and a no-name.</p>
</blockquote>

<blockquote>
  <p>However, there was one other really weird thing - for the first time ever, the leaderboard on the website didn’t match the standings calculated by my script, and I wish I knew why. It had zubby and Mark swapped in 3rd and 4th, and 15-20th were also different. It’s not like the former are even particularly close together, and my script has never been wrong before, and it matches my own displayed portfolio value exactly. I wonder what happened.</p>
</blockquote>

<blockquote>
  <p><strong>21:19</strong> - I extracted (and prettified) the html for the leaderboard page, which as usual for Manifold, has a bunch of hardcoded JSON data, including the user data for the top 20 users displayed. This shows among other things, their current balance, but sadly not their current portfolio or portfolio value. I compared the balances of the top 10 to what my script thought they should be, and they all matched exactly.</p>
</blockquote>

<blockquote>
  <p>Also, at 9:06pm, David Hassett bought China COVID back down to 49%, which raised my ranking from 11th back up to 9th, and this was correctly reflected on both the leaderboard page and in my script (once I refetched market data from the API). And yet through it all, the Mark/zubby swap and the 15-20th discrepancy persisted. Very mysterious. In any case, I need to stop worrying about Salem and just watch SAO and then prepare for bed. There’s nothing I can do about Salem right now anyway, and thinking about it will just make it hard to sleep later.</p>
</blockquote>

<blockquote>
  <p><strong>26.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>05:52</strong> - I ended up not making it to bed until 12:06, partly because, while I didn’t actually visit Salem after ~9:15 last night, I did get caught up thinking about it for quite a while. …</p>
</blockquote>

<blockquote>
  <p>As for Salem - it was the most expected outcome - 1% YES, 4% NO. China COVID is down to 45% and OCaml put a big limit there, presumably with the freed up money from the winnings. I decided to buy it down to 44% and put a limit there of my own (no point putting a limit at 45% since Johnny’s would have to be filled first.) Unusually, there was no 538 update waiting for me this morning for the first time this week. But it has typically listed an update time of 6:30-7, so maybe there will be one later.</p>
</blockquote>

<blockquote>
  <p><strong>06:05</strong> - P.S. There was also a newly created market on Salem this morning, “Send ATACMS to Ukraine?”. Noone else had bet at all yet, so I threw in $1 just for fun, so I could claim the first bet. This is the first time I’d been the first to see a new market.</p>
</blockquote>

<blockquote>
  <p><strong>07:20</strong> - 538 updated again at 6:58, and the average is down to 42.0%, even though there are no new polls. It often updates with no new polls included, presumably re-weighting or minor data additions to existing polls, but this is the first time that such an update actually changed the top line number.</p>
</blockquote>

<blockquote>
  <p>I went ahead and sold 125 of my 385 shares (57-&gt;55%), painful as it is. Also, the China COVID market broke through Johnny and my limit orders, up to 47%. There certainly is reason for concern, since John Hopkins <em>did</em> add the 59k deaths in the January 15th update (which says the deaths were from Dec 08-Jan 12th) as a single day data point on January 15th. If they did the same thing with the 1.27 million hospitalized number from the same report, that would spike the weekly average above 100k. It seems completely unreasonable to me, and they at least haven’t done so so far, but the fact that they did something similar with deaths already is definitely concerning. However, I feel like after my numerous setbacks this month, and the fact that I’m already heavily invested in the market, I have to keep doubling down, because if it resolves YES, I’m screwed anyway. Also, there’s another new market, for whether the debt ceiling will be raised.</p>
</blockquote>

<blockquote>
  <p><strong>07:42</strong> - In other Salem news, the leaderboard now shows that Mark has dethroned Ben in second (and zubby is back down to 4th, where my script had them all along). For as long as I can remember, Ben has been secure in 2nd place (but distantly behind Johnny in actual money), and thus this was a surprise.</p>
</blockquote>

<blockquote>
  <p>Ben did have a small YES bet on Q4 4% GDP and Mark had a NO bet, but that alone would account for only a fraction of the gap between them, and when I ran the rankings again on my desktop just now, sure enough, Ben and Mark were still nearly in the same position as last night. Furthermore, the other rankings on the leaderboard are even more different from my script predictions than before, with random swaps all over the place (plus some completely different people in the bottom section).</p>
</blockquote>

<blockquote>
  <p>I really wish I knew wtf was going on. But I also feel like I need to stop thinking and worrying about Salem so much, since if China COVID doesn’t go my way, I’ll be out of the running anyway. But I feel like I should still keep trying to maximize value in e.g. the Biden approval market until then, so I’ll be in the best position just in case. Also, there was a third new market this morning - Q1 GDP 1%. There was already a Q1 GDP 3% market, but I guess they figured that seems less plausible now since Q4 GDP was already under 3%, and they might as well have two markets like they did for Q4.</p>
</blockquote>

<blockquote>
  <p><strong>07:57</strong> - Well technically speaking, there weren’t two markets for Q4 GDP, so this is new. The 4% market was officially “US GDP &gt;= 4% in any quarter 2022”, but of course once the Q3 numbers came out, it de-facto became a Q4 market, and I spent so long thinking about it that way that I forgot how it was actually worded.</p>
</blockquote>

<blockquote>
  <p><strong>21:50</strong> - As for Salem, I checked 538 a few times during the day, less often than before, but still enough to see it go down to 41.9% and back up to 42.0%. I didn’t check Salem at all, as I was at work and couldn’t do anything anyway and it’s a lot less fun when everything is going poorly. On the way back, I was actually kind of dreading what I would see when I got home.</p>
</blockquote>

<blockquote>
  <p>In the event, it could have been worse. Biden Approval was down to 46%, but I was expecting that. I was surprised that China COVID had seen no trades all day, still at 47%. In fact, my free cash actually went up because I had put down a small $20 YES limit at 16% on the US COVID market yesterday in an effort to free up cash, which had finally been filled.</p>
</blockquote>

<blockquote>
  <p>The big surprise though was that “Will PredictIt Survive?” was suddenly up to 94%. Checking the history, it had shot up from 35% in just the last hour or two before I got home (~5:45), as first zubbybadger, then Johnny, and lastly ussgordoncaptain capitalized on the (presumed) news. I had trouble figuring out what news had actually triggered the flip though, as Googling didn’t turn up any relevant news stories. I eventually discovered that the PredictIt Twitter account had tweeted at 4:13pm saying that the appeals court had granted them a temporary stay, presumably the trigger.</p>
</blockquote>

<blockquote>
  <p>Of course I couldn’t have done anything about it even if I had thought to look in such places, since I was at work at the time, but it’s still frustrating every time I see someone manage to scoop the market like that, since I wish it were me (and of course rankings in the competition are zero-sum). Oh well.</p>
</blockquote>

<blockquote>
  <p>… Oh, the other thing I forgot to mention is that after getting back, I checked Salem again and found China COVID up to 48%, filling my limit from this morning. I put a new limit at 48%, plus small YES limits to partly cash out in the US COVID and Mask Mandate markets, and a small ($20) NO limit on Bakhmut at 38%. But I haven’t even looked at Salem since ~7:40. I feel like I should be worrying about it a lot less than I am. In any case, it’s now 10:21. I guess I’ll check again before worrying about bed. Hopefully it will be easier to sleep tonight since I didn’t get as much sleep last night.</p>
</blockquote>

<blockquote>
  <p>Update: No visible changes since 2.5 hours ago.</p>
</blockquote>

<blockquote>
  <p><strong>27.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:24</strong> - This morning brought further bad news on the Salem Front. I checked 538 after getting up (~6:43), and it had updated at 6:39, going back down to 41.9%. I reluctantly sold 31/301 of my shares (46-45%). Just four minutes later, zubbybadger jumped in and bought it down to 39%. Then at 7:09, it updated again, with a new poll taking it down to 41.6%. Unfortunately, this time, zubby got to it first, buying to 29% (in fact, the only reason I thought to check is that zubby posted a comment, sending me an email notification). I gave in and sold my entire stake (29-&gt;26%). These last two weeks have been absolutely brutal for me on Salem. It’s frustrating, since everything seemed to be going so well earlier this month, and now it is all for nought.</p>
</blockquote>

<blockquote>
  <p>Incidentally, I forgot to mention the most alarming part of the PredictIt affair yesterday. Ussgordoncaptain commented “god I lost because my phone notifications were turned off”, implying that they do have phone notifications of some sort set up to find alerts about this somehow. Which implies that they probably also set up alerts in case Trump tweets, since that’s the simplest and most obvious to do, and that I have pretty bad odds of winning the race, even if he does end up tweeting.</p>
</blockquote>

<blockquote>
  <p><strong>22:10</strong> - I didn’t check Salem again until this evening, but there were no further updates from 538 today, and basically nothing happened on Salem either since Biden Approval tanked this morning. The most notable event was a no-name buying through my small 48% limit (in China COVID), after which I put another small limit down at 49%. I’m surprised that Johnny hasn’t tried to push it down again, since it’s been like a day now. Actually, I was surprised that there was barely any trading in general today (you know it’s a slow day when the most notable event is a no-name buying “Former Trump Official to Run For President by Summer” from 70 to 75%).</p>
</blockquote>

<blockquote>
  <p><strong>29.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:14</strong> - …later I got to the big other item on my agenda, Salem debugging, which ended up taking a lot longer than I expected, ~2-4:30. Of course, I don’t have much chance of actually winning, but I really wanted to solve the mystery of the leaderboard discrepancies, just due to curiosity.</p>
</blockquote>

<blockquote>
  <p>The first item was relatively simple to resolve. I first reported seeing a leaderboard discrepancy on the 25th, but in retrospect, I realized that the first discrepancy was probably actually when I checked the previous time (IIRC the 22nd), though I didn’t appreciate it at the time.</p>
</blockquote>

<blockquote>
  <p>When I first set up all the Salem stuff, I could access the <em>market</em> APIs to get the probabilities and resolutions and list of bets and everything, but for some reason, I couldn’t access any of the apis for <em>user</em> data. The user apis do work when trying to query regular Manifold, and I assume that Salem somehow disabled them in an attempt to prevent people from seeing the exact standings.</p>
</blockquote>

<blockquote>
  <p>What this meant is that my script was able to calculate everyone’s portfolio and simulated leaderboard and so on, but it was all random user <em>ids</em>, not names, and there was no automated way to get anyone’s name. Instead, I built up a manual partial id=&gt;name map for top users, by comparing my script’s predicted top 20 to the public leaderboard. Whenever someone showed up in the top 20 who I hadn’t already hardcoded a name for, I would find the corresponding name on the leaderboard and add it to the map in my script. Fortunately, there’s little reason to care about the names of anyone who hasn’t made the top 20 anyway.</p>
</blockquote>

<blockquote>
  <p>When I checked the script again on the 22nd, I noticed something odd. There was a new unknown user in 20th, who should have the name Oliver S. The odd part is that I had already previously assigned “Oliver S” to a <em>different</em> userid. I thought it was strange and likely a bug, but didn’t pay it much attention at the time and thought there was a chance of two different accounts that happened to have the same name.</p>
</blockquote>

<blockquote>
  <p>When the much more extensive discrepancies showed up a few days later however, I realized that this was probably the first sign of the discrepancy. Presumably this “Oliver S2” was actually in 21st at the time or something, and the discrepancy was just enough to put him in 20th in my script, beating out the actual Oliver S, who was still 20th on the public leaderboard.</p>
</blockquote>

<blockquote>
  <p>Anyway, yesterday afternoon, I looked into it by checking “Oliver S2”’s betting history and comparing it to the publicly visible bet history on the website (which shows usernames) and confirmed that Oliver S2 is actually Adrian Kelly. So that was one minor mystery resolved (~20m).</p>
</blockquote>

<blockquote>
  <p>However, I also wanted to figure out <em>why</em> the leaderboards were suddenly way off, and that proved much more difficult. I again checked the balances in the page source data for the leaderboard and compared them to my script’s predicted balances. When I did this before, the top 11 all matched exactly. This time, I checked all 20, and strangely, four of them (Mark, Connor, ussgordon, and Henri Lemione) had different balances then they should, while the other 16 were exactly down to the decimal as usual.</p>
</blockquote>

<blockquote>
  <p>Mark’s discrepancy was especially notable and intriguing, as my script suddenly had him at -949, while the official data had him at 0 (actually 0.1457… - since the UI only shows rounded amounts and only lets you spend whole numbers, it is common to end up with a fraction when you try to spend everything, but I won’t bother listing those.)</p>
</blockquote>

<blockquote>
  <p>While it is theoretically possible, as I discovered, to go negative via limit orders, this seemed less plausible, and it was a lot more likely for him to be at 0 after spending down everything, so it was a hint that my numbers were the ones that were wrong, although it took me hours to figure out why.</p>
</blockquote>

<blockquote>
  <p>My script was previously just focused on totaling everything up to determine <em>current</em> standings, but I modified it to instead build a list of all bets (or even more specifically, all bet fills, since limit orders can be partially filled at different times, not that Mark appears to have used any) and all market resolutions in sorted order of time in order to simulate the entire history of everyone’s cash balances over time, and then printed out the history of Mark’s balance.</p>
</blockquote>

<blockquote>
  <p>Mark had very often spent everything down to 0 but had never gone negative up until a day or two ago. Also, he had shot up to around 950 after the GDP resolutions on Jan 26th, just about the same amount he was now negative. After more fruitless troubleshooting, I tried subtracting the official balance from my predicted balance to get the exact amount of the discrepancy, and then checked how many shares Mark should have had as of Jan 25th, and discovered that the discrepancy <em>exactly</em> matched the number of GDP 4% NO shares he had, down to the decimal.</p>
</blockquote>

<blockquote>
  <p>I checked Gmail and discovered that Salem had actually sent me <em>two</em> emails about the GDP 4% resolution. Bingo! Evidently, they had accidentally resolved that market <em>twice</em> giving people on the NO side double the money they should have gotten. After I modified my script to count that market resolution as worth double, the discrepancies in the four user’s balances suddenly went away. I left a comment (4:35pm) on Salem mentioning @SalemCenter to explain the problem and ask them to fix it, though I wasn’t optimistic about the response.</p>
</blockquote>

<blockquote>
  <p>Of course, the double resolution didn’t explain away <em>all</em> the discrepancies. First off, I had first noticed a mismatch on the 22nd, and on the 25th, there were massive mismatches even though the top balances were all the same. Even then, after correcting the script for the money doubling, the top 17 spots of the predicted leaderboard now matched up, but the bottom was slightly different. (Specifically, it had Adrian Kelly inserted in 18th, who didn’t appear on the public leaderboard at all, and thus I couldn’t check what his balance was supposed to be. The balances of 18-20th, or 19-21st in my script, all matched up. This could be explained if his account was deleted or something, though I don’t think that’s likely.)</p>
</blockquote>

<blockquote>
  <p>However, I decided that it was best to wait to see how things fell out with the double resolution issue before hunting for the source of the further discrepancies. Besides, I was exhausted after hours of debugging and just wanted to declare victory. In fact, it made me feel like I won Salem in spirit, even though I’m not close in the rankings, due to discovering a critical bug in the contest, which is not something everyone could do.</p>
</blockquote>

<blockquote>
  <p>After relaxing for a bit, I discovered that someone named “James Grugett” had already responded at 4:58pm, saying “This appears to be accurate after inspecting the logs. I will write a script to subtract the second payout from user balances.”</p>
</blockquote>

<blockquote>
  <p>I was pleasantly surprised by the speedy and positive response. It was also surprising due to the account. People (including me) had commented a number of times @ing SalemCenter with questions about question resolution criteria and contest administration, and in the cases where they responded, they had always responded under the official “Salem Center” account.</p>
</blockquote>

<blockquote>
  <p>… However, I got waylaid by notification of another comment from Salem first. At 6:16pm, James had commented again, saying “It is done! You can see the updated balance reflected in, e.g. this user’s portfolio graph: https://salemcenter.manifold.markets/VictorLevoso?tab=bets”.</p>
</blockquote>

<blockquote>
  <p>Of course, I couldn’t actually see the linked page. It seems that regular Manifold allows you to see other user’s portfolio value over time, but Salem disabled that for obvious reasons, but their admins can still see it and didn’t realize others can’t.</p>
</blockquote>

<blockquote>
  <p>While on Salem, I looked around and noticed “Former Trump Official To Run For President” up to 81%. The main news of Salem was that Saturday morning, Johnny had suddenly woken up and bought (together with another user) China COVID back down to 43%. A second no-name took Trump Official President up to 80 and he put it back to 77 as well.</p>
</blockquote>

<blockquote>
  <p>This time however, zubbybadger had sold it 77-81 just minutes before, and I have to pay attention to something like that, because if it is a sign of new information, it would mean I was in the perfect position to profit. I spent some time researching, but couldn’t find any explanation for the sale…</p>
</blockquote>

<blockquote>
  <p>… The morning brought new notifications from Salem. Immediately after the last message (6:17pm), James had commented “Oh wait, only I can see your portfolios haha. Cheers.” At 1:07am, ussgordoncaptain responded “yeah though you can backcalculate everyone’s portfolio using a scraper+python”. It was a big surprise to see that I wasn’t the only one who had thought to write a python script to reverse-engineer everyone’s balances and portfolios. On the bright side, this makes me less worried that I’d be accused of cheating if contest organizers realized that I was doing this.</p>
</blockquote>

<blockquote>
  <p>As usual, I also checked the markets on Salem and was surprised to see Biden Approval way up. From 4:17-6:08am, zubbybadger had suddenly sold it from 19% all the way up to 41% (with Johnny pushing back a bit 24-22%, after the first sale.)</p>
</blockquote>

<blockquote>
  <p>Now <em>this</em> really got my attention, since it seemed to imply a huge profit opportunity one way or another. 538’s average still hadn’t updated since Friday morning when it went down to 41.6%, but I also googled for news stories, but couldn’t find anything. I thought maybe zubby was just selling to get money to buy something else, but the script showed that wasn’t the case either. I was completely mystified by why they would suddenly do this, especially as it seemed to imply information I didn’t have, but if it was just a random dumb trade, I worried that the profit opportunity wouldn’t last long and there was still no clear reason for Biden’s prospects to be any better than the last two days (if anything, the chances of a swing go down the closer we get to February.)</p>
</blockquote>

<blockquote>
  <p>Eventually, I decided to just put $50 into NO, and keep checking 538 periodically. However, when I checked back on Salem later this morning while researching some numbers and times in the process of writing the earlier part of this entry, I discovered that Johnny had suddenly sold from 41-47%. Now that <em>really</em> made me worried. Having <em>two different</em> top traders (in fact exactly the 1st and 2nd place) both seemingly acting on hidden information, especially when Johnny had just recently been on the NO side made me think that regardless of what it is, <em>something</em> must be up, so I immediately sold my stake back. I only got $40 out due to the price swing from Johnny and transaction fees both ways, but losing $10 is better than losing $50 at least.</p>
</blockquote>

<blockquote>
  <p><strong>10:54</strong> - After idling around this morning, I randomly checked 538 again at 10:43, not expecting anything, and was shocked that they had just updated with a new poll (at 10:38), spiking the average up to 42.2%. I decided to put $34 on YES (at 48%, which is effectively more like 51% accounting for transaction fees).</p>
</blockquote>

<blockquote>
  <p>What still mystifies me though is how zubby and Johnny figured it out so early, assuming this is what they knew about. There was a CBS article about the poll earlier this morning which I saw when I was desperately googling for news earlier, but it wasn’t clear when the poll was taken or whether it was even a new poll, let alone whether 538 would include it, and if so how it would be adjusted and weighted. And even that article came out <em>after</em> zubby’s pump, though before Johnny’s  (obviously, since that happened after I first researched it this morning).</p>
</blockquote>

<blockquote>
  <p>In the past, when I’ve been really confused about why other players are trading the way they are, the answer has often been “Kalshi”. I checked Kalshi, and coincidentally, there is in fact a market specifically for Biden’s 538 approval rating on February 1st (and no other dates until the end of the year). Kalshi’s market is hard to read because they actually have separate markets for multiple bands of possible outcomes, rather than a simple yes/no &gt;42%, but if you add up the yes probabilities for each outcome &gt;=42%, it comes to an implied 52% chance. Of course, there’s no way to see the historical values, so I can’t tell what it was like seven hours ago and whether that would have prompted zubby and/or Johnny’s selling.</p>
</blockquote>

<blockquote>
  <p>Anyway, I definitely didn’t expect the Biden Approval market to be a continued source of volatility, and hopefully profit (though I’ve purely <em>lost</em> money trying to trade it so far today.)</p>
</blockquote>

<blockquote>
  <p>Also, I’m surprised that Josiah Neeley hasn’t made it back into the top 20. He disappeared from the leaderboards after the market tanked on Friday, but he should be climbing back up now, because at least eyeballing the bet history, he didn’t sell out at the bottom like I did and should still be holding lots of shares.</p>
</blockquote>

<blockquote>
  <p><strong>11:11</strong> - I just used my Python script to find Josiah’s ranking and found that he is currently in 29th, but would be 12th if Biden immediately resolved YES. It looks like he also put a lot of money into PredictIt survival on the NO side back when it was in the 20-30% range. I’m not even sure what that is for him now, a triple-whammy? quadruple? All I can say is I’m glad I’m not him. I also discovered that despite their selling, Johnny and zubby both still have huge NO stakes on Biden Approval. If it resolves YES, Johnny would still comfortably be first but zubby would fall to 4th place. Also, Dylan Levi King is now down to 71st place (I modified my script to show the ranks of everyone I put names to, not just the top 20, to find Josiah’s current rank.) How the mighty have fallen (IIRC, he was 12th back in December). Him, I can’t feel sorry for though, since he repeatedly squandered money in obviously dumb trades across many markets. The worst though is someone named Mike Aniello, who is in 905th place with only $0.4216. Obviously, he must have gambled everything on a risky bet and lost.</p>
</blockquote>

<blockquote>
  <p><strong>21:48</strong> - … Later this evening, I spent over half an hour unsuccessfully trying to debug the further leaderboard discrepancies in Salem. My script’s predictions now differed from the public leaderboard in three ways - 5th and 6th (Connor and David) were swapped, as were Stevie Miller and Henri Lemione in 15th and 16th, and I had Adrien Kelley inserted in 19th as well.</p>
</blockquote>

<blockquote>
  <p>However, this time, all the relevant balances matched the page source, so I had nothing to go off of. It seems like it will be basically impossible to debug these discrepancies without more information, and there’s no way to get that information, so eventually, I was forced to just give up.</p>
</blockquote>

<blockquote>
  <p>Also notable was that in an unprecedented extreme coincidence, my portfolio value was only about $0.1 below 10th place (Spencer Henderson). Aside from being highly unlikely to have two balances happen to differ only 1 part in 35000, it also provided yet more evidence that the portfolio value calculations are correct. If the site is somehow miscalculating them, it would have to happen to be in a way that favors Spencer. But I doubt they’re actually off. However, it’s hard to think of what else it could be. It’s weird that it only affects a few people with no apparent pattern, and there are no discrepancies in the cash balances. I wish I knew what was going on.</p>
</blockquote>

<blockquote>
  <p>I also commented asking zubbybadger how they knew to dump Biden this morning <em>before</em> the 538 update, and they explained</p>
</blockquote>

<blockquote>
  <p>“I saw Chuck Todd talking about the NBC poll on GMA on twitter. The CBS poll dropped like 30 minutes later which was a complete surprise to me, which made me sell a lot more. Those were probably the 2 worst polls for the No holders to get. Solely on vibes, I think No wins, but it’s pretty much a coin flip at this point.”</p>
</blockquote>

<blockquote>
  <p>It seems that they basically just got lucky. I assume that Johnny’s later selling was based on the CBS article about the poll, which was out at the time, even if the 538 average hadn’t been updated yet. It’s amazing how good other people are at finding out about news stories quickly (and assessing them correctly - I didn’t take the CBS article seriously myself.)</p>
</blockquote>

<blockquote>
  <p><strong>30.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:56</strong> - I checked again (among many other times today of course when there was no update) at 2:48pm and found it had updated again at 2:43, back up to 42.3%. The market was back down to 81%, but you can’t really profit off tiny swings like that thanks to transaction fees, and I wished I had not sold out (of course hindsight is 20/20 - it could have just as easily gone <em>down</em> further rather than back up, in which case I’d have been praising my genius.) At 2:50, while I was still agonizing over whether to buy back in or not, a rando bought it up to 82%, and so I decided to stay out for now.</p>
</blockquote>

<blockquote>
  <p>There haven’t been any trades since. It will be interesting to see what happens over the next day or two. It ends at 6am on Wednesday, and 538 <em>usually</em> doesn’t add new polls before 6:30, but it could very easily add a new poll or two tomorrow. I’m hoping that the probability doesn’t go too close to 100% before the outcome becomes clear, so I can buy in and make a small fast profit.</p>
</blockquote>

<blockquote>
  <p>In other news, someone filled a $100 YES limit I put down on PredictIt at 92% a few days ago. I figured it was worth putting in a limit just below the market price because someone holding a lot might need to sell out for liquidity. Of course, it’s unfortunate timing because it would be useful for <em>me</em> to have the liquidity right now, since it would have been better to throw it into Biden Approval tomorrow (and/or Wednesday morning). Oh well.</p>
</blockquote>

<h2 id="the-final-blow">The final blow</h2>

<p>After work on the 31st, the two weeks of continual bad news were capped off by the greatest misfortune of them all - the China COVID market had suddenly spiked <em>up</em>. I had accumulated a large NO position in the market over the last month of trading, and there was no way I could recover from such a heavy loss. I was out of the contest for good… or so I thought.</p>

<blockquote>
  <p><strong>31.01.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>17:20</strong> - Welp, so much for Salem. I checked Salem after work ~5:09, and was shocked to see that Johnny had just dumped the China COVID market up to 88%. I checked OWID and the Github issue and googled for news reports, but didn’t see an explanation, and figured that since since I’m already invested so heavily in the market, I might as well double down, and put my last $152 in, then sold some other shares and put more in.</p>
</blockquote>

<blockquote>
  <p>Afterwards, I looked for other issues in the same Github repo out of curiosity, and discovered a comment posted at 5:04 in another issue saying</p>
</blockquote>

<blockquote>
  <p>The WHO COVID-19 Dashboard has updated China cases and deaths: https://covid19.who.int/region/wpro/country/cn</p>
</blockquote>

<blockquote>
  <p>We’re working to bring this data into our repository but need to rectify some conflicts with data for Hong Kong SAR. For now, I recommend observing the WHO dashboard for mainland China COVID-19 data.</p>
</blockquote>

<blockquote>
  <p>The linked dashboard shows millions of cases in December, so this seems to imply that the market is a guaranteed YES now. However, there was nothing I could have done anyway. Even if I sold, I’d be so far behind that I don’t have any chance of winning anyway. I guess at least I can stop worrying about Salem now. It will be really weird to not have that in my life any more.</p>
</blockquote>

<blockquote>
  <p>In other Salem news, 538 updated to 42.4% this morning. I was shocked when I randomly checked Salem again around 11:13 and saw that zubby and Johnny had sold from 89% down to 75% again for no apparent reason. I checked Google, Twitter, etc., but couldn’t find anything. A few minutes later however, I checked 538 again, and it had updated at 11:16, taking the polling average down to 42.1%.</p>
</blockquote>

<blockquote>
  <p>I spent another 15 minutes unsuccessfully searching Twitter for news of new polls that could have triggered the selloff, then checked back on Salem and discovered that zubby and bought back up to 88% at 11:17, leading to the following exchange of comments:</p>
</blockquote>

<blockquote>
  <p>RG: @zubbybadger Man, you and Johnny are giving me a heart attack, suddenly selling it down to 75% and back for no apparent reason. I kept searching Google and Twitter to try to figure out what you knew, but I came up empty.</p>
</blockquote>

<blockquote>
  <p>ZB: @RobertGrosse Very curious if he knows what’s going on or if he’s just tailing me lol. Pew released a poll at 38%. It wasn’t enough to bring us under, but I thought it would be close. I don’t have anything else on my list that’s[sic] could be dropping today and 538 doesn’t usually update until after 9 AM. You never know though!</p>
</blockquote>

<blockquote>
  <p>J10N: No idea what’s going on, just blindly following Kalshi, which is at like 70%: https://kalshi.com/events/538APPROVE-23FEB01/markets/538APPROVE-23FEB01-B41.2/</p>
</blockquote>

<blockquote>
  <p>But yeah that resolution is a later[sic] in the day so maybe that’s the difference. And I am starting to worry that the Kalshi market is just you @zubbybadger in a wig.</p>
</blockquote>

<blockquote>
  <p>ZB: @1941159478 Lol respect for admitting that. Yeah I’m in the Kalshi market and heavily invested there. Tomorrow we get another Rasmussen, Yougov/Economist, plus the possibility for a couple other heavily weighted polls (Monmouth and Fox especially). Unfortunately all of those are likely to show up after 9 AM EST. I think the NO side’s best bet is something random in the next couple of hours (maybe Yahoo?) or AP-NORC at midnight.</p>
</blockquote>

<blockquote>
  <p>RG: @zubbybadger Wow, it sounds like you are incredibly knowledgeable and invested in this. And I thought I was clever just by checking the 538 average periodically to see if it goes up or down.</p>
</blockquote>

<blockquote>
  <p>ZB: @RobertGrosse Yeah, I didn’t even play this right though. Those polls over the weekend caught me completely off guard. I still might have set myself up to lose if there’s something coming that I don’t know about!</p>
</blockquote>

<blockquote>
  <p>I was amazed to see just how much more advanced zubby was than I, though even zubby failed to predict most of the wild gyrations in the polling average lately. Anyway, it’s all moot now, sadly.</p>
</blockquote>

<blockquote>
  <p><strong>18:42</strong> - I just sold my Biden and Bakhmut shares to free up $199 and put a $199 NO limit at every 1% interval from 99% down to 75% (by hand). With that many limit orders, it could absorb nearly infinite sell pressure. Hopefully if people decide to start selling again, I’ll rack up a huge position and either end up in 1st place or last. And <em>now</em> I can completely forget about Salem until March and then check and see if by some miracle it resolved NO. But in any case, it will at least make things interesting for the other market participants, basically a windfall to whoever notices first and has the most free cash to take advantage.</p>
</blockquote>

<blockquote>
  <p><strong>22:11</strong> - … I also unfollowed Trump on Twitter and uninstalled the Twitter app this evening, now that I’m no longer playing Salem.</p>
</blockquote>

<h1 id="february">February</h1>

<p><img src="/img/salem2/feb.png" alt="Score graph" /></p>

<p>I thought I had already lost at the end of January, and decided to completely ignore Salem for the month of February and then check in again in March just in case a miracle had happened.</p>

<p>I disabled all notifications from Salem, stopped checking the site, and enjoyed a peaceful month wasting all my time on other pursuits instead of wasting it on Salem.</p>

<p>The rankings in my absence were pretty volatile though. As it turned out, far from quickly spiking to 99% and then resolving YES like I expected, the China COVID market swung wildly back and forth over the course of the money, before finally closing at 5%. These gyrations took me as low as 26th place and as high as 6th, but I ended up in 7th place in the end.</p>

<h2 id="duplicate-payouts">Duplicate payouts</h2>

<p>In late January, as a side effect of investigating the leaderboard discrepancies, I figured out that the “US GDP Growth over 4% in any Quarter 2022?” market must have accidentally been resolved <em>twice</em>, giving NO bettors twice as much money as they should have won. I didn’t even know this was <em>possible</em> on Manifold. Fortunately, when I commented about this, the staff ran a script to undo the effects and subtract the relevant amount from each person’s balance.</p>

<p>While I was away in February, the same thing happened <em>again</em>, in the “Will PredictIt Survive?” market. This time, it fell to Zubby to notice and report the problem, which was likewise quickly reversed.</p>

<h1 id="march-1-15">March 1-15</h1>

<p><img src="/img/salem2/mar1.png" alt="Score graph" /></p>

<p>Apart from the initial shock of returning to Salem and finding out that I’d actually won, the first half of the month was quiet, with me only making a few minor bets. I did however spend a lot of time trying to reverse engineer the leaderboard score adjustments.</p>

<h2 id="the-return">The return</h2>

<p>I couldn’t believe my eyes when I checked Salem again at the beginning of March. However, there ended up being several days of suspense because Salem inexplicably failed to actually resolve most of the end-of-February markets.</p>

<blockquote>
  <p><strong>01.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:40</strong> - Salem - Back at the end of January, I’d assumed that I was toast, so I just yolo’d everything into NO limits on the China COVID market just in case a miracle happened, and then decided to completely avoid checking Salem until March, so I’d find out what happened one way or nothing.</p>
</blockquote>

<blockquote>
  <p>I expected the most boring case to be what happened (it resolves YES, hardly anyone buys my limits), and when I checked as planned this morning, my first sight was a balance of $-130, so I assumed that was what happened, until I looked at the markets and saw that China COVID was at 5%! Somehow, the market hasn’t resolved yet, but people think it is going to resolve NO after all. My “portfolio value” is now over 7k, and I’m in 7th place on the leaderboard. Although it’s a bit weird, since this implies that all my “sure thing” end of February bets that I didn’t sell somehow lost. I’m going to have to keep looking into it to figure out what happened, but my heart started pounding as soon as I saw that, and I figured I should immediately note this down. I guess now I need to start actively following Salem again, since I have a decent chance of winning again.</p>
</blockquote>

<blockquote>
  <p><strong>07:07</strong> - Looking at the comments on Salem, it looks like the last month was a rollercoaster, so it’s a good thing I didn’t have to worry about all that. Anyway, it sounds like the current state is that OWID is still showing 0, but the spreadsheet the data is based on shows &gt;100k cases, and they may or may not update it in the future. The end-of-February markets all closed, as programmed, but they haven’t been resolved yet for some reason, not just China COVID, but also US Covid and Mask Mandates. (Which is also the reason why they didn’t show up on my portfolio page as mentioned earlier.) In any case, I can’t actually do anything on Salem, so I guess I just have to wait and hope they resolve NO.</p>
</blockquote>

<blockquote>
  <p>One other weird thing is that of the limit orders I left, only the 75%, 76%, and part of the 77% limits were filled, even though the prices subsequently went up to 82%. Presumably, someone from Salem decided that my limit orders weren’t serious and arbitrarily canceled them, but it’s weird that they wouldn’t leave any sort of comment or notification about that.</p>
</blockquote>

<p>Note: At the time, I assumed that my limit orders had been manually canceled by admins. It was only after the contest was over that I found out that Manifold <em>automatically</em> <a href="https://github.com/manifoldmarkets/manifold/blob/0e62922331bb1c31070c2ddb1ea67f9d9d08487f/common/src/new-bet.ts#L218">cancels your limit orders once your balance goes below zero</a>. So your balance can go negative via limit orders, but only by the amount of a single bet.</p>

<blockquote>
  <p>P.S. The “Debt Limit raised” market is down to 56% from a high of 77%. It doesn’t affect me Salem-wise, since I never bet in it, but it seems like ominous news as far as the actually important state of the world goes.</p>
</blockquote>

<blockquote>
  <p><strong>10:33</strong> - I just decided to check Salem again, as I couldn’t resist thinking about it, and turned on email notifications for market resolutions. There isn’t anything I can do on Salem until the markets resolve anyway, so I might as well get notifications so I don’t have to keep worrying about it. Incidentally, not <em>all</em> of the February markets have failed to resolve. The “Russia to control Bakhmut” market, which was also supposed to end on Feb 28 did resolve on time, so it’s not like the Salem team is just asleep or something. No idea why the other three haven’t resolved yet. If it was just China COVID, I could understand it due to being ambiguous, but there’s no controversy over the outcomes of the other two markets. Oh well, it’s not like I can do anything but wait.</p>
</blockquote>

<blockquote>
  <p><strong>22:03</strong> - … I really hope I didn’t use up all my luck with Salem (though the longer Salem goes with the markets stuck unresolved, the more uncertain it seems).</p>
</blockquote>

<blockquote>
  <p><strong>02.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:06</strong> - Salem: The Mask Mandate market resolved overnight, but the other two are still unresolved. Also, the oil price market, which closed March 1st, is stuck unresolved as well. It’s so odd, the way they’re resolving some markets and not others for no apparent reason. They also resolved the Peter Obi market. With the mask mandare market finally resolved, I have a positive balance again, so I could technically start trying to gamble again, but I don’t think it’s worth it, especially as I won’t even know whether I’m in the running until China COVID resolves.</p>
</blockquote>

<blockquote>
  <p><strong>03.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>00:27</strong> - …After work, I got home to an email notifying me that China COVID had finally resolved (NO). It was dated 8:40am, but of course I don’t have internet access at work. So I’m back in the game as far as Salem goes. I re-installed the Twitter app and followed Trump again, though I don’t expect him to actually tweet this month and don’t expect to win the race even if he does. I haven’t touched anything else yet though - hopefully I’ll be able to figure out a strategy after looking at things over the weekend.</p>
</blockquote>

<blockquote>
  <p>The US Covid and Oil markets are still stuck unresolved for some reason, and I have a chunk of money tied up in the former, but I’m not worried about that now, as China was the important one, and I have $6235 in free cash now (with a portfolio value of $7,448). It’s a bit dismaying that my balance is now high enough to have been good for second place (IIRC) when I left a month ago, but now only puts me in 7th. It’s such a Red Queen’s Race. Also, I looked at the history and it turns out the China COVID market peaked at 87%, not 82% like I said before. It’s annoying that the admins stepped in and canceled my limit orders, since I would have made serious bank if they had been filled. But I guess I can’t complain too much, since I never expected to win in the first place and thought I had lost for good and was just hoping to at least go out in style and not expecting to achieve even that.</p>
</blockquote>

<blockquote>
  <p>Also, I got “Smartest Money” and “Proven Correct” on the China COVID market. In a deep bit of irony, the Proven Correct comment was my resignation comment, “Welp, I guess I’m out as far as this competition goes. It was nice knowing you all. Even if I sold I’d be so far behind that I can’t win anyway.”. I’m so glad to have been proven incorrect!</p>
</blockquote>

<p><img src="/img/salem2/china_covid_proven.png" alt="Score graph" /></p>

<h2 id="the-leaderboard-discrepancy-hunt">The leaderboard discrepancy hunt</h2>

<p>Once the weekend arrived, I could plug in my desktop (see above) and start trying to hunt down the leaderboard discrepancies again:</p>

<blockquote>
  <p><strong>04.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>14:05</strong> - I haven’t been looking at Salem much, but I got the emails this morning that the last two stuck markets had finally resolved. I finally got around to firing up the computer to check the standings this afternoon.</p>
</blockquote>

<blockquote>
  <p>When I last checked on Jan 29th, 8:14pm, the standings were (per my script)</p>
</blockquote>

<blockquote>
  <p>1) Johnny Ten-Numbers   11909.6212543</p>
</blockquote>

<blockquote>
  <p>2) zubbybadger  8005.88716964</p>
</blockquote>

<blockquote>
  <p>3) Ben  7537.06524301</p>
</blockquote>

<blockquote>
  <p>4) Mark   7485.39806775</p>
</blockquote>

<blockquote>
  <p>5) David Hassett  5837.63273154</p>
</blockquote>

<blockquote>
  <p>6) Connor Pitts   5737.61252569</p>
</blockquote>

<blockquote>
  <p>7) ussgordoncaptain   4975.49057389</p>
</blockquote>

<blockquote>
  <p>8) Krum-Dawg Millionaire  3724.91205728</p>
</blockquote>

<blockquote>
  <p>9) Asher Gabara   3623.72040371</p>
</blockquote>

<blockquote>
  <p>10) Spencer Henderson   3517.12434972</p>
</blockquote>

<blockquote>
  <p>11) Robert Grosse   3517.01782341</p>
</blockquote>

<blockquote>
  <p>12) Jack G-W  3106.81841568</p>
</blockquote>

<blockquote>
  <p>13) Iraklis Tsatsoulis  2754.16388399</p>
</blockquote>

<blockquote>
  <p>14) Max   2698.67223969</p>
</blockquote>

<blockquote>
  <p>15) Henri Lemoine   2619.22840724</p>
</blockquote>

<blockquote>
  <p>16) Stevie Miller   2593.35918722</p>
</blockquote>

<blockquote>
  <p>17) Zach Viglianco  2550.02611026</p>
</blockquote>

<blockquote>
  <p>18) Nate Stover   2417.08414792</p>
</blockquote>

<blockquote>
  <p>19) Adrian Kelly  2397.42475241</p>
</blockquote>

<blockquote>
  <p>20) Sam Dittmer   2381.50076577</p>
</blockquote>

<blockquote>
  <p>When I checked again at 2pm today, they are now</p>
</blockquote>

<blockquote>
  <p>1) Johnny Ten-Numbers   9364.13773078</p>
</blockquote>

<blockquote>
  <p>2) zubbybadger  9168.2494107</p>
</blockquote>

<blockquote>
  <p>3) Mark   8682.97902346</p>
</blockquote>

<blockquote>
  <p>4) David Hassett  8008.54652802</p>
</blockquote>

<blockquote>
  <p>5) Connor Pitts   7825.06048076</p>
</blockquote>

<blockquote>
  <p>6) Ben  7627.37493567</p>
</blockquote>

<blockquote>
  <p>7) Robert Grosse  7489.07083312</p>
</blockquote>

<blockquote>
  <p>8) ussgordoncaptain   6126.38597093</p>
</blockquote>

<blockquote>
  <p>9) Zach Viglianco   5012.44230592</p>
</blockquote>

<blockquote>
  <p>10) Krum-Dawg Millionaire   4532.57009935</p>
</blockquote>

<blockquote>
  <p>11) Josiah Neeley   4092.7755846</p>
</blockquote>

<blockquote>
  <p>12) Stevie Miller   3579.11266493</p>
</blockquote>

<blockquote>
  <p>13) Spencer Henderson   3466.98127927</p>
</blockquote>

<blockquote>
  <p>14) Asher Gabara  3317.53597191</p>
</blockquote>

<blockquote>
  <p>15) Alvaro de Menard  3058.86012968</p>
</blockquote>

<blockquote>
  <p>16) Jack G-W  2976.78286778</p>
</blockquote>

<blockquote>
  <p>17) Henri Lemoine   2945.66674254</p>
</blockquote>

<blockquote>
  <p>18) Sam Dittmer   2803.73086904</p>
</blockquote>

<blockquote>
  <p>19) Charles Paul  2668.23401361</p>
</blockquote>

<blockquote>
  <p>20) Oliver S  2604.34321508</p>
</blockquote>

<blockquote>
  <p>Of course, these need to be taken with a grain of salt, since there have been persistent unexplainable discrepancies in the data since mid January. In particular, the leaderboard has shown zubby in first and Johnny in second ever since I checked in on March 1st. My rankings also have Connor and David swapped compared to the official rankings, though there are no swaps at the bottom of the table for once.</p>
</blockquote>

<blockquote>
  <p>The good news is that the top 7 are closer than I feared. If only the admins hadn’t canceled my limits early, I might very well be in first now, but there’s no sense in continuing to lament that. The real challenge will be figuring out how to get ahead (or even stay ahead) going forward.</p>
</blockquote>

<blockquote>
  <p>Incidentally, the comments indicate that the PredictIt market also resolved twice (in mid-February while I was gone), but the commenters fortunately noticed and got the staff to fix it on their own.</p>
</blockquote>

<blockquote>
  <p><strong>14:52</strong> - I checked the cash balances against those from the leaderboard page source again, but as I expected, they matched exactly like usual. Back when the discrepancies first started, I thought that if it weren’t a cash difference, there must be some difference in the market probabilities used to calculate the portfolio values, but there was never any pattern in the holdings of those affected by the swaps, so it didn’t seem plausible.</p>
</blockquote>

<blockquote>
  <p>Fortunately, I had a new hypothesis - if it’s not cash or market value, it must be some adhoc per-user adjustment. Specifically, back when the contest first started, there was a lot of chaos due to low liquidity and people not understanding how Manifold worked, and people complained that it was unfair that a few users who happened to be lucky on the first day profited immensely from these errant trades. Therefore, the organizers announced that they would subtract off people’s winnings from the first day for scoring purposes, but still let people keep the money (so they still have an edge with a higher bankroll).</p>
</blockquote>

<blockquote>
  <p>I thought perhaps they only got around to implementing that in mid-January, thus causing the discrepancies. I modified my script to simulate the standings after the first day of the contest, and then subtracted them out from the scores, and sure enough, it caused my projected leaderboard to finally match. Of course, it is hard to say this is correct with confidence with only one datapoint, and I may be somewhat off on the exact time they checked the scores to calculate the adjustments. However, it is notable that the top 20 after the first day included Johnny, Adrian Kelly, Mark, David Hassett, and Henri Lemoine (and no other users I’ve been tracking). I believe that set neatly accounts for one member of every discrepancy that I recall seeing before, so it seems likely that this is the answer after all. It’s nice to finally solve that mystery.</p>
</blockquote>

<h2 id="first-bets">First Bets</h2>

<p>After the 4th, I didn’t write about Salem again until the 12th, as I basically wasn’t doing anything in early March. On March 12th, I wrote the first code to try to reverse engineer the leaderboard score adjustments, and also made my first minor bets for March.</p>

<blockquote>
  <p><strong>12.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:15</strong> - The main news is that after lunch, I finally spent a couple hours on Salem. First off, just for fun I wrote some code to automatically put bounds on the adjustments for affected players by calculating what the minimum and maximum possible adjustment they could have without changing the displayed top 20. I figured that the adjustments I estimated before probably aren’t exact, since I don’t know which time point they used, so it would be nice to see if they could be bounded directly. Over time, as people’s portfolio values bounce around, the calculated bounds should be narrowed down. However, it is hard to get much data like this unless the leaderboard happens to get really shaken up again.</p>
</blockquote>

<blockquote>
  <p>After that, I finally spent time looking into the current unresolved markets and trying to decide what to do next. The markets now are relatively boring, but there are two notable markets, for the Chicago mayor race and Wisconsin supreme court race, both on April 4th. There’s also another Biden approval 42% market for April 1st, but there’s unlikely to be much drama or profit opportunity there, as he’s currently sitting at almost 44% on 538. (Then again, that’s what I thought last time!)</p>
</blockquote>

<blockquote>
  <p>I still don’t have any plans and don’t see any good profit opportunities, but I did make a few small bets just for the sake of it - $600 on Russia to hold Melitopol on 3/31 (96%) and $100 on Vallas for mayor (65-&gt;66%), plus an additional $100 limit just below market on both.</p>
</blockquote>

<blockquote>
  <p><strong>13.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:45</strong> - I made some more bets on Salem this evening - $200 each on Trump Twitter (16-&gt;14%) and Biden Approval (82-&gt;84%).</p>
</blockquote>

<blockquote>
  <p><strong>15.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>01:09</strong> - Salem remains quiet. Tonight I put down $140 on Trump indictment at 69%. Conveniently, the market was at a limit order, and thus it was actually 69%, so this is equivalent to buying in at ~66% under normal circumstances.</p>
</blockquote>

<h1 id="march-16-31">March 16-31</h1>

<p><img src="/img/salem2/mar2.png" alt="Score graph" /></p>

<p>As of March 4th, things were looking pretty good for me. I was up to seventh place, and the top six were relatively closely packed ahead of me. In fact, I was only 22.4% away from first place ($9168 vs $7489)! Sadly, Zubby and to a lesser extent, Johnny soon started running away again.</p>

<p>Although I was officially in 7th place, I knew I was effectively in 6th because 6th place was Ben, who was a) barely ahead of me and b) not doing anything, and thus I knew that I would naturally pass him eventually even with just safe bets. However, my goal was to get into the top 5, which would be much tougher, and March ended up going pretty badly for me, especially at the very end. I was very conservative in March, so my balance barely changed, while the other top 5 players raced ahead of me, putting them much further out of reach.</p>

<h2 id="the-trump-twitter-blip">The Trump Twitter blip</h2>

<p>As in January, I checked the Salem website frequently in March, hoping to happen to be the first person to see a major dumb money spike and thus the one to profit by trading against it. However, I didn’t have any luck on that front. In fact, it actually <em>backfired</em> for me, as I managed to catch a “lucky” dip during the short-lived spike in the Trump Twitter market and sold out. But it immediately went back down again and I would have done a lot better if I hadn’t been “lucky” enough to see that dip and I’d never sold in the first place.</p>

<blockquote>
  <p><strong>17.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>18:02</strong> - Salem: Since I got back into Salem last week, I’ve been checking it several times a day, but it was eerily quiet up until today. The first bit of drama happened late this morning. When I checked around lunchtime, I saw that someone had bought Newsom to Run for President (by June 1st) from 17% up to 41% an hour and a half before. Sadly, Johnny and zubby had already pushed it back down to 22%. Even checking several times a day, I’m always late to the party.</p>
</blockquote>

<blockquote>
  <p>Even months ago, I’d concluded that the chance of Newsom running was effectively zero, but there was no way to profit from the market, since betting against it would mean tying up your money until June, and back in January, I was desperately short of capital and had more profitable short-term opportunities anyway. This time however, I have a much larger bankroll (and June is a bit closer), so I threw in $100 to bump it down to 21%.</p>
</blockquote>

<blockquote>
  <p>While I was at it, I threw another $100 on Biden Approval at 88%. I realized to my amusement that the Biden Approval and Trump Tweet markets had nearly the same odds and maturity (it was at 12% at the time), but decided not to bet any more on the latter, as it was too unpredictable compared to opinion polls.</p>
</blockquote>

<blockquote>
  <p>This evening when I checked after work, I saw Trump Tweeting had spiked to 37%, with the run starting at 1:19pm (i.e. not that long after the lunch session). It looks like the reason is because Trump posted to Facebook this afternoon, and thus it suddenly looks like he’s likely to tweet too. Sadly, I’m late to the party as usual. I decided to stay put for now and pray I get lucky, but the next few weeks are certainly going to be nerve wracking. At least I only had $200, but losing that much is still painful, when profit opportunities are so slim. I was only like $200 behind 6th place these last couple weeks, and still trying to figure out how I could even make that up with all the markets so quiet and no obvious opportunities for big profits besides the Vallas election.</p>
</blockquote>

<blockquote>
  <p>Incidentally, Trump Indictment also shot up this evening for no apparent reason, going from 71% to 80%. Anyway, that’s the Salem news, a fresh source of worry as I’ll probably be checking even more obsessively for the next couple weeks than I had been.</p>
</blockquote>

<blockquote>
  <p><strong>18.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:03</strong> - On the Salem front, I had a remarkable stroke of luck Friday night. I decided to check Salem one last time before going to bed, and saw that Trump Twitter had both gone up slightly (as well as Trump Indictment). I opened up the bet history to check who had pushed it up (Connor Pitts), but even as I had the page open, a new bet came in. Some random person had put $999 on NO just seconds ago, sinking it from 38% down to 23%.</p>
</blockquote>

<blockquote>
  <p>I decided to buy $60 of YES (23-&gt;25%) in order to close out my position at a low price while I still could, since the way the market had been going, I assumed it would quickly be pushed back up to the high 30s. I didn’t expect it to revert <em>that</em> quickly though - just a minute later, Connor bought it back up to 35%. He must have still been on the site from when he made his previous trades 25 minutes before.</p>
</blockquote>

<blockquote>
  <p>I kicked myself for not buying more than $60 so I could flip the extra at a profit, but of course hindsight is 20-20. I was a lot less regretful this morning when I got up and saw that it was down to 31%. It seems that the Zubby-Johnny duo had cooled on it again. The shallow decline belied the volatile trading overnight, as it went up to 44% and down to 27% during the night. However, there hasn’t been a single trade all day since I got up.</p>
</blockquote>

<blockquote>
  <p>This evening, I checked the leaderboards and noticed that Connor had climbed from 5th to 3rd (presumably on the strength of his recent massive bets on Trump Indictment, currently at 91%). I got on the desktop and ran the stats script again, hoping that the leaderboard flux would help narrow down the bounds on everyone’s first day adjustments.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, the adjustment bounds are still extremely wide, because the only way to get it really narrow is if I happen to run it when two relevant users happen to be very close to each other. Still, it was enough to resolve one question - whether those unlucky enough to lose money on the first day (as Spencer did) had their standings adjusted upward. I didn’t think they would, but it was nice to have confirmation.</p>
</blockquote>

<blockquote>
  <p>I also discovered that Zubby is now ahead of Johnny even without the latter’s downward adjustment. I also added code to the script to calculate how far I was from 5th place. I’m currently 4.4% ($329) away, down from 5.1%/381 last week.</p>
</blockquote>

<blockquote>
  <p>I also ran the numbers if Vallas won or lost and found that for one, I was the beneficiary of the paradox. If he wins, I’ll be 2.6%/198 away, but if he loses, I’ll still be only 3.3%/240 away, and in sixth place either way. The reason is that the current 5th, David Hassett, has a huge YES position on Vallas. If he wins, David will shoot up to 2nd. If he loses, I’ll lose my bet, but still get closer to 5th because David will fall to a distant 7th, so I’d only have to catch up to Ben, the current 6th place.</p>
</blockquote>

<blockquote>
  <p><strong>19.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>10:45</strong> - Salem: Connor dumped $2013 of Melitopol overnight for no apparent reason. I’d bought $100 yesterday, and thus regretted not putting in a limit instead, but of course hindsight is 20/20. It’s also a bit silly to regret just $1-2 of forgone profit while ignoring the uncertain markets where vastly larger sums are won and lost. Speaking of which, Trump Twitter was down to 23% this morning (now 24%). It has fallen a lot faster than I expected on Friday. In retrospect, I would have been better off if I hadn’t gotten “lucky” and dumped it at a loss Friday night.</p>
</blockquote>

<blockquote>
  <p>However, I was still happy to see Connor’s sale because the transaction fees heavily penalize cashing out high probability bets, and it’s always nice to see a competitor stumble. I’ve long ago given up on catching up with Johnny or Zubby, but 3-6th (Mark, Connor, David, and Ben) are my primary competition right now (8th+ are far enough behind that there’s little immediate risk there). If anything, when I see the highly active ZB+J duo taking profits, I’m disappointed that it wasn’t me but relieved that at least the money isn’t going to anyone else.</p>
</blockquote>

<blockquote>
  <p>Normally when someone cashes out of a sure-thing bet like that, it is because they need the money to invest in a different, more profitable opportunity, but it appears that Connor just sold out for no reason and kept everything in cash.</p>
</blockquote>

<blockquote>
  <p>To figure out what happened, I fired up the stat script again this morning and discovered that my rankings now had Henri and Stevie swapped (in 17th and 18th), thus confirming for the first time that my adjustment numbers don’t exactly match the ones actually being used.</p>
</blockquote>

<h2 id="adjustment-reverse-engineering">Adjustment reverse engineering</h2>

<p>I didn’t have much luck actually <em>trading</em> in March, but I also devoted considerable time and thought to reverse-engineering the leaderboard score adjustments, and had a bit more luck there, though I wasted a lot of time on data collection practices that later turned out to be pointless as I came up with better ideas instead.</p>

<blockquote>
  <p><strong>20.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:52</strong> - Salem has been quiet, but I noticed this morning that Connor was back up to 3rd on the leaderboard. I had already shut down my computer last night, but decided to fire it back up to run the stats, since I assumed the fact that he had changed rank again meant that he must be close and this would help narrow down the adjustments. Sure enough, David Hasset became the second person after Henri to have accumulated bounds that no longer include my calculated adjustment value.</p>
</blockquote>

<blockquote>
  <p>The new bounds for David are -291.8 to -194.1, while my estimated adjustment was -189.8. Henri was unchanged at -60.8 to 31.1 (-73.0). Johnny was also unchanged at -1477.2 to -195.9 (-914.7). It’s hard to get tight bounds for the higher ranks, especially Johnny, since the bounds can only be narrowed down if he happens to get really close to another player. And Henri’s bound still includes 0 (obviously I now know that there are no positive adjustments, but I figure I might as well leave the upper bounds above 0 for consistency.)</p>
</blockquote>

<blockquote>
  <p>I also lost a bit of ground against 5th place (now ~5.7% behind), due to Connor, Mark, and David moving up, though I can’t tell the exact numbers since Mark and David have unknown adjustments. Ben, who is still 6th, has done essentially nothing for weeks, and I’ve effectively already passed him, but my goal is top 5, not top 6, so that is largely irrelevant (it just helps in the sense that Ben staying put means that I at least only have three competitors in the Red Queen’s Race rather than four.)</p>
</blockquote>

<blockquote>
  <p><strong>21.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:25</strong> - On the Salem front, I checked the leaderboard again around noon yesterday and discovered that Connor was back in 5th. I wanted to immediately boot up the computer and update the adjustment bounds, but of course I couldn’t do that during work, so I did it after work ~5:15. Fortunately, nothing much had changed since noon. Mark became the third person after David and Henri to have confirmed that my estimated adjustment is incorrect.</p>
</blockquote>

<blockquote>
  <p>As usual, the markets have been quiet. I’ve been checking the news several times a day though to try to get hints about when the Trump indictment might come down. It’s probably pointless, but the biggest potential profit opportunity is if I can somehow be the first person to break the news. It seems very unlikely, but I have to at least try. It sounds like nothing is expected today though.</p>
</blockquote>

<h2 id="the-second-biden-dip">The (second) Biden dip</h2>

<p>I had a big scare in late March when Biden’s approval rating dipped again and it seemed like we were headed towards a repeat of January.</p>

<blockquote>
  <p><strong>17:56</strong> - After getting up, I checked 538 and noticed that Biden’s approval had slipped to 43.5%. I hadn’t been checking it regularly, since it was so high and stable, but I decided to check again today. It was concerning, but I decided to hold, since buying and selling incurs high costs and I learned the hard way back in January that overreacting to every little bump is a fool’s game.</p>
</blockquote>

<blockquote>
  <p>Not too long afterward, zubby sold it from 90 down to 87%. I bought an additional $100 yesterday morning, which was unfortunate timing. I wish I’d waited, but of course hindsight is 20/20. I checked 538 again this afternoon and it was down to 43.4%. I got on my desktop and ran the stats again in case the fall had jiggled the positions enough to narrow down people’s adjustments.</p>
</blockquote>

<blockquote>
  <p>Also this afternoon. Josiah Neelely put $1000 into Trump Indictment, bumping it up to 92% (they seem to barely move even with large amounts of money when they’re so close to 100%). Someone else bought Trump Twitter from 21% to 24%, which was another minor bit of unfortunate timing, as I’d put in $50 at 21% yesterday.</p>
</blockquote>

<blockquote>
  <p><strong>18:25</strong> - … I checked Salem, and despite no market moves I could see, Connor is back in 4th place, sandwiched between David and Mark. That’d be the perfect opportunity to (probably) narrow down the adjustments, but of course I couldn’t use the desktop even if I wanted to right now.</p>
</blockquote>

<p>Note: I couldn’t use my desktop because the power was out.</p>

<h2 id="linear-programming">Linear programming</h2>

<p>Once the power came back on at my apartment, I fired up the desktop and started reverse engineering the score adjustments again. This time, I had the idea of using a linear programming solver.</p>

<blockquote>
  <p><strong>22:58</strong> - Later tonight, I fired up the desktop and dumped the stats again, as Connor and Mark had traded places again. However, my main plan was to spend the night analyzing the data and seeing if I could develop better bounds.</p>
</blockquote>

<blockquote>
  <p>The first step was to simply re-calculate the bounds (using different, newly written code). When I first started accumulating the bounds estimates, each time I did the update (eight to date, going back to the 12th) I also dumped (to json) the top 20 on the leaderboard and also my calculated portfolio values for every user at the time, with the idea that I could potentially later re-analyze that data with different algorithms.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, the first time (data left over from the 4th, IIRC), I forgot to record the portfolio values, so the running bounds estimates were based on additional data not included in the complete log. This turned out to only matter in one case - the lower bound on Johnny’s adjustment.</p>
</blockquote>

<blockquote>
  <p>The current bounds are (195, 1477), but without the missing data, the lower bound is 0. (Since I know now that all adjustments are negative, I decided to flip the sign and re-define the adjustment as the (positive) value subtracted from the rankings to make things simpler.) Back at the beginning of March when I first checked, he was already in 2nd but still had a higher net work than zubby. However, between the 4th and the 12th, zubby zoomed ahead and now beats Johnny outright, and thus it won’t be possible to put a lower bound on him unless he starts flirting with 3rd place, which seems pretty unlikely.</p>
</blockquote>

<blockquote>
  <p>As it turns out, it looks like I happened to have saved a copy of the leaderboard from March 4th, (as well as January 28th and 29th when I was originally trying to figure out the discrepancy issues.) I could conceivably try to reconstruct what everyone’s portfolio values were at that time and feed that data in, but that’s more work and a lot less reliable.</p>
</blockquote>

<blockquote>
  <p>After writing the new bound calculator script, the next step was to apply linear programming. The original algorithm I’ve been using is pretty stupid. When an adjustment candidate is next to a non-candidate (users who didn’t bet on the first day of the contest are assumed to have no adjustment) on the leaderboard, you can trivially update the lower and/or upper bound on their adjustment based on the difference in their values.</p>
</blockquote>

<blockquote>
  <p>However, when two adjustment candidates are next to each other, this doesn’t work. The original algorithm just conservatively applies the current worst bound to each value when calculating the difference to adjust the bounds for the other. I’d been thinking that it would be a lot better to accumulate bounds on the difference between their adjustments and then feed everything into a linear programming solver. I figured it would probably be overkill, but wanted to try it just to see what would happen.</p>
</blockquote>

<blockquote>
  <p>Anyway, I did successfully get the LP solver working. Since it only applies when two candidates are next to each other in the rankings, I thought it would only be relevant to Mark and David. However, it actually turned out that the only improvement was a slight decrease in the upper bound on Johnny, from 1477 to 1400 (Johnny has been next to Mark and David at various points when I dumped the stats, as Mark/David/Connor have been shuffling around 3-5th the whole time).</p>
</blockquote>

<blockquote>
  <p>Anyway, it pretty much doesn’t actually matter for anything, and I already have pretty tight bounds for Mark and David (404-438 and 194-208), the only ones directly relevant to me, but I thought it would be an interesting experiment, and it was sure more fun than watching Cowboy Bebop would have been.</p>
</blockquote>

<h2 id="biden-approval-1">Biden Approval</h2>

<blockquote>
  <p><strong>22.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:18</strong> - When I checked Salem around 11am, I saw that Trump Indictment had suddenly fallen from 91% to 84% two hours earlier, presumably a result of the news that the grand jury would not be meeting today. I’m so glad that I was conservative and only put in $140 at 69% and had decided to only put in more money once the outcome was certain. I feel bad for Josiah Neeley, who put in $1500 at the top (though I guess it worked out for him in the end on the Biden rollercoaster in late January). I considered selling at 84%, but it seems to me like it is still probable, even if it will take until next week. Later, someone sold down to 81%.</p>
</blockquote>

<blockquote>
  <p>Much more worrying was Biden’s approval rating, which continues to fall. I was alarmed that it had gone from 43.7% to 43.4% to 43.1% in two days, per 538’s tracker. How does this always happen in the final week of the month? And this time, there isn’t even any obvious scandal that could be driving down the numbers. This afternoon, it was down to 43.0, but went back up to 43.1 later.</p>
</blockquote>

<blockquote>
  <p>I did not bother firing up the desktop to dump stats this evening and see if it would further narrow down Mark or David’s bounds, since there’s no real point. What would be more interesting is if the leaderboard got shaken up enough to test some of the other pairings and narrow down bounds on other players, but of course I don’t actually want that to happen from a personal winning standpoint, unless it happens by one of the top 5 players suddenly dropping past me.</p>
</blockquote>

<blockquote>
  <p><strong>23.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:10</strong> - … When I got up, I saw that Biden’s approval had fallen to 42.7%. If I didn’t know better, I’d swear that zubby had a button to magically tank his approval in the final week of every market. I guess all I can do now is anxiously sit tight and pray that it stays/goes back above 42 at the end like it did in January.  It made it hard to concentrate on [Japanese study] this morning, so I stopped early. Hopefully I can avoid worrying about it much though.</p>
</blockquote>

<blockquote>
  <p><strong>24.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:04</strong> - Finally a bit of good news on the Salem front. 538 didn’t update at all yesterday, staying at 42.7, and when I got up, I saw that it was now up to 42.9%. Of course, that doesn’t mean he’s out of danger, but it does reduce the risk. I decided to put in $150 (75-&gt;77%) and hope for the best.</p>
</blockquote>

<blockquote>
  <p>Also, when I checked last night, I cautiously decided to throw $40 more into Trump Indictment (74-75). I don’t understand why it dropped so much. The coverage I’ve read indicates that the delay doesn’t actually affect the chances of an indictment coming down. I wonder if people had overreacted originally.</p>
</blockquote>

<blockquote>
  <p>Trump Twitter also fell to 11% overnight, but I haven’t touched that lately, following my two $50 buys at 21 and 24%. Also, someone bought down Newsom to 19%, the first trade in that market since my own buy back on the 17th. It’s funny because I thought I was taking advantage of a temporary spike to get a good price, but the market is so thinly traded that that turned out to be a complete illusion.</p>
</blockquote>

<blockquote>
  <p>Anyway, I’m not out of the woods yet, but at least I have reason to be more optimistic about my position again.</p>
</blockquote>

<blockquote>
  <p><strong>25.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:54</strong> - Later Friday morning, Connor Pitts threw $1000 into Biden Approval (77-&gt;84). That was at 8:42. At 8:55, zubby sold down to 83%, and at 9:06, Johnny sold down to 80%. It’s amazing how fast they are, particularly zubby (Johnny has seemingly been a lot less active lately).</p>
</blockquote>

<blockquote>
  <p>Then at 11:03, zubby bought it up again, followed by Johnny at 12:27 (for some reason, he’s always behind zubby and thus gets worse prices on each direction), pushing it up to 89 (Josiah later bumped it up at 90 at 4:26pm).</p>
</blockquote>

<blockquote>
  <p>The market bounced back a lot faster than I expected. It’s funny because I was incredibly nervous putting in even $150 on Friday morning, and now I’m kicking myself for not putting in a lot more. Connor basically stole my thunder by being a lot bolder, and he’s probably going to make a lot more than me on the market, despite the fact that I had the “diamond hands” to hold through the dip and was the one who bought at the bottom. On the bright side, it’s nice to see zubby and Johnny look like fools for once.</p>
</blockquote>

<blockquote>
  <p>Meanwhile, the Trump Indictment market is still where I left it over a day ago (a rando threw in $12 yesterday, but it is still at 75%.) I’m beginning to suspect that everyone actually knew something I’m missing somehow after all. I can’t understand why everyone would suddenly think the indictment is much less likely just because of the grand jury delay. It’s funny because when I buy at the dip and everyone pumps it back up, I regret not buying more, but when they don’t, I get nervous, even though I only put in $40. But that’s just hindsight bias of course.</p>
</blockquote>

<blockquote>
  <p>Paul Vallas has been pretty stable, stuck in the 60-66% range for weeks, and I haven’t paid it much attention, but I saw a story yesterday that the polls have narrowed significantly. As usual, I just have to hope for the best.</p>
</blockquote>

<blockquote>
  <p><strong>11:38</strong> - I also threw in $50 more into Biden Approval and Trump Twitter (at 90% and 11%) this morning. It’s ironic that the latter now offers slightly better odds. I wanted to go all in on Biden Approval in my heart, but I realized that logically, the chance of something going wrong in the next six days is probably still at least 9%. In fact, it’s even worse than that, because with Melitopol at 96%, that means there is a risk-free return of ~3% so the effective return on Biden is only like 6% now.</p>
</blockquote>

<blockquote>
  <p>Anyway, after breakfast, I spent an hour or two working on the Salem scripts again out of curiosity, even though the adjustment estimation stuff is completely useless. I solved the unknown time problem by modifying the script to calculate the entire range of time during which the top 20 user’s balances matched the expected values, and then calculated the upper bound on the difference between each adjacent pair of users across the entire time period and used those for the calculations, rather than a specific value from a specific point of time.</p>
</blockquote>

<blockquote>
  <p>The March 4th dump gave me a lower bound on Johnny as expected, and also decreased the upper bound (now 196-1183), with no other changes. The January 29th dump only tightened the lower bound on Henri Lemoine, and the January 28th dump (from before the double Q4 GDP resolution was fixed) provided no new information at all. Oh well. I was really hoping that the long ago dumps would be more useful, but I guess the current bounds are mostly tight enough that they are unlikely to be improved.</p>
</blockquote>

<blockquote>
  <p>Afterward, I ran some counterfactual scenarios. I’m currently just 1.43% behind 5th, but that is largely an illusion because I’m once again a victim of the paradox. Even after this morning’s purchase, Connor has ~50% more Biden shares than me, so even if it resolves YES, I’ll lose ground and be 1.90% behind. (Mark also has a fair bit on Biden, albeit less than me.)</p>
</blockquote>

<blockquote>
  <p>I also discovered a different sort of counter-intuitive paradox as far as Trump Indictments goes. As I have $180 riding on it, I always assumed I should be rooting for YES. However, I discovered that zubby, Johnny, and Connor all have huge (2000+ share) positions on YES, which means that if it resolves NO, I’ll rise to 5th by default despite my loss as Johnny and Connor fall out of the top 5. Meanwhile, if it resolves YES, I’ll be 4+% behind 5th place again. I guess now I just have to pray that he <em>doesn’t</em> get indicted. It almost makes me think that I should sell my stake in order to double-down on the defacto NO bet.</p>
</blockquote>

<blockquote>
  <p>Anyway, that was the morning - a lot of time wasting worrying about Salem, and not even the kind of worrying that leads to useful results.</p>
</blockquote>

<blockquote>
  <p><strong>20:21</strong> - Anyway, I got home at 3:52, and spent 20-30 minutes lost in thought before finally checking the computer. I saw that Stevie Miller (now 11th place) had bought Trump Indictment down to 70%, and I was now 6th place on the leaderboard. It didn’t come by passing Ben as I always expected, but by him swinging the market almost exactly just barely enough to place Connor under me.</p>
</blockquote>

<blockquote>
  <p>I also ran the stats again and discovered that now if Trump Indictment magically resolved NO, I’d still be in 6th with Stevie in 5th. He now has over 5000 NO shares. The purchase this afternoon was only a small part of that, but apparently enough to tip the counterfactual rankings. It looks like he has been consistently betting against indictment for the last month, including several bets when it was at 90+%, so it’s no wonder he has so many.</p>
</blockquote>

<h2 id="optimal-bet-allocation-calculator">Optimal bet allocation calculator</h2>

<blockquote>
  <p><strong>27.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>13:48</strong> - … I wrote a script to calculate the optimal allocation of money between multiple equivalent markets on Salem. Assuming nothing unexpected happens, at the end of the month there will be three near certain markets resolving imminently, Melitopol. Trump Twitter, and Biden Approval. They’ll probably be like 98% by then, but I figure it’s best to throw most of my remaining money in there at the end to earn a few quick pennies. The question is how to split my bets between them.</p>
</blockquote>

<blockquote>
  <p>I’d originally planned to write a function like this back in December, when there were something like six different markets resolving at year’s end, but never got around to it. Better late than never. The code doesn’t take into account limit orders, which make things way more complicated, but I don’t expect anyone to put in limits against a sure market anyway.</p>
</blockquote>

<blockquote>
  <p>Speaking of Salem, I saw Sunday morning that Stevie had bumped Trump Twitter back up to 11% and put in another $107. I soon had second thoughts however. When I went on my walk Sunday morning, I as usual spent the whole time ruminating about Salem (and ignoring Noriko’s podcast in the background), and regretted my wager and concluded that it was a bad idea. My regret was short-lived however. A few hours later, someone bought it down to 8%, and it is now down to 6% (or rather was when I left for the doctor this morning.)</p>
</blockquote>

<blockquote>
  <p><strong>28.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:51</strong> - Anyway, after finally getting home, I immediately drank some water, then briefly checked Salem, put away the groceries, and took a second shower. I’d missed what at the time seemed like a bit of excitement in the Trump Indictment market, as while I was away, it had gone from 70 to 69, jumped to 76, then back down to 69 and finally ended at 72%. Since it was a weekend for me, I’d almost forgotten that it was still Monday and thus the grand jury was meeting and there was news that might sway the market. Of course, that was nowhere near the swings on Tuesday.</p>
</blockquote>

<h2 id="zubbys-windfall">Zubby’s Windfall</h2>

<p>In one of the most remarkable coups of the contest, Zubby somehow managed to buy a huge dip after only <em>four minutes</em>, cementing his massive lead over Johnny in first place. Zubby did it by hand, but Johnny turned out to actually be using a bot to alert himself to major market movements like this. Somehow even with the bot, he ended up being consistently slower than Zubby in March, to the point where I nicknamed him “Johnny Come Lately”.</p>

<blockquote>
  <p><strong>29.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:34</strong> - Around 1:10, I checked Salem, and saw that I’d missed some major action in the Trump Indictment market, real drama this time, not the piddly little nonsense that had passed for drama back on Monday.</p>
</blockquote>

<blockquote>
  <p>Specifically, at 10:22 Alec Cenci (then 18th place) suddenly bought it from 72% all the way down to 28%. Then, just four minutes later, zubbybadger bought it back up to 61%, and at 10:44, Johnny Come Lately bought it up to 68%. It’s funny how Johnny always seems to follow behind zubby, getting worse prices each way. I was amazed at how fast zubby had jumped on it, and asked if they had a bot set up to notify them of market movements or something, but they said they just got lucky. It makes sense, given that they aren’t normally quite that fast.</p>
</blockquote>

<blockquote>
  <p>Anyway, I decided to take the opportunity to sell out my own stake (68-&gt;65%), netting $162 for a loss of $18. It’s hard to sell at a loss, but the news of yet another week’s delay (plus a delay in the Georgia case) made me want to just wash my hands of the whole thing and free up the money for other bets (not that I’m exactly short of cash at the moment). I was really glad that I sold out, because this morning, Johnny sold down to 62%, and then Spencer down to 59%.</p>
</blockquote>

<blockquote>
  <p>That wasn’t the only market action I missed Tuesday morning. Alec Cenci also dumped Trump Twitter from 5% up to 14% (also at 10:22 and the same amount they immediately threw into Trump Indictment). No zubby/Johnny squad stepped in to try to correct that one - it took until 12:22 when Krum-Dawg Millionaire bought it down to 9%.</p>
</blockquote>

<p>Not only did I fail to call the Trump Indictment market, but I managed to sell near the bottom, because of course I did. I think there might have been an element of wishful thinking involved. If the market resolved NO, it would be really good for me in the contest, and also better for the country (as having the first indictment be based on a relatively insignificant crime with a dubious legal theory would make it seem like a political witch hunt and cause people to be more dismissive if/when Trump later got indicted for more serious crimes - but of course Bragg had his own incentives.)</p>

<h2 id="the-big-miss">The Big Miss</h2>

<p>It was the last two days of the month when things <em>really</em> went south though, as not only Zubby and Johnny jumped ahead, but so did Connor and my other competitors.</p>

<blockquote>
  <p><strong>30.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:04</strong> - There was a bit of bad news on the Salem front, as when I checked 538 in the afternoon, I saw that after five straight days of Biden’s approval staying at exactly 42.9% across multiple poll updates, it had fallen to 42.7% at 11:50.</p>
</blockquote>

<blockquote>
  <p>This is exactly the kind of thing I worried about before, but it is too late to do anything about anyway. I just have to pray that it doesn’t fall farther in the next two days. It was unchanged at 42.7 after another update in the evening, and when I checked after getting up this morning, I saw it was down to 42.6%. Coincidentally, 538 had updated just 38 seconds before I checked after getting up. The Salem market seems undeterred though. Just 15 minutes before, zubby had sold it up to 96%. Zubby has normally been more bearish on Biden than me and somehow knows about the polls before they show up in 538, so if they’re acting like it’s a sure thing now, I guess I shouldn’t worry too much.</p>
</blockquote>

<blockquote>
  <p>Also, this morning on Salem, Johnny responded to my comment from two days ago saying that he <em>does</em> have a bot set up to alert him to market movements. It’s funny how despite having a bot, he is consistently slower than zubby, who is apparently doing it all by hand. Anyway, it makes me think that I need to invest in figuring out how to set up a bot of my own so that I’m not fighting one handed.</p>
</blockquote>

<blockquote>
  <p><strong>17:31</strong> - Well, today was certainly a day on Salem. This morning when I checked the leaderboards, I was up to 5th place, having finally passed Ben, presumably on the strength of the final bump of Biden Approval up to 96%, and having not yet been overtaken by Connor, presumably weighed down by Trump Indictment.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, it was short lived. I randomly checked Salem again at 3pm and found way more action than I expected, as Trump Indictment had spiked up, with news having just come out reporting that the grand jury voted for indictment.</p>
</blockquote>

<blockquote>
  <p>The first buy was actually a rando, Chris Rigas, 59-&gt;67% at 12:31pm. However, I assume that was just random, not based on any information. The real action started at 2:25pm when zubby suddenly started buying it up at 61% (Johnny and Josiah having pushed it back down a bit). Zubby pumped it to 75% (with some resistance from Johnny), followed by a rando (Thomas Stearns) boosting it to 84% at 2:31pm.</p>
</blockquote>

<blockquote>
  <p>After one last sale at 2:32, Johnny stopped trying to push it down and started buying it up again at 2:33pm, soon joined by PPPP and Josiah Neeley. At 2:41pm, Connor Pitts jumped in, throwing in a massive $3611 in, which (plus another 300 from Josiah) took it up to 96%, where it still was when I happened to check in an eon later around 3pm.</p>
</blockquote>

<blockquote>
  <p>Of course, it was far too late for me to do anything there. It didn’t seem to make sense to buy in at 96% when the time to resolution is still uncertain and Melitipol is sitting at 97% to resolve in just a day and a half. That didn’t stop others from later pumping it up to 98.7%, so either they think it will resolve in the next day for sure, or they don’t understand opportunity costs at all (which to be fair, is a hard concept, and something I’ve messed up before as well.)</p>
</blockquote>

<blockquote>
  <p>The chaos in Trump Indictment did lead to unusual moves in other markets as well. China GDP &gt;4% jumped from 9 to 14% as Connor dumped his stake to free up money to put more down on Trump. That’s the one that tanked back in mid January as the outcome became certain, but it won’t actually resolve until the end of June, and so has just been sitting around testing people’s time value of money.</p>
</blockquote>

<blockquote>
  <p>Newsom To Run For President, also spiked up to 31% as zubby dumped it to free up money. That one, I put $300 into (down to 26%), so at least I (hopefully) was able to profit slightly off that.</p>
</blockquote>

<blockquote>
  <p>Zubby also bought Trump Twitter up to 10% at 3:08, which I guess makes sense, since there’s always a risk of important high profile news like this being what spurs Trump to finally start tweeting. I just nervously checked his Twitter page a few times over the next hour, hoping to be the first to see it if it did happen. Ussgordoncaptian was less cautious though, putting seemingly their entire stake on it (down to 2%) at 3:29pm - others later brought it back up to 5%.</p>
</blockquote>

<blockquote>
  <p>Anyway, this was pretty unfortunate news for me, though I suppose at least I haven’t outright lost any major bets yet, like Biden Approval. But it does mean that I’m much farther away from the top 5, since Connor was the only one I was close to. I haven’t booted up the desktop to check, but I’m guessing that I’m now a lot farther away than I was even at the beginning of March. Oh well. At least I did briefly reach 5th place.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s now 5:49, but I really had to get that off my chest, as I’ve been thinking about Salem all afternoon, and couldn’t even concentrate on trying to study Japanese after work.</p>
</blockquote>

<blockquote>
  <p><strong>17:53</strong> - P.S. What really stings about the whole thing is that it was Connor Pitts who managed to join in. Zubbybadger now having basically infinite money is one thing, but it’s not like I ever had any chance of beating them anyway. But Connor was my closest rival, and now he’s lightyears ahead again (in fact, he’s up to 3rd, ahead of David and Mark). I wish I had a bot to alert me to major market movements. If it had been me there instead of Connor, things would be very different. It wouldn’t be a complete reversal of positions, since I think Connor already had a large stake in the market - his gain wasn’t just from the big bet this afternoon, but I would certainly be a lot closer.</p>
</blockquote>

<blockquote>
  <p><strong>19:23</strong> - Even worse news on the Salem front: the Trump Indictment market resolved at 6:49pm today. I’d been hoping that it would take several days to resolve and lock up everyone’s liquidity so that I would at least be able to eke out another percent or two on Melitopol et al., and the fear that that might happen is the reason I stayed out of the market. But no such luck, and Connor and Josiah have already plowed large amounts of money back into the other markets. Incidentally, zubby’s total profit on the indictment market was $4,592, almost half of their total portfolio value as of last weekend. They’re now likely in a more dominant position than Johnny ever was.</p>
</blockquote>

<blockquote>
  <p><strong>31.03.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>18:40</strong> - Well, on the Salem front, I screwed up again. I had assumed that the Trump Twitter and Melitopol markets would both resolve at 9pm (midnight Eastern) on the 31st, with Biden Approval following at 6am April 1st. Last weekend, I wrote a script to calculate the best way to distribute money between multiple markets, and planned to wait until Friday evening and use it to throw my money into the three markets and eke out whatever pennies I could.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, Trump Twitter resolved at 11:01am this morning for some reason, which means that much like with Trump Indictment yesterday, I left a bunch of money on the table by failing to invest before resolution and that it freed up other’s money to join in the remaining markets. After work this evening, I immediately fired up the computer and used the script to distribute my money between the remaining two markets as planned. Of course, they were already up to 98.6%, so profit will be minimal, but it’s better than nothing.</p>
</blockquote>

<blockquote>
  <p>Still, it is pretty frustrating, as I deliberately kept most of my money uninvested till the end so that I’d be able to capitalize on any opportunities that arose without having to eat fees and time delay selling out other positions, but I completely failed to capitalize on any of the major profit opportunities that actually arose.</p>
</blockquote>

<blockquote>
  <p>It’s funny because when I examined the state of Salem in early March, I concluded that the main opportunity for profit (or loss) would be in correctly guessing the outcomes of the Chicago Mayor and Wisconsin Supreme Court elections. However, those have barely moved at all this month while the actual action was in Trump Twitter and Trump Indictment. The worst part is that I did invest in the latter, but then sold at a loss. Actually that happened both times.</p>
</blockquote>

<blockquote>
  <p>The best that can be said for March is that I avoided any major losses (not counting opportunity costs and missed opportunities). I played conservatively and ended up with a slight profit for the month (and overtook Ben, who has just been sitting there the whole time), but lost a lot of ground relative to other top players as a result.</p>
</blockquote>

<blockquote>
  <p>And much like in January, all my time and effort and obsessive checking of Salem several times a day didn’t help much in the end. In fact, not once but twice this month, I took advantage of a temporary spike to close out my position at a small loss, counting myself lucky, only for that to have turned out to be a bad idea. Meanwhile, I managed to miss the most important events. Hopefully I can figure out how to set up a bot to alert myself to market movements, and hopefully that will help in the future, but I’m not sure even that will, and the longer the competition goes, the harder it will be to overtake the top 5.</p>
</blockquote>

<blockquote>
  <p>Also, as far as the adjustment bounds thing goes, previously all the stat dumps had been a manual process on my desktop, where I had to run the script, manually confirm the leaderboard positions on the website, then comment/uncomment some code and run it again.</p>
</blockquote>

<blockquote>
  <p>Early this week, I came up with a new idea, where I used the Chrome Dev Tools to dump the page source of the Salem leaderboard whenever I noticed a major movement, and saved the dumps to a Google Doc so that I could later copy out the leaderboard json blob and put it through the script, the way I did with the January 28/29 and March 4th dumps. I spent a while working on that this evening, and it did lead to minor improvements on some bounds. But of course it is a stupid and pointless waste of time, as I already have pretty tight bounds on Mark and David, the two I’m closest to, and tightening them further won’t really matter to anything more than idle curiosity. Also, I’m unlikely to get any better bounds in the foreseeable future. I guess now I can finally put that to rest for the time being.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s now 6:56, so I just spent 16 minutes writing this, and almost the last two hours thinking about Salem. Hopefully I can do some Japanese practice now.</p>
</blockquote>

<h1 id="april-1-15">April 1-15</h1>

<p><img src="/img/salem2/apr1.png" alt="Score graph" /></p>

<p>At the end of March, I was pretty disheartened again, as the top five had seemingly slipped out of reach. I concluded that my main problem was that I played too conservatively in March and that I needed to be bolder in betting and take more risks. Fortunately, I ended up reaching the top 5 after all just days later.</p>

<p>Additionally, April also saw more top players drop out of the competition, making the leaderboard increasingly static and lifeless. As already mentioned, Ben (who was ahead of me in sixth for most of March) was not actively playing (it turns out his last bet was all the way back in early December), and players who are just sitting there are relatively easy to pass and also much less of a threat, since they won’t jump up and overtake you from behind.</p>

<p>In March, ussgordoncaptain had been behind me in a distant 8th place, making me feel relatively secure in 7th at least, although they did gain ground over the course of the month. However, that turned out to be their last effort, as they, too, stopped playing after March 31st. It’s rather ironic, since ussgordoncaptain had predicted back in December that the remainder of the contest would be very quiet, with only a few people left who had any real shot and thus few people bothering to play.</p>

<p>Lastly, Connor Pitts, one of my closest targets in March before he infuriated me by taking large profits and jumping ahead, also stopped playing following the elections on April 4th, leading to the situation where three of the top eight players were no longer actively participating in the contest. This situation would persist for months and only ended whem Malte Schrodl broke into the top eight later on, bumping ussgordoncaptain down to 9th, so three of the top <em>nine</em> were inactive instead.</p>

<p>However, I didn’t know all that at the time, and April opened with yet another disappointment, though fortunately a relatively trivial one:</p>

<blockquote>
  <p><strong>01.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:19</strong> - Salem - somehow I managed to just miss things again, multiple times. I knew that the Melitopol market was set to resolve before Biden Approval, and thus hoped to plow the winnings from the former back into the later to earn a bit more. I considered weighting it higher in my script, but had no idea how what price I’d be able to get Biden Approval at afterward, and also worried that it might take a while to resolve (like the markets at the end of February), so I decided to just treat them as if they resolved at the same time in my bet calculation script. At least that part proved wise. Still, I was hoping to be able to reinvest in Biden to get a bit extra.</p>
</blockquote>

<blockquote>
  <p>Trading on the Melitopol market was set to close at 11:59pm Pacific. Not sure why they used Pacific instead of Eastern like the other markets. I thought they might resolve it at 9pm anyway, but that didn’t happen.</p>
</blockquote>

<blockquote>
  <p>By coincidence, I got caught up reading the Magic subreddits again until 12:04, but of course, trading just closed in the market, they didn’t actually resolve it then. I went to bed at 12:27. As usual, I had trouble sleeping, which I thought would be to my advantage for once. Whenever I woke up during the night, I would check my phone to see if I’d gotten the email about market resolution yet.</p>
</blockquote>

<blockquote>
  <p>At 5:09am, I woke up and saw a notification for an email about Josiah commenting on the market (at 4:50). I decided to get up and check what was going on, but of course, there was no resolution, just Josiah commenting to ask them to resolve it.</p>
</blockquote>

<blockquote>
  <p>I went back to bed at 5:12 and woke up again at 6:08. The Biden market had trading set to close at 6am so there was nothing I could do, but got up again to check anyway out of curiosity. Naturally, they had resolved the Melitopol market at 5:12am, so I literally just missed it. And I also just missed the reinvestment cutoff. It was up to 99.3%, but I still could have earned a bit more if I had even happened to wake up just 10 minutes earlier. Johnny had immediately reinvested everything at 5:12, followed by two “randos” (what I call people whose names I don’t recognize from being on the leaderboard), but at least none of the other top players managed it, not even Josiah.</p>
</blockquote>

<blockquote>
  <p>Anyway, I tried to go back to bed, but the frustration, etc. of thinking about Salem meant I couldn’t fall back asleep like the other times, so I got up again after a few minutes. So I guess I was triply cursed. By just missing the relevant times twice and also waking up early enough to still lose a lot of sleep over it. Oh well, what’s done is done. It’s now 6:31, hopefully I can make the most of my morning and avoid sleep deprivation headaches. I wish I could start going to bed earlier again.</p>
</blockquote>

<blockquote>
  <p><strong>12:45</strong> - Some minor good news on the Salem front. Mark woke up and made a bunch of bets this morning. It seems that he normally keeps all his money invested and thus is only active in times like this when a market resolves and gives him more money. Significantly though, one of those bets was NO on Paul Vallas.</p>
</blockquote>

<blockquote>
  <p>Currently, David and Mark are neck and neck in 4th and 5th respectively, about 4.7% ahead of me (down from 6.1% when I checked yesterday evening and became dejected, so that’s nice at least). Since David (still) has his massive YES bet on Vallas, that means that they are even more anticorrelated on that market than before.</p>
</blockquote>

<blockquote>
  <p>If Vallas wins, then David will shoot ahead, but Mark will fall back and I’ll only have to beat Mark to regain 5th. If Vallas loses, then I’ll be set back, but will still not be that far behind Ben, and will only have to catch up to Ben again to take 5th with David knocked out. I did some math and concluded that buying $32 more of YES would equalize these ratios, so that no matter what happens in the Chicago and WI Supreme Court elections, I’ll be at most 0.88% away from 5th place.</p>
</blockquote>

<blockquote>
  <p>Of course, the markets are constantly changing and varying by more than that, and it’s not like being 0.88% away from 5th on April 5th specifically is meaningful, and the nature of the Salem is that you have to run as hard as you can just to stay still and if Vallas loses, I’ll be knocked down enough that ussgordoncaptain starts looking like a real threat (it helps that he already gained a bunch this week as well), etc. So it’s not a particularly good strategy, but using math like that makes me feel clever, so I went ahead and did it. It’s only $32 anyway.</p>
</blockquote>

<h2 id="alls-quiet-on-the-salem-front">All’s Quiet on the Salem Front</h2>

<p>On the morning of April 4th, everything was still quiet, and it didn’t seem like there was much opportunity for advancement left. Little did I know that everything would change that evening.</p>

<blockquote>
  <p><strong>03.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>13:34</strong> - I’ve barely paid attention to Salem since Saturday morning, figuring that there was little I could do and the markets in play right now aren’t ones that were interesting to me as I don’t know anything about them. However, I checked this afternoon and saw that Q1 GDP &gt;=1% had dropped a lot and so checked GDPNow and saw that this morning’s GDPNow forecast had dropped from 2.5% to 1.7%.</p>
</blockquote>

<blockquote>
  <p>As GDPNow seems to usually be an overestimate, I thought it was pretty safe to buy NO on Q1 GDP &gt;= 3% now, and put in $500 (21-&gt;17%). That’s more than my first inclination would want to risk, but the lesson of last month is that I need to be bolder about taking risks (and also have them all pay off for me of course, which is easier said than done).</p>
</blockquote>

<blockquote>
  <p>I really regretted not actively following the GDP stuff, assuming that nothing of interest would happen for the next few weeks. If I had just checked GDPNow when it came out this morning and bought in then, it would have been at 24% instead. Oddly, the usual suspects, zubby and Johnny haven’t touched these markets (Johnny bet on the 1% one yesterday, zubby hasn’t ventured in at all). Instead it fell to Alvaro de Menard, currently 15th place, to sell the 3% market down from 24 to 21% at 11:04am today.</p>
</blockquote>

<blockquote>
  <p>It’s funny because when the titans do jump in, there is no opportunity for profit, but when they don’t, I worry that there’s something they know that I don’t. In this case, at least there’s the endorsement of Mark. NO on 3% was one of the markets he bought with his winnings Saturday morning (27-&gt;24%).</p>
</blockquote>

<blockquote>
  <p>In other news, Salem added a new market today, on whether Erdoğan manages to stay in office. They also added two markets last Friday, on Trump gets indicted <em>again</em> and whether he rejoins Twitter. All three end on July 31st, when the entire contest ends. There are increasingly few markets which resolve before July, part of what makes things less interesting. In fact, I think April will be the first month since last year when no markets are set to resolve at the end of the month (though the two GDP markets will resolve on the 27th, which is close).</p>
</blockquote>

<blockquote>
  <p><strong>04.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:44</strong> - This morning on Salem, I noticed a spike in the “Ukraine to take major city” market, from 39 to 49%. I decided to buy $125 in NO (going down to 45%) and then put in a YES limit at 40% in hopes that the others will buy it back down. It’s only a profit of $10 even if I’m successful, but every little bit helps. Oddly, none of the major players have touched this market. The recent movements were all no-names (I think I’ll go back to that term, rather than “rando”). I also noticed that zubby and Johnny no longer seem to be betting against Vallas at 66% (in fact the only NO limit is at 80 now), so that’s an encouraging sign at least.</p>
</blockquote>

<blockquote>
  <p>There was also a weird event where “Mark Ingraham” (a no-namer, not to be confused with regular Mark in 5th place) commented on Erdogan last night “This will be a NO, given his charges. Mods are retards and banned me.” and then on GDP &gt;1%, “This will also be a NO. Capitalism is in rapid collapse and few if any quarters will have positive growth. Mods are of course retards and prevent me from betting.” No idea what is up with him, but presumably he’s just a troll of some sort who got banned. Still, this is the first time this has happened in the entire competition.</p>
</blockquote>

<h2 id="election-night-1">Election Night</h2>

<blockquote>
  <p><strong>20:25</strong> - Wow, what an evening on Salem! It was pretty tense for a while, but in the end it worked out better than I could have hoped. I first checked in on Salem a little after noon, and basically nothing had changed as usual. I put down $100 on Protasiewicz at 83% just for fun and to hedge my bets a little. I think I might have checked a couple more times in the afternoon, but nothing much happened.</p>
</blockquote>

<blockquote>
  <p>As the polls had Vallas 2-4% up, indicating a close race, I assumed that the votes would take a long time to count and the results wouldn’t be clear for a while, probably not even before 8:59pm when the market was set to close, and so I didn’t have much urgency in checking Salem after work and instead continued reading Zvi’s latest AI post, which took me until ~5:52.</p>
</blockquote>

<blockquote>
  <p>At 5:52pm, I finally checked Salem and was in for a shock, with Vallas at 15% and dropping even as I watched. I briefly considered panic selling, but the election results showed a dead heat with Vallas up &lt;0.1%, which seemed like a lot more than 15% to me. It wasn’t until several minutes later when I found my way to Dave Wasserman’s Twitter, where he talked about how Johnson would have an edge in mail-in votes and thus Vallas’s rapidly dwindling lead was bad news for him, that I decided to sell.</p>
</blockquote>

<p>Note: I had not previously read Dave Wasserman’s Twitter. My strategy was to just endlessly search through the most recent election-related tweets on Twitter until I happened to see people who looked like they knew what they were talking about, a strategy I would employ again for the two Turkish elections, and also the way I later found out about the ScotusBlog.</p>

<blockquote>
  <p>By the time I sold at 6:00, it was down to 9%, and I only got $28 for my original investment of 232. Fittingly, Johnson first took the lead outright immediately after I sold. I also discovered that 538 had a live blog and anxiously spent the next hour flipping between the NYT election results for the two elections, the Salem market pages, Wasserman’s Twitter, and the 538 Liveblog.</p>
</blockquote>

<blockquote>
  <p>After my sale, Josiah continued buying down to 6%, Sam Dittmer bumped it up to 12% at 6:09 and Josiah had one last buy down to 10% at 6:10. I assumed Josiah was out of money at that point. I put in $500 of my own on NO at 6:14 (10-&gt;8%) and then another $1000 (8-&gt;6%) at 6:15 as Johnson’s lead widened. I immediately had second thoughts though and actually had a $50 YES limit out at 6% for a while, but there were no takers, and I canceled it once the next round of votes came in and Johnson’s lead widened again. It didn’t help my nervousness that others had bought it back up to 8% (it didn’t turn until 6:42, when Sam dumped his stake).</p>
</blockquote>

<blockquote>
  <p>I also started buying up the WI Supreme Court market once results started coming in, at first only a little bit, but more and more as more results came in and 538 and Wasserman talked about how Kelly was underperforming Trump in the major counties, etc.</p>
</blockquote>

<blockquote>
  <p>At 6:54, I put in the last bit of my money, $200 on each market (at 5% and 95%). Well, I left $79 uninvested for liquidity sake, but I invested essentially all my money as the results became clearer. With Johnson’s lead up to 2.4% and WI called by various places, I figured there was no point in watching things further and decided to go out for donuts to celebrate and hope for the best.</p>
</blockquote>

<blockquote>
  <p>I left at 7:01 and got back around 8:16, and saw that both markets had resolved, at 7:38 and 7:39pm. One thing that really surprised me was how absent the top players were during the critical 5:30-7pm period. Zubby did a bunch of selling on the Vallas market early on (5:28-5:37) but disappeared after that. Most of the selling was done by Josiah Neeley and a couple of nobodies (Noah Lafountain, Sid Sid, and Richard Zhu, with Noah being the earliest and most active). The WI side was even better, as while Noah and Josiah (and a couple bets from others) were there buying it up with me, I was largely ahead of the curve and thus managed to harvest a lot more of the profit than I would have expected. In particular, I was the first person to bet really big on it, with $1500 at 6:43 (89-&gt;91%).</p>
</blockquote>

<blockquote>
  <p>In fact, I actually made a big profit overall, despite taking a huge loss on my initial bet on Vallas. My “net worth” is now up to $8168, up from $7828 right before the big plunge at 5:21. And that means that I’m now in 5th place again, with David knocked out of the top five and my bold bets this evening boosting me back past Ben and even ahead of where I was before.</p>
</blockquote>

<blockquote>
  <p>There was a little bit of top player involvement after I left for donuts, but only after the main action was over. At 7:34, David sold $89 worth of YES from 5-&gt;2%. I know he had over 2000 YES shares before, and I’m guessing he sold everything and that was all he got for them. Ouch. Connor put a total of $8600 into WI from 6:55-7:06 (95-&gt;97%), and then $8900 against Vallas at 7:39pm (2% -&gt; 0.5%). It seems that the WI market resolved at 7:38pm and the Chicago market at 7:39pm, presumably because a human at Salem was manually resolving them and Connor was somehow watching at that exact moment and managed to transfer all his winnings into the Chicago market before it resolved too. That was really impressive.</p>
</blockquote>

<blockquote>
  <p>Still, it is really nice that for once, I was the one throwing in thousands at 89-93% and Connor the one just getting the dregs later. Take that! And that was pretty much it. Zubby never reappeared and Johnny didn’t show up at all. I can’t understand how they could have missed out on this, since it’s not like election night is an unexpected night and they’re usually really on the ball. But I can’t complain about my good fortune.</p>
</blockquote>

<p>Note: “Liberals Win Wisconsin Supreme Court?” resolved at 19:38:54, Connor bet everything on “Paul Vallas Mayor of Chicago?” at 19:39:10 ($8900 NO, market 2.32% -&gt; 0.51%), and then that market also resolved at 19:39:55. I’m not sure why it took the Salem staff 61 seconds to resolve both markets, but it was a really impressive play on Connor’s part. I imagined it being like Indiana Jones rolling under the closing door at the beginning of Raiders.</p>

<p>Little did I know that this would be Connor’s swan song. He never bet again, making him a stationary target. He was far ahead of me at the time, but with months left in the competition, I knew that I would pass him sooner or later (in fact, at the end of the competition, two other players also just barely passed Connor, so he finished in only sixth place.)</p>

<blockquote>
  <p><strong>22:05</strong> - Noah Lafountain is now 14th on the leaderboard, so I guess I can stop treating him like a nobody now. 13th place is also a new (old) face, Dylan Levi King. I remember DLK being on the leaderboard back in December before they went crazy and bought China COVID all the way up and then back down again (making me rich for a while in the process). However, it seems that they made a large bet against Vallas back in early March, and hence got catapulted back up the ranks tonight.</p>
</blockquote>

<blockquote>
  <p>When I checked Salem again tonight after watching the latest episode of Hi Score Girl, I saw that “Will Russia Control Kramatorsk on 5/31/23?” had plummeted, with Mark buying 23-&gt;21% at 8:28 followed by DLK putting in $2000 on NO (21-&gt;11%) at 9:26. I at first assumed it was a news development and checked Google, but there was nothing, and I realized that they must have just been reinvesting their winnings from the elections tonight.</p>
</blockquote>

<blockquote>
  <p>I also went back and checked the old Nevada Senate market page to bask in nostalgia.</p>
</blockquote>

<h2 id="post-election">Post-election</h2>

<p>The next few weeks were uneventful, with the only notable action being the Q1 GDP markets. I stopped checking Salem frenetically like I had in January and March, and planned to write a bot to alert myself to sudden market movements instead, like Johnny had. Unfortunately, I procrastinated for several weeks on the bot, and it only barely worked even when I finally finished it. I also learned that Johnny had written scripts to scrape the API data and calculate everyone’s portfolios and rankings, much like I had.</p>

<blockquote>
  <p><strong>05.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:54</strong> - Salem - Last night I also checked the old Nevada Senate page to bask in my “smartest money” award. It shows the top 5 winners in each market, and I was #2 (809). I noticed that Noah Lafountain was in 4th (387), so I guess he’s been playing for a long time as well and just only now made it onto the leaderboard. Incidentally, David Hassett was first with nearly double my profit (1566).</p>
</blockquote>

<blockquote>
  <p>Last night, David had fallen to 8th, below ussgordoncaptain. When I checked again this morning, I didn’t see any notable market moves, but he was now back up to 7th. I figured that this means they must be relatively close together and there was a decent chance they were close enough to help narrow down the adjustment bounds, so I dumped the leaderboard source to my Google Doc for later again. I wish I’d done that last night as well.</p>
</blockquote>

<blockquote>
  <p><strong>06.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:28</strong> - Salem: I completely forgot about my plan to check GDPNow yesterday morning until I suddenly remembered at 9:50. The latest forecast is down to 1.5%, so I threw another 300 in on no for the 3% market (14-&gt;12%). Fortunately, my delay didn’t matter since people have barely touched the 3% market for some reason.</p>
</blockquote>

<blockquote>
  <p>Meanwhile, there’s been a lot of action lately in the &gt;1% market, with it bouncing around in the 70-80% range. Not sure why everyone is betting there instead of 3%, but I guess to be fair, the outcome is a lot more uncertain and there’s a lot more money to be made there if you’re right.</p>
</blockquote>

<blockquote>
  <p>Anyway, no action of note in markets I care about lately, but there was a notable discussion. I went to the Chicago Mayor page last night to leave a comment congratulating Connor on somehow moving his money faster than Salem could resolve the markets, and saw that someone had started a discussion about whether Salem should resolve markets earlier so people couldn’t profit off of near certain outcomes. What was especially notable though is that Johnny left some comments with numbers estimating how much profit each person got from markets before they closed. He said that he also wrote a script using the API, so I guess I’m not the only one to do that. I’ve done my best to avoid mentioning the possibility myself out of fear of it being considered cheating. It makes sense since Johnny previously said that he had a bot to alert him to major market movements as well (although I’m not sure how he manages to often miss them anyway if that is the case).</p>
</blockquote>

<blockquote>
  <p><strong>08.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>14:22</strong> - After finally pulling myself away from … this morning, I attended to my Salem script. I put in the leaderboard dump from Wednesday morning, plus one more right then for good measure, but it didn’t lead to any bound improvements.</p>
</blockquote>

<blockquote>
  <p>I also tried using the bounds to reverse engineer the cutoff time. As fun as it is to try to narrow down the bounds purely based on leaderboard observations, the whole thing started as I know that the adjustments were calculated by taking the scores at some point in the first day or two and subtracting $1000 (if above 1000). The only uncertainty was <em>when</em> they chose the scores from.</p>
</blockquote>

<blockquote>
  <p>Therefore, I figured I could use a similar script to the code I already wrote for finding the time range corresponding to the particular set of top 20 cash balances from the leaderboard json dumps and instead calculate all the time ranges which are consistent with the already known adjustment bounds, and then figure out what ranges everyone’s scores were at those times.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, it turns out that there are <em>no</em> times consistent with all the bounds I’d established. I figured that the problem must have been with the manual script-based dumps I did many times in late March, where I would manually confirm the order of the top 20 on the website and then put that in together with the calculated scores of everyone from my script. That’s a more fallible process than the score bounds reverse engineered from the json dumps because there might have been a change in values while I was in the process of messing with the script or I might have just made a mistake in the process somewhere.</p>
</blockquote>

<blockquote>
  <p>Therefore, I calculated the adjustment bounds using only the json leaderboard dumps, ignoring the earlier manual logs, and then used those to see which time ranges were consistent. The bad news is that throwing out the mid-March data means somewhat wider bounds for everyone, and the historical reconciliation barely helped with Mark and David, whose scores varied over almost the entire range of my calculated bounds. It did narrow down Johnny’s adjustment a lot though, and would also help with Adrien, should he somehow ever make it back into the top 20. Also, the dump from Wednesday morning did improve the bounds when the March data is discarded, so that wasn’t a complete waste.</p>
</blockquote>

<blockquote>
  <p><strong>09.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>10:50</strong> - Anyway, I mostly stayed home and took it easy Saturday, and didn’t do much of note. I finally got around to looking into the status of Salem with my script. I’m currently way behind Mark and Connor (~10.3% from 4th place), so there’s little chance of me getting 4th (though I narrowly would take 4th if Q1 GDP 1% resolves NO, as Mark is betting on that), but also relatively little risk of losing my spot in 5th. I also noticed that David has invested everything in a mix of three markets, which surprised me as he didn’t usually spend his entire stack of money in the past.</p>
</blockquote>

<blockquote>
  <p>The remaining markets are also much more boring than in the past. I confirmed my impression that they’re all long term now. There are 29 markets remaining, of which two are set to close on April 27th (the two Q1 GDP markets), four on May 31st (Newsom and DeSantis to run for president, and Russia to hold Kherson and Kramatorsk on 5/31), one on June 30th (China GDP - which was already effectively decided back in January), one on July 27th (Q2 GDP), and the entire <strong>twenty one</strong> remaining markets are all set to close on July 31st, the end of the competition.</p>
</blockquote>

<blockquote>
  <p>To be fair, the Erdogan market will probably actually resolve in May, and others may resolve sooner if something specific happens (Trump indictment, return to Twitter, recognition of the Taliban, etc.) Still, it seems like an unusually boring selection of markets for someone like me who had always focused on the soonest resolving markets.</p>
</blockquote>

<blockquote>
  <p>I think it might be to the point where the time-value of money is greatly reduced and it makes more sense to invest in long term markets. But you still have to be careful there, because there’s potential for unexpected developments when you really want to have money available. In any case, it seems like the best I can do is to create a bot to alert me to major market movements, and then stop worrying about Salem for a while (besides checking GDPNow, I guess).</p>
</blockquote>

<blockquote>
  <p><strong>12.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:50</strong> - Sunday afternoon, I spent an hour trying to set up Python 3.10 and the Google Cloud Platform client example before getting tired again and giving up on the Salem bot effort to play Beat Saber.</p>
</blockquote>

<blockquote>
  <p><strong>15.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:52</strong> - I’ve barely been paying attention to Salem or checking it at all lately, but I did remember Friday morning that GDPNow would be updating its estimate that morning. I checked a bunch in the early morning, but it never updated, and I didn’t remember to check again until 1pm, when I saw that it had jumped up to 2.5% (from the previous estimate of 2.2% a few days before, itself a big jump up from 1.5%.)</p>
</blockquote>

<blockquote>
  <p>Of course this is great news for the country, which is what really matters, but it is more unfortunate for my position on Salem. I’d stood tight on my position after I’d noticed that the estimate had risen to 2.2%, but this was the last straw, and I decided to sell 500 shares, a little under half my position (11-&gt;13%).</p>
</blockquote>

<blockquote>
  <p>I later put in a YES limit at 13% to cash out the rest in the unlikely event that someone else decides to trade. I also threw $100 each into 1% GDP (YES) and Newsom (NO) at 86% and 12% respectively.</p>
</blockquote>

<blockquote>
  <p>Of course, as usual, it basically didn’t matter that I was hours late finding the GDPNow update, as noone else seems to trade on those releases at all for some reason, and particularly not in the 3% market. The whole market had no trading on Friday since 3am, and the 1% market, which had recently tended to be a lot more active, was silent on Friday as well.</p>
</blockquote>

<h1 id="april-16-30">April 16-30</h1>

<p><img src="/img/salem2/apr2.png" alt="Score graph" /></p>

<p>After David’s self-immolation on election night and Connor’s dropping out of the competition, it seemed like the only question left was whether I could <em>also</em> overtake Mark and reach 3rd place. It would be tough, but I figured I could probably do it, and even changed my display name on Salem to “I’m coming for you, Mark”. I wouldn’t manage it in April though.</p>

<p>As you can see from the graph above, April was very quiet up until the 26th when there was sudden movement thanks to the GDP markets, followed by Josiah Neeley quitting and donating all his money to Johnny. I gained some ground against Mark following the GDP markets, only to immediately fall even further behind Mark. (It didn’t help that Mark got some of Josiah’s money as well.)</p>

<blockquote>
  <p><strong>17.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:59</strong> - [Sunday Afternoon] I fired up the desktop and checked Salem, the first and only time since Friday. I ran some hypothetical scenarios to see how the rankings would change depending on the resolution of the two 4/27 and four 5/31 markets. The rankings are remarkably stable in each case. I was still 5th in every scenario except when Newsom runs for president, though the exact margins between me and 4th place or 6th place would increase or decrease depending on the particulars. In fact, in most cases, there was not even any movement at all in the top 10 rankings.</p>
</blockquote>

<blockquote>
  <p>I think I would actually be better off if GDP ends up above 3%, as despite still having 573 shares, Mark has more like 1000, and Ben also has a smaller amount, so I’d be a bit closer to 4th place, and not lose too much margin from 6th (David would start to become a bit of a threat lurking behind though). It’s nice that the best outcome for the country is also favorable to me, though it is improbable.</p>
</blockquote>

<blockquote>
  <p>I was also surprised to discover that almost noone at the top is in the Erdogan market, despite that seemingly being the best place to make money right now, since the outcome is still massively uncertain and it will probably resolve in May following the elections. Only three of the top 10 have any money in it at all, and only small amounts.</p>
</blockquote>

<blockquote>
  <p>After that, I took the next token step towards building a bot. Last week, I’d left off after getting the Google API client example working, so the next step was to modify it to send email. As I wasn’t sure where to find the API docs and I’d heard that people had good experiences asking ChatGPT for help with such things, I decided to try it myself.</p>
</blockquote>

<blockquote>
  <p>It was pretty amazing, as ChatGPT would explain how to use the API, complete with example code. The first example it posted was incorrect, but once I pasted in the error message, it figured out the correct API. so I guess I’ve officially found ChatGPT to actually be useful for the first time. I just wish I could get access to GPT 4, since everyone says it is a vast improvement over 3.5.</p>
</blockquote>

<blockquote>
  <p>Despite it not taking long to successfully get my first test email sent, I got bored and stopped immediately anyway, so the actual bot work will have to continue to wait.</p>
</blockquote>

<h2 id="a-missed-opportunity">A missed opportunity</h2>

<blockquote>
  <p><strong>20.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:40</strong> - I checked Salem again yesterday and discovered that DeSantis spiked from 57% to 77% from 10:23-10:29am from three purchases by three different players (it has since fallen back to 67%). I googled a bit to try to find out what happened and saw a news story citing sources that he planned to announce in May rather than June.</p>
</blockquote>

<blockquote>
  <p>When I checked Salem again just now to confirm the numbers, I also discovered that a nobody had bought “Russia to Take Donbas” from 15% up to 29% yesterday evening (Johnny since bought it down to 24%). So there definitely are opportunities that I’m missing by not checking Salem regularly any more (the Donas one was open for 10 hours before Johnny intervened), though I wonder if I would have been confident enough to take advantage even had I seen it. I’d stopped checking Salem for the last couple weeks because there was never anything interesting going on, but maybe I need to start again.</p>
</blockquote>

<h2 id="the-bot">The bot</h2>

<blockquote>
  <p><strong>24.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:26</strong> - On the Salem front, I tried another trick I’d thought of for the adjustment calculations, just for fun. Previously, I had calculated upper and lower bounds on each individual’s adjustment as well as the difference in adjustment when two people were next to each other in the rankings, eliminated the redundant bounds, and then used an LP solver to find refined lower and upper bounds taking into account the binary constraints.</p>
</blockquote>

<blockquote>
  <p>I then searched through the simulated history and found all the points in time which were consistent with all the solved adjustment bounds for each individual person, and then for each person, took their highest and lowest value in that period as refined new bounds. However, it later occurred to me that I could potentially do better by incorporating the binary bounds as well. After all, a candidate point in time in the simulated history has to simultaneously satisfy all the binary bounds as well to be a true candidate, and using only the individual bounds resulting from the LP solver loses information. I wasn’t sure if it would help, but it worked like a charm, reducing the candidate points in time from 71 to 38, and I now have relatively tight bounds on everyone’s adjustment.</p>
</blockquote>

<blockquote>
  <p>Later in the afternoon, I finally devoted myself to working on the bot, as I told myself that I would be doing it this weekend no matter what. I programmed a Python script to query the Manifold API every 15 seconds to get a list of markets (and their current market probabilities), and programmed it to send me an email whenever a market changes by over 7% in a 15 minute period, with a maximum of one email every 30 minutes. Hopefully it will work.</p>
</blockquote>

<blockquote>
  <p>For simplicity, I’m not running it in the cloud, but rather just on my desktop computer. This of course means leaving the desktop running 24/7. Previously, I had only powered it on for a little while every weekend when actively using it, and shut it down during the week. I hope it doesn’t interfere with using my monitor with the work macbook, since I have the monitor plugged into both computers (or will once I plug the macbook in again). I’m hoping that with the desktop not being interacted with, it will be sleepy and not try to use the monitors.</p>
</blockquote>

<blockquote>
  <p>Another annoyance is that Google expires oauth tokens every 7 days for an application in “testing” mode, with no way to renew them. I had to manually delete the token file and reauth, and it seems that I’ll have to do that every 7 days. It’s not hard to do, but it is still frustrating with how pointless an annoyance it is.</p>
</blockquote>

<blockquote>
  <p><strong>25.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:23</strong> - I got my first email from the Salem bot yesterday, as “DeSantis to Run for President by Summer?” went from 68.2% to 58.4% at 1:02pm yesterday. Unfortunately, I never saw the email on my phone lockscreen, let alone getting a sound notification, and didn’t notice until later (not that it matters in this case, but it means that the bot emails won’t help when it actually matters). I added a filter to Gmail to automatically mark all emails from myself as Important, hopefully that will help. At least I know the bot part works now.</p>
</blockquote>

<h2 id="biden-declares">Biden declares</h2>

<blockquote>
  <p>When I got up, …I saw a comment saying that Biden had officially declared, and went over to Salem to see what had happened with the news.</p>
</blockquote>

<blockquote>
  <p>Earlier this morning, Johnny had bought Newsom from 10% down to 8% and “Biden the Favorite in Summer 2023?” from 85% up to 88%. The latter case was immediately followed by Noah and then a massive $4,691 bet from zubby bringing it up to 90%. It’s kind of funny, because I knew this was going to happen all along and it’s amusing to see the others finally catch up to this fact. But it also demonstrates a startling lack of consideration for opportunity costs, since “Will Russia Control Kherson on 5/31/23?”, which resolves at the same time as the Newsom market (and two months before the Biden market) was still at 12% (I put in $200, so it is 11% now).</p>
</blockquote>

<blockquote>
  <p>It’s possible that they think there is still more uncertainty about Kherson than Newsom, but it is really hard for me to imagine Russia successfully launching an invasion across the river and occupying the entire city in barely over a month, when Bakhmut has taken them far longer. More likely, people just get ahead of themselves at the news and don’t look closely at the other competing markets.</p>
</blockquote>

<blockquote>
  <p>I also discovered a rather strange pair of market movements, as Sam Dittmer had simultaneously bought GDP 3% YES from 14% up to 20% and bought GDP 1% NO from 91% down to 86%. (Johnny had already brought the former down to 17%, and I put in $200 bumping the latter up to 87%). It’s an unintuitive strategy, since those are mutually contradictory outcomes, but presumably it’s just a “volatility play”, betting against the consensus on both ends in the hopes that something unexpected happens. The odds are good enough that he’ll come out ahead from a single win if either one happens, not to mention that a number of top players, particularly Mark, but even myself and Ben, will suffer major losses at the same time.</p>
</blockquote>

<h2 id="q1-gdp-and-adjustment-reverse-engineering">Q1 GDP and adjustment reverse engineering</h2>

<blockquote>
  <p><strong>26.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:38</strong> - The big news today was Salem. In the morning, I periodically checked GDPNow, waiting for the final Q1 GDP forecast. I didn’t expect anything notable to happen, and thus was shocked when I checked again around 9:08 and saw that the forecast had come in and had dropped from 2.5% all the way to 1.1%. I couldn’t believe it could change so dramatically at the very end, but nevertheless rushed to Salem to trade on the news.</p>
</blockquote>

<blockquote>
  <p>I quickly sold my YES stake in the 1% market (84-&gt;81%) at 9:12 and bought 2k NO on the 3% market (15-&gt;9%). Sadly, I forgot to cancel the $75 YES 13% limit I’d put down 12 days ago when I was trying to sell my stake, and thus my big order was partly wasted trading against my own limit order. Oops. One of the downsides of limit orders I’ve discovered is that it is easy to lose track of them and forget to cancel them when conditions change, even now that I’ve been barely using them.</p>
</blockquote>

<blockquote>
  <p>At 9:14, I bought another $200 NO on the 1% market for good measure (81-&gt;75%), and then put up a YES limit at 70% to counteract it, hoping that someone else would panic sell and cash me out at a small profit (this ended up happening, but not until 1:30pm, over four hours later. Meanwhile, the 3% market hasn’t been touched at all. I’m continually amazed by the lack of activity there, as well as the lack of activity in general - even the 1% market wasn’t touched until the afternoon.)</p>
</blockquote>

<blockquote>
  <p>At 2:23pm, I checked in again and saw that I’d finally been cashed out in the 1% market. I also decided that I already had so much on the 3% market that if I lose, I’m out of the game anyway, so I might as well double down, and put down another 1k (9-&gt;7%). Although presumably the really rational thing would have been to really go all in, instead of just investing 3k.</p>
</blockquote>

<blockquote>
  <p>After buying 1% down to 75% this morning, I figured it would trigger my email bot, and thus it would be tested again. Sure enough, I got an email, but it was “37.862%-45.448% Ukraine to Take Major City?” as someone had coincidentally bought that market at the exact same time (and the bot is programmed to only send a maximum of one email every 30 minutes, regardless of the number of market movements).</p>
</blockquote>

<blockquote>
  <p>I later got a total of five additional emails from the bot in the evening, primarily due to gyrations in the “DeSantis to run for President” market, though the 1% market also went down and back up and there were other markets with large movements back and forth as well.</p>
</blockquote>

<blockquote>
  <p>Despite specifically creating a filter to forcibly mark all emails from myself as important, the emails still weren’t marked as important. I also marked them as important manually, hoping that Gmail’s inscrutable AI would decide they were important the normal way even without the filter, but many emails later, that still hasn’t happened yet either. When I started the bot project, I would have never guessed that getting the bot working would be the easy part and that Gmail would utterly fail at basic functionality.</p>
</blockquote>

<blockquote>
  <p>And frustration at scripts seemed to be a running theme today. Tonight I discovered that the Wanikani API is no longer returning reviews at all (apparently they disabled it due to not being able to handle the load), and I didn’t even mention the disappointment over the Salem leaderboard adjustments tonight.</p>
</blockquote>

<blockquote>
  <p>Anyway, as far as Salem goes, the dice is cast and I’ll just have to see how things go tomorrow morning. Hopefully it will be under 3% and I’ll still be in the running. It’s a bit stressful to have to constantly take risks like that, but it’s hard to avoid that as well.</p>
</blockquote>

<blockquote>
  <p><strong>29.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:44</strong> - Wednesday night, I noticed that Mark had slipped to 4th below Connor on the leaderboard and thought I might be able to narrow down the adjustment bounds so I got on the computer and ran the rankings and discovered that they were shockingly close (at then-current market values). Connor was ahead by only about $5 out of thousands (9126 vs 9121) and ahead of the upper bound on Mark’s balance by only about $0.8! (I’ve just been using the median value of the adjustment bounds as my estimates, and in this case Mark’s range was around 10, so 9121 +- 5.)</p>
</blockquote>

<blockquote>
  <p>With the two so absurdly close, I decided to try manipulating the market prices for science in order to try to find the exact point where they cross over and thus find out the adjustments exactly. I did this by buying small amounts of YES on the GDP 1% market (50-&gt;52%), because Mark had a lot of shares there and as it was at 50%, it would be relatively easy to manipulate the price, and because I figured it was basically a fair price for a coin flip so I’d barely be losing money in expectation (I ended up winning the coin flip, so I’m glad I did).</p>
</blockquote>

<blockquote>
  <p>I spent a while buying small amounts of YES and checking the leaderboard and dumping the leaderboard json after each time, but the rankings stubbornly refused to change. Eventually, I reached the point where Mark’s lower bound was just above Connor (i.e. 9127-9137 vs 9126) and yet the leaderboard still showed him in 4th. I tried refreshing for a minute or two in case it was just slow to update, but it wouldn’t change. As this indicated some sort of contradiction in the data, I was forced to just give up, so that was a huge frustration.</p>
</blockquote>

<blockquote>
  <p>Even more frustrating is that around an hour later (~10:11), I checked the leaderboard again, and suddenly Mark was in 3rd place, despite the fact that there had been literally no bets at all in the last hour, and so nothing changed. It almost made me wonder if I somehow messed up/hallucinated the final leaderboard check and that if you ignore that and Mark is at the very upper end of the possible range, it could theoretically be consistent. But overall, it just left me very confused and dispirited. I was considering trying to do more investigation, but even as I watched, at 10:16, someone suddenly started buying up a different market (DeSantis IIRC) which pushed Mark well out of range.</p>
</blockquote>

<blockquote>
  <p>…I went to bed at 12:02 and woke up at 6:38/6:39 (67.6-68.2).</p>
</blockquote>

<blockquote>
  <p>For once I wasn’t sleepy and had to lie in bed for 15 minutes before getting up. But the other reason I got up immediately after waking up is that I was eager and anxious to see how the GDP markets had resolved.</p>
</blockquote>

<blockquote>
  <p>As it turned out, the 1% market had closed but not resolved yet. Even more surprisingly, the 3% market was still open. It appears that they <em>tried</em> to set them to close before the data was revealed, but messed it up, so the 1% market was set to close at 5:29 am (or 8:30 Eastern), but the 3% market was set to close at 8:29am <em>Pacific</em> for some reason.</p>
</blockquote>

<blockquote>
  <p>Even better, the 3% market had for some reason still remained completely untouched since my bets on Wednesday. The actual GDP number was 1.1%, exactly as forecast by GDPNow this time, and after some minor hesitation, I decided to dump nearly everything I had into the 3% market, since it was just free money, buying $3700 of NO at 6:43 (7-&gt;3%).</p>
</blockquote>

<blockquote>
  <p>It’s a really good thing I did it then, because despite the market barely being touched for days, just 23 minutes later at 7:06, Johnny finally acted and bought $3000 NO (3-&gt;2%). Good thing I nabbed all the free money first.</p>
</blockquote>

<blockquote>
  <p>I also woke up to one more bot email, this one from the 1% market. For some reason, Josiah Neeley seems to have become utterly convinced that it would resolve NO and made a series of three large bets, $1k at 4:15pm (69-&gt;46), 500 at 6:54pm (58-&gt;45), and then a final 1k at 3:34am (52-&gt;32), triggering that last overnight email. In each case, it went back up to the 50s, primarily due to Johnny’s efforts, though others contributed as well.</p>
</blockquote>

<blockquote>
  <p>At 8:10am, the 1% market finally resolved, and a couple people (Alvaro de Menard and a nobody) moved their money over the 3% market, as did I once I noticed (already down to 1.3%). The 3% was still unresolved when I left for work ~8:30 and apparently didn’t resolve until 8:45 am for some reason. I have no idea how the Salem people work, since there is no reason why they should ever not resolve the two markets at the same time, but whatever.</p>
</blockquote>

<blockquote>
  <p>One oddity is that normally, each resolved market shows the top 5 bettors by winnings in that market. However, the 3% market only shows the top 4 (myself, Mark, Johnny, and Ben). Clearly there must be some absolute threshold to show up, since there were other people trading in the market, not least the two who piled in at the very end, but it still seems like a testament to how utterly desolate the market was. I guess everyone thought that gambling on the 1% was a lot more fun.</p>
</blockquote>

<h2 id="josiah-neeleys-donation">Josiah Neeley’s donation</h2>

<blockquote>
  <p>When I got home from work Thursday evening, there was one more surprise in store. At 9:21am, Josiah Neeley inexplicably threw in $1974 on YES for “Newsom to Run for President by Summer?”, spiking it from 8% to 67%, which Johnny bought down to 20% from 9:34-9:46am.</p>
</blockquote>

<blockquote>
  <p>Then at 11:16, Josiah threw in a final $108 (20-&gt;24%) after selling his stake in another market to free up one last bit of cash for his final hail mary. This time, Mark bought it down from 24-&gt;16% at 11:24.</p>
</blockquote>

<blockquote>
  <p>I was very frustrated, because that should have been me. To be fair, I’ve never connected my phone or Chromebook to the wifi at work and thus wouldn’t have seen the alerts even if Gmail wasn’t a buggy piece of shit, but <em>this is exactly the scenario my bot would excel at</em> if it actually worked. With Josiah’s forays into the 1% market, I would have stayed out even if I had been the first to see them, because I don’t like to bet large amounts in markets where the outcome is uncertain, but the Newsom market is practically “my” market and I absolutely had the money and the confidence to take advantage. And Johnny took 13 minutes to respond, so I would have had tons of time to jump in if the bot alerts were actually working. The whole thing was extremely frustrating.</p>
</blockquote>

<blockquote>
  <p>As for Josiah, I have no idea what he was thinking. Presumably, he became absolutely convinced that 1% would resolve NO, and then when he lost most of his money, he put the rest into a longshot bet since he’d be out of the game otherwise anyway. I ran the stats Thursday night and confirmed that he is basically all in - he has a tiny stake in one other market (like $50 IIRC) that he could have sold too, but other than that, it’s all riding on Newsom. And to be fair, he would immediately shoot to 4th, and close to 2nd, if it did somehow resolve YES, it’s just that that’s not actually going to happen.</p>
</blockquote>

<blockquote>
  <p>Back in my highschool days when I played Warcraft III a lot, including the custom map Island Defense, it was common for Island Defense players to say that the titan was “fed” when incompetent builder players left vulnerable units out for the titan to kill, giving them tons of easy XP and gold, and it definitely seems like Johnny is “fed” now. Of course, I had no hope of catching Johnny anyway, so my only frustration in the matter is that I didn’t secure the easy money for myself instead.</p>
</blockquote>

<blockquote>
  <p>I imagine zubby would have good reason to be upset though. Zubby still has a commanding lead, but it’s not quite as commanding has before. As of Thursday night, zubby was at 14k while Johnny was at 12.5k, putting him within plausible striking distance of first again. To be fair, Johnny has been very active this last week or two, and made aggressive bets on risky outcomes (e.g. buying up the 1% at low prices, which is good EV but could have easily backfired if he got unlucky). Meanwhile, zubby wasn’t completely absent, but made relatively few bets, a complete reversal of March when zubby was the most active and Johnny always seemed to come after zubby when he showed up at all, to the point where I even nicknamed him “Johnny Come Lately”.</p>
</blockquote>

<p>I didn’t know this at the time, but Zubby had extra reason to be upset. It turns out that he had <em>also</em> set up a bot to alert himself to market movements in order to compete with Johnny, but he was on a golf course at the time and hence missed out like I did.</p>

<blockquote>
  <p>Anyway, following the GDP resolution on Thursday, I made a decent profit and jumped up to $8870, putting me close to Connor, who has been sitting at $9126 in all cash since the early April elections and hasn’t done anything since then, much like Ben before him.</p>
</blockquote>

<blockquote>
  <p>The fact that he didn’t even pile into the free money 3% market bolsters my assumption that he has really been AFK and not just excessively cautious. But it’s always possible he’ll wake back up at some point. If he doesn’t, I was already close enough that I’d pass him just from the 5/31 markets resolving, assuming there were no surprises there.</p>
</blockquote>

<blockquote>
  <p>First however, I have to avoid shooting myself in the foot. I checked Salem again at 1pm on Friday and saw that the DeSantis market had dipped to 45% that morning before Johnny bought it back up to 55%, and I fomo’d in and wagered $100 myself (55-&gt;57%). I quickly regretted it though, as it went back down, and it is now only at 45% again.</p>
</blockquote>

<blockquote>
  <p>In fact, the major drop was Dylan Levi King buying 52-&gt;45% this morning just 10 minutes before I got up. I was really tempted to buy the dip before someone else (Johnny) could, but I spent a while researching news stories and just couldn’t get confidence that DeSantis will actually run before the end of the month, as the talk now is only of an exploratory committee in mid-May. At least I only put in $100, and there’s still a decent chance it will pay off.</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s all the Salem news for now. It was a wild few days, but I’m sure things will be boring for another couple weeks again. The main thing now is that I have to figure out what to do about the Erdogan and DeSantis markets, as those seem likely to be the next to resolve and also have the most uncertainty among upcoming markets (otherwise, there’s just the three 5/31 markets that are basically sure things just tracking the time value of money).</p>
</blockquote>

<blockquote>
  <p>Speaking of which, I forgot to mention that when I got home Thursday evening and saw all the missed opportunities from Josiah’s YOLO into Newsom, I decided I could at least pick up the scraps and put down $2345 (16-&gt;9%). That amount wasn’t random - I tried different numbers, wanting to put in just enough to bring it down to 9% (which presumably means just under 9.5%, given the rounding). I was a bit reluctant to tie up so much money until the end of the month when I might need it to capitalize on any other easy-profit opportunities that arose, like if Trump suddenly tweeted or the Erdogan result came in and I found out before too many others, but oh well. That might not happen and in any case I still have $5040 in spare cash. It’s so hard to predict when random opportunities like this will arise. I regretted some of my bets during the April election when I was in early and could earn a free 2-5%, but I had no way of knowing that that would happen, since in the past, I was always late to the party.</p>
</blockquote>

<blockquote>
  <p><strong>08:53</strong> - P.S. Thursday night, Mark put in another $575 on Newsom (9-&gt;8%). Betting isn’t just a matter of taking profit opportunities. That’s the most important part, but denying profits to my closest competitor is also a nice bonus. I’m a bit puzzled about why, if Mark was interested in betting that anyway, why he didn’t just put it in immediately Thursday afternoon when it was still at 16% but whatever, I’ll take it.</p>
</blockquote>

<h2 id="a-rare-bot-win-and-failure-at-sms">A rare bot win and failure at SMS</h2>

<blockquote>
  <p><strong>30.04.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:12</strong> - …Thursday night, I checked the Salem rankings as previously mentioned, and confirmed that while Josiah had one small stake he could still sell, he is pretty much all in on Newsom. Also Thursday night,</p>
</blockquote>

<blockquote>
  <p><strong>01.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:28</strong> - A bit after noon, I checked the Salem standings again and ran some hypotheticals. Nothing notable had changed since Thursday night, but I did notice that Sid Sid had appeared at 16th on the leaderboard. I remember seeing their bets a lot in recent months, and I guess now I can stop calling them a nobody.</p>
</blockquote>

<blockquote>
  <p>Even with the DeSantis blunder, I’ll still easily overtake Connor at the end of the month, so as I thought, the real competition is Mark. Passing Mark will be very difficult though, as he is much farther ahead (in fact he actually made more profit off the GDP markets than I did, due to betting on both YES 1% and NO 3% and not panic selling like I did), but it could happen if I get lucky. My best hope for passing Mark is if DeSantis runs for president, since he is betting heavily against that, while I have a small positive wager.</p>
</blockquote>

<blockquote>
  <p>Currently (well as of noon on Sunday), Mark is 13.6% ahead of me. If the three sure 5/31 markets (Newsom, Kherson, and Kramatorsk) resolve NO as expected, that increases to 14.4%. If DeSantis also resolves NO, that shoots up to 24.1%, probably permanently out of reach. On the other hand, if it resolves YES, he’ll be only 2.7% ahead of me. So it basically all comes down to that, though I’m hoping that I’ll also be able to make some profit off Erdogan or getting fed by random whales. I also changed my display name from Robert Grosse to “I’m coming for you, Mark”, just for fun.</p>
</blockquote>

<blockquote>
  <p><strong>20:35</strong> - …After that, I read the Economist for a while, and noticed another email from my Salem bot. At 3:29, Noah Lafountain suddenly bought “Trump Back on Twitter between April and July?” from 54% up to 72%. I saw the email five minutes later, and after quickly checking to make sure Trump hadn’t tweeted and googling for news stories trying in vain to find the impetus, I hesitantly put $100 on NO (72-&gt;68), since 72% seemed like pretty good odds, especially as if Trump was planning to tweet again, it seems like he would have already done it. 23 minutes later, I put down another $150 (68-&gt;63) and put in a YES limit at 53% to cash out in case it falls that far.</p>
</blockquote>

<blockquote>
  <p>Anyway, that was a rare win for my email bot. Of course, noone else entered the market until over three hours later, so the window wasn’t that short anyway. The market’s now down to 57%, so it seems like I made a decent profit.</p>
</blockquote>

<blockquote>
  <p>Speaking of the Salem bot, I also tackled the second major item on my todo list Sunday evening, modifying the bot to send an SMS as well as email so that I’d actually get notifications regardless of how buggy Gmail is and also when my phone isn’t connected to wifi. Unfortunately, I had far less success on that one.</p>
</blockquote>

<blockquote>
  <p>I easily set up a Google Voice account and successfully sent two test SMSs to myself. Unfortunately, Google Voice does not have an API and is not meant to be used programmatically. I then signed up for a Twilio account, but it said my account was suspended before I even completed the signup flow! It sent me an email asking me about my intended use case in order to unblock the account, and I responded but still haven’t heard back.</p>
</blockquote>

<blockquote>
  <p>Lastly, I tried signing up for Vonage which got off to a bad start when they sent me an SMS code to confirm my phone number during sign up which I didn’t get. I asked to resend, but the second didn’t show up either. The two SMSes didn’t show up until fully ten minutes later, by which time the codes had already expired. Fortunately, at that point, resending the code again worked instantly and I managed to complete the signup flow, but it didn’t bode well for their ability to deliver SMSes reliably. Sure enough, when I tried to send a test SMS, it was rejected for some reason.</p>
</blockquote>

<blockquote>
  <p>I also learned that it is possible to send SMSes just by emailing a special address (<phone number="">@tmomail.net), but the test SMS I sent that way took a whole half hour to show up, so that didn't seem like a viable route either. So now I'm not sure what I can do. I can't believe it is so hard to send a simple SMS message in this day and age.</phone></p>
</blockquote>

<h1 id="may-1-15">May 1-15</h1>

<p><img src="/img/salem2/may1.png" alt="Score graph" /></p>

<p>At the end of the first half of May, I finally managed to pass Mark and take third place. There was also excitement at the top end, as Johnny also passed Zubby and regained the top spot.</p>

<h2 id="botting-for-the-win">Botting for the win</h2>

<p>My failure to find a way to send SMS from my bot or to get notified of new emails on my phone meant that the bot was near useless, as I would only see if the emails if I happened to be on my laptop at the right time <em>and</em> not in the middle of something else on the computer. My bot proved to be useless the one time it actually mattered (the Josiah Neeley fiasco), but I did manage to get a few small wins from it in May. I suspect that at the time, Johnny had the threshold on his bot set too high, so it would only alert him to <em>major</em> price movements, and he thus missed small-scale profit opportunities like this.</p>

<blockquote>
  <p><strong>05.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:48</strong> - At 9:13pm Wednesday night, a nobody (Evan Harper) suddenly bought up the DeSantis market (50-&gt;74%), and I saw the email from my Salem bot after finishing the nightly Aggretsuko episode at 9:31pm. I quickly checked for news about DeSantis, but didn’t see anything recent and concluding it was just a dumb uninformed bet, sold my YES stake and put $400 down on NO (74-&gt;73-&gt;61%). I also put down a YES limit at 51%, hoping to cash out when it went back down. It had been trading at 45-46% recently, but you don’t want to be too greedy.</p>
</blockquote>

<blockquote>
  <p>Anyway, that makes the second win from my Salem bot in recent days, where I happened to be on the computer in time to see the email relatively quickly. It’s not immediate like it would be if I had SMS working, but fortunately, it usually takes a while before people see these random spikes. However, based on past experience, that still won’t protect me against actual resolution based spikes (e.g. if Trump tweeted or got indicted again), as those tend to have everyone piling everything they can into it in a matter of minutes. Still, I have been able to pick up a nice profit those two times, and this put my net worth over 9k for the first time. At this rate, I’ll soon pass Connor on the leaderboard.</p>
</blockquote>

<blockquote>
  <p>The DeSantis market is now down to 57%, courtesy of Sid Sid. The weird thing is that a couple hours later (11:26pm) Wednesday night, Johnny bought it down to 56%, but then sold it back at 1:31am. So it seems like Johnny thinks the true price is higher now and it wasn’t quite as much of a steal as it might have seemed, but it was still a good deal.</p>
</blockquote>

<blockquote>
  <p>Actually, I just checked the leaderboard again, and it seems that Sid Sid buying down to 57% last night was enough to officially put me in 4th on the leaderboard. I’ve now passed Connor de-jure as well as de-facto, and my “I’m coming for you, Mark” name seems more appropriate now.</p>
</blockquote>

<blockquote>
  <p>Other than that, I’ve barely been checking Salem at all. It seems like we’re going through another quiet period again, and besides, I have the bot emails to alert me if there are any really good deals.</p>
</blockquote>

<h2 id="zubbys-mistake">Zubby’s mistake</h2>

<blockquote>
  <p><strong>06.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>09:40</strong> - I haven’t bothered checking Salem much lately since I figured that my bot would email me if there were any sudden changes, but I randomly checked again this morning and saw that I’d missed a lot of drama yesterday afternoon.</p>
</blockquote>

<blockquote>
  <p>At 2:52pm yesterday, zubby bought up DeSantis 57-&gt;69%, and then just as suddenly back down to 45% at 2:53-4pm. I wonder what happened there. My assumption is that zubby was intending to buy NO, but accidentally bought YES instead and immediately sold and bought NO when they realized their mistake (but not before 50P managed to sell $25 of NO at 69% - talk about lucky timing!). Anyway, the market is now down to 41%, though of my course my limit was at 51%, and thus I didn’t benefit at all from the further drop - if anything, it is bad because it puts Mark further ahead. But at least I did lock in a profit on the previous buy. Also, Johnny canceled the 8% YES limit on Newsom (presumably to partially cash out his large NO stake from when he caught Josiah’s spike) that I was hoping to trade against later and moved it down to 5%.</p>
</blockquote>

<p>Note: 50P <em>bought</em> NO at the peak, rather than selling NO. Obviously <em>selling</em> NO during a price spike would not have been lucky timing.</p>

<blockquote>
  <p><strong>10:37</strong> - I got on the desktop to investigate why my bot didn’t email me yesterday, and it turns out it hit a connection error while querying Salem at 12:39am yesterday and hadn’t been running for the last day and a half. I added logic to ignore errors and keep going, and to email me the first time an error occurs so I can investigate in case it gets stuck permanently unable to connect. But this error was presumably just transitory and the first such error in nearly two weeks of running, so hopefully they won’t be common.</p>
</blockquote>

<blockquote>
  <p>I also checked the standings again while I was at it, but barely anything had changed. I’m now 11.7% behind Mark, which goes up to 12.0% assuming the three end of month markets resolve NO as expected. This jumps up to 19.6% if DeSantis resolves NO and only 0.9% if it resolves YES. As before, my best hope is that DeSantis does run soon, it’s just that my relative standing to Mark has increased very slightly thanks to my recent wins.</p>
</blockquote>

<blockquote>
  <p><strong>10.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:43</strong> - During Avalon on Sunday, I got a bot email about a fetch error, but figured it wasn’t urgent, and in the afternoon, I restarted the bot (so it would send another email if it failed again) and also manually re-generated the API token, which I have to do every Sunday because Google is stupid. (The API token isn’t related to the fetch errors from Salem, I just need it to send emails). Monday evening, I got another fetch error email and again restarted the bot. In both cases, it was just an isolated failure. I think I’m going to need to reprogram it to not send emails after isolated errors. The only reason I set it to email after the first error was so that I could check in case it got stuck erroring out repeatedly, but so far that has never happened.</p>
</blockquote>

<h2 id="atacms-and-storm-shadow">ATACMS and Storm Shadow</h2>

<blockquote>
  <p><strong>11.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:49</strong> - I got home to another Salem bot email, the first of what would be many due to chaos in the “Send ATACMS to Ukraine?” market.</p>
</blockquote>

<blockquote>
  <p>It first started at 6:40pm on Tuesday when Sid Sid bought 36-&gt;39% and then sold again two minutes later and left a comment asking the mods to clarify “is this any type of long range missile or the ATACMS in particular”. It seems that the British announced that they’ll be providing long distance missiles to Ukraine, which means that the US now sees no need to provide its own ATACMS, and so it could resolve YES or NO depending on whether the British missiles count or not and Sid Sid presumably sold due to uncertainty over the resolution criteria.</p>
</blockquote>

<blockquote>
  <p>At 6:44pm a nobody (Richard Zhu) bought it down to 23%, thus triggering my first bot email. I looked into it after getting home and considered buying NO shares myself, but decided to stay out due to uncertainty over the resolution criteria, and the fact that a NO would take until July 31st to resolve. In retrospect, I’m glad I stayed out.</p>
</blockquote>

<blockquote>
  <p>From 9:40-10:15am Wednesday morning, 50P bought it back up to 33%, over the course of 11 transactions. For some reason, 50P always splits their buys into a long stream of tiny transactions. It’s a suboptimal strategy since the Manifold fee algorithm results in very slightly higher fees when splitting up a purchase compared to buying the same amount in one transaction, though I’m guessing that most players don’t know this, probably not even a lot of the top players. More significantly, it’s annoying to me because it clogs up the bet history and makes it hard to read.</p>
</blockquote>

<blockquote>
  <p>It didn’t stop me from getting another bot email at 10:15 though, since my bot just triggers on a total 7% variation in a 15 minute window. I noticed the email five minutes later and checked the market, but again decided to stay out. Ironically, what I didn’t notice is that at the very moment I checked, 50P sold back to 26% at 10:20. Then from 10:26-27, they bought back to 29%. I have no idea why they did any of this, although it’s ultimately meaningless. Still weird though, and if I were a mind-reader, I guess I could have profited off these gyrations regardless of the ultimate outcome. Sadly I am not a mind-reader.</p>
</blockquote>

<blockquote>
  <p>The gyrations continued when zubby stepped in and bought it up to 34% in two transactions at 10:41 and 10:49am. At 9:10pm, 50P made one last buy up to 35%.</p>
</blockquote>

<blockquote>
  <p>Then at 1:31am, another nobody (Alexander Mengden), bought $10 three times -&gt;36% (50P isn’t even the only one splitting up their transactions for no reason), and then at 5:13 and 5:15am, bought it up to 45% , resulting in another bot email. Finally, at 7:10, Johnny stepped in and bought it down to 31% in three transactions, followed by a sale to 34% (incidentally, back in the early days of the contest, I wondered whether Johnny was a bot, but concluded that he wasn’t when I saw him buying and then immediately selling back like this, which just incurs fees for no reason).</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s the chaos in the ATACMS market, though it’s ultimately meaningless to me, not being a mind-reader and just sitting out. I did make one notable bet on Tuesday though. I put down $100 on DeSantis after seeing the Politico story about him cutting ties with a state fund-raising group in preparation for a likely run last Friday.</p>
</blockquote>

<blockquote>
  <p>The market had been 39% for the last day or two, but sadly went up to 41% that morning, presumably someone buying on the same article I saw, so my buy went 41-&gt;44%. It’s now back down to 42%, so Johnny and Sid Sid clearly don’t agree with me, but at least it’s basically even odds.</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s all the meaningless Salem nonsense for now. It took so long to recount that it is now 8:29, and thus I’m 10 minutes over the target entry length, and will also be leaving for work a tad later than intended. And I didn’t even get through Tuesday!</p>
</blockquote>

<blockquote>
  <p>Edit: I just tabbed over to the Salem tab I had open to double-check the DeSantis results in order to close it, and as I watched literally just seconds ago, a nobody (Ruston Eastman) bought up 42-&gt;46% (in three separate transactions) followed by Sid Sid buying back to 44%. Not that it matters.</p>
</blockquote>

<h2 id="twitter-ceo">Twitter CEO</h2>

<blockquote>
  <p><strong>20:40</strong> - I think my last entry was incorrect and I actually did see the sale down to 29% when I checked at 10:20am on Wednesday morning. Not that it matters.</p>
</blockquote>

<blockquote>
  <p>At 1:23pm today, I decided to check the Gmail app on my phone, just in case anything crazy had happened this morning. Even though my phone is connected to the wifi at work now, it still doesn’t help unless I actually bother to check my email, since Gmail is too stupid to actually send notifications and I never got SMS working.</p>
</blockquote>

<blockquote>
  <p>I was shocked to see multiple bot emails indicating that Twitter CEO was spiking, and immediately got on the Chromebook to investigate.</p>
</blockquote>

<blockquote>
  <p>It looks like Twitter CEO had sat untouched at 30% for the entire last week, until the fun began at 12:46pm today, as 50P slowly started buying it up, joined by Sid Sid at 12:50 and Spencer at 1:05. Josiah Neeley also threw in $48 (54-&gt;56%) at 12:56. Now that’s a name I didn’t expect to ever see again. It’s weird, since it really seemed like he’d given up entirely, and even doubling his money wouldn’t be enough to matter here.</p>
</blockquote>

<p>I really wish Josiah would come forward and explain WTF he was thinking with the tiny bet on Twitter CEO. Back when he YOLO’d into the Newsom market, he didn’t <em>quite</em> put everything on YES. He still had one small bet ~$50 on something else which he later sold to bandwagon onto Twitter CEO. But as a strategy, this makes absolutely no sense, because if he lost on Newsom, he would be stuck at the very bottom of the leaderboard no matter what, and having $50 vs $60 left over would not actually change anything. He should have either gone <em>all</em> in on Newsom or else sold it and attempted to rebuild. Going <em>mostly</em> in and then making other random bets with the last $48 makes absolutely no sense.</p>

<p>I guess I can’t <em>really</em> throw stones, since I didn’t sell out of everything else when I put most of my money into China COVID at the end of January either. However, I didn’t know that limit orders automatically get canceled when you go negative, so I <em>thought</em> that I was effectively going all in with my limit orders. Josiah had no such excuse.</p>

<blockquote>
  <p>Anyway, the market passed 37 at 12:50 (35-&gt;39%), triggering the 7% threshold on my bot for the first time. If I’d actually had SMS notifications working, I could have jumped in immediately and probably bought in while it was still in the 40s or 50s. It’s funny how nothing happens 99% of the time, and then something like this or Josiah’s yolo happens and I really regret not getting around to/managing to fully setting up the bot.</p>
</blockquote>

<blockquote>
  <p>…Anyway, back to Salem. By the time I checked the market, it was up to 86%. I decided to put in $1400 (86-&gt;92%). I didn’t want to go too deep because a quick news check indicated that the new CEO wouldn’t start until six weeks from now and the market might not resolve until then (i.e. after the 5/31 markets). This evening, I put in a $42 NO limit at 94% to try to free up some of the capital.</p>
</blockquote>

<blockquote>
  <p>Anyway, Sid Sid is now up to 11th on the leaderboard, presumably due to riding the Twitter CEO rocket, as well as their various other recent wins. I’m surprised 50P hasn’t shown up on the leaderboards yet.</p>
</blockquote>

<blockquote>
  <p>Twitter CEO wasn’t even the only Salem drama this morning. I also discovered that Salem had commented on the ATACMS market at 9:30am, unexpectedly ruling that the British missiles didn’t count and it had to be literal ATACMS, and it immediately tanked (now 15%).</p>
</blockquote>

<blockquote>
  <p><strong>12.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:29</strong> - A bit more excitement on the Salem front: I almost had a heart attack when I checked my email after getting up this morning and saw “63.323%-94.000% Elon Appoints New Twitter CEO?”. Fortunately, it looks like the new CEO is still going to happen, but for some reason, a nobody (David Lawrence) suddenly decided to buy down from 94 to 63% overnight. It looks like they even sold their NO stake in “Nuclear Use in Ukraine” (10-&gt;12%) to do it.</p>
</blockquote>

<blockquote>
  <p>Johnny had already bought it back up to 84%, but I figured there was still a bit of profit to be made and bought $1211 more myself (84-&gt;91%). Now I really need to start freeing up capital. I put in a $16 NO limit at 92% and another $22 at 94% in hopes that people will help cash me out.</p>
</blockquote>

<blockquote>
  <p><strong>11:13</strong> - At 11:10, following our team meeting, I randomly decided to get out my chromebook and check email just in case before leaving for my usual walk. Much to my surprise, I had a bot email from 11:01, “33.698%-44.516% DeSantis to Run for President by Summer?”, as well as a resolution email saying that Twitter CEO resolved YES.</p>
</blockquote>

<blockquote>
  <p>Twitter CEO went up 93% before resolution, so I lost the $16 from my 92% limit, but overall, it was a pleasant surprise, since I was worried that the money would be tied up for six weeks. It’s funny because yesterday afternoon when the news first broke, I felt like it was basically a 50-50 whether it would resolve immediately, or only resolve in six weeks. However, since it didn’t resolve yesterday, I assumed it would be the latter. If I’d known, I would have of course dumped in my entire fortune rather than trying to cash out, but of course, there’s no way to know things like that, and having the money tied up for six weeks is pretty bad (especially when the current rates on the 5/31 markets were barely lower, and there would also be the DeSantis and Erdogan wildcards during that time).</p>
</blockquote>

<blockquote>
  <p>As a joke, I commented “Deploying more capital - steady lads.” this morning, and it was selected as the “Proven Correct” comment. Meanwhile, “Smartest Money” was “ussgordoncaptain bought S$500 of YES from 37% to 53% 4 months ago”, which was a bit of a surprise, since every time I’ve checked for IIRC the last month or two, ussgordon has been sitting on all cash. I guess they made a big profit flipping it four months ago and that counted them as “Smartest Money” somehow. It really should have been Sid Sid or 50P, who were actually first to trade on it, but I guess the fact that they split it into many small transactions means it didn’t get flagged by the algorithm.</p>
</blockquote>

<blockquote>
  <p>The other email was the DeSantis thing. It looks like Spencer randomly bought from 45-&gt;38% at 10:46 and 10:49, and then Alvaro de Menard bought down to 34% at 11:00, this triggering my bot almost exactly at the 15 minute threshold. Alvaro immediately sold half back though, and then Johnny bought up 36-&gt;39%.</p>
</blockquote>

<blockquote>
  <p>Anyway, I’m planning to check the standings tonight, but I should have gained a fair bit of ground towards Mark on the back of the Twitter CEO winnings, especially since I think Mark also had money on NO. Of course, I still probably won’t be able to take on Mark unless DeSantis resolves YES, but at least it’s a lot closer now.</p>
</blockquote>

<h2 id="desantis">DeSantis</h2>

<blockquote>
  <p><strong>17:33</strong> - More surprises on the Salem front: After work, I got on my Chromebook, around 5:19pm and noticed a bot email saying “41.563%-49.626% DeSantis to Run for President by Summer?”, which I didn’t think much of, since it had been fluctuating in that range for a while, and an email that someone had commented on the market.</p>
</blockquote>

<blockquote>
  <p>The comment linked to a news article saying that DeSantis was planning to move his campaign to a new HQ on Monday, which would trigger a 15 day deadline to file paperwork with the FEC, thus effectively forcing him to officially declare his run.</p>
</blockquote>

<blockquote>
  <p>Coincidentally, at the exact moment I checked Salem, Sid Sid had suddenly dumped their NO stake, spiking it from 50 to 78%, just seconds before I checked. Of course, it wasn’t really as close as all that, since I probably would have dithered for a few minutes before investing anyway.</p>
</blockquote>

<blockquote>
  <p>With it now at 78% I decided to stay out, since 15 days sounded like a lot and he could theoretically still decide not to run after all as well (or the article could be mistaken - there have certainly been false reports before, like the sources saying that an exploratory committee would be formed on the 11th.)</p>
</blockquote>

<blockquote>
  <p>Around 10 minutes later, after thinking about it more (and checking the calendar to confirm that 15 days after Monday is still before the end of the month), I decided to throw another $100 in after all. Conveniently, zubbybadger had stepped in and pushed it down to 76% in the meantime.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s almost unbelievable how much luck I’ve had on Salem lately, first with the Twitter CEO market and now this. Especially as DeSantis was basically <em>the</em> thing standing between me and overtaking Mark. Mark is still 3rd on the leaderboard for now, but I’m sure that will change if it resolves YES. Incidentally, Sid Sid was 11th on the leaderboard earlier today, buoyed by their success on Twitter CEO, but now they’re down to 15th again and PPPP has come out of nowhere to occupy their old spot at 11th. PPPP was the first person to buy DeSantis just now, 42-&gt;50% from 4:47-4:49, thus triggering my original bot email, but for some reason, they left the main spike to Sid Sid.</p>
</blockquote>

<blockquote>
  <p>It’s almost amazing to realize that if this does resolve YES, I will have made a profit on the market three times in three different directions, first YES, then NO, then YES again. Of course, I don’t want to count my chickens before they hatch, and I could still be surprised in the wrong way for once. We’ll just have to see what happens.</p>
</blockquote>

<blockquote>
  <p><strong>20:57</strong> - After my last buy, zubby bought down to 74% again, and later on, Zach Viglianco stepped in and tanked it to 65%, so I very nervously threw in another $100 (65-&gt;66%). Zubby also left a comment saying “I’d still guess the day after Memorial Day, but seems like a solid price”.</p>
</blockquote>

<blockquote>
  <p>Anyway, tonight I fired up the desktop (nowadays I’ve been leaving it on 24/7 even while not in use to keep the bot running but I accidentally hit the power button while plugging the keyboard and mouse back in.) and checked the rankings.</p>
</blockquote>

<blockquote>
  <p>I’m now 3.96% behind Mark, or 4.21% if the three sure markets resolve NO. And as before, it all comes down to DeSantis, but of course the disparity is now even more dramatic. If it resolves NO, I’ll be 20.26% behind Mark, while if it resolves YES, I’ll be negative 3.51% behind.</p>
</blockquote>

<blockquote>
  <p>I also discovered that Johnny is now very close to overtaking zubby again, which makes sense since Johnny has been very active lately, constantly profiting off the various spikes that have been occurring lately (plus zubby guessed wrong on the ATACMS thing).</p>
</blockquote>

<blockquote>
  <p>Out of curiosity, I also checked Josiah. He’s now up to “only” 782nd place, thanks to jumping on Twitter CEO early, but of course most of his portfolio is in the soon-to-be-worthless Newsom YES shares. He only has like $82 in cash, even after the win. I don’t know why he even bothered with that. He should have either sold Newsom and gone all in on the rush, or else dumped everything into Newsom, since he’s all in on that anyway.</p>
</blockquote>

<blockquote>
  <p>It’s now 9:05, so that’s 36 minutes I spent recounting Salem stuff today, even apart from the normal half hour journal entry this morning which was also mostly Salem. To be fair, it was a wild day on Salem.</p>
</blockquote>

<blockquote>
  <p><strong>14.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:48</strong> - Salem: 50P pushed DeSantis down to 61% Saturday morning. I really don’t understand why people are so bearish on it, given the news story Friday. At least some people are more optimistic. Josiah Neeley put down $89 on YES (presumably all his non-Newsom money) yesterday afternoon. I left the following comment addressed to him:</p>
</blockquote>

<blockquote>
  <p><em>I don’t understand why you’re actually playing again, but only with (presumably) your non-Newsom money. Even when you double your money like with the Twitter CEO market, it’s not enough to even move the needle. However, if you sold your Newsom shares and invested it like this, you’d still be pretty far behind, but it would only take a couple doublings of your money to get back on the leaderboard.</em></p>
</blockquote>

<blockquote>
  <p><em>Either you gamble everything on Newsom and don’t bother doing anything else or you sell your Newsom shares and actually start trying again. Doing both at the same time is pointless.</em></p>
</blockquote>

<h2 id="my-mistake">My mistake</h2>

<p>Like Zubby did earlier, I accidentally bought the wrong shares and immediately sold again at a hefty loss. Fortunately, the amounts involved were <em>much</em> smaller in my case, but it still stung.</p>

<blockquote>
  <p>Of course, I’m not one to lecture, as I made a minor blunder myself afterward. I decided to put down $50 on YES on the Erdogan market (35-&gt;36%), since I thought that was for him losing and the odds seemed favorable to me. It was only a minute or two later when I realized that YES is for Erdogan staying in office and sold back for only $43. Oops.</p>
</blockquote>

<blockquote>
  <p>I’ve known since late December that there were hefty transaction fees, but losing 14% just by buying and immediately selling (on a small bet with minimal slippage even) was surprisingly high even to me. For a long time, part of my strategy has been to try to minimize frivolous trading and only buy or sell things if you think you can make a decent profit or buy and hold to resolution. I think avoiding stupid transaction fees like this has given me a small edge over other players, who are much less careful.</p>
</blockquote>

<blockquote>
  <p>I’m guessing this lost $7 negates some of my clever but ultimately inconsequential plays earlier, like when I flipped “Ukraine to Take Major City” from 48 to 40, but then again, it is also dwarfed by bigger things. I gained at least a hundred or two on Twitter CEO and will win or lose more on DeSantis regardless of how that turns out. Still, that was pretty embarrassing and annoying to me.</p>
</blockquote>

<h2 id="the-turkish-elections">The Turkish elections</h2>

<p>Going into the Turkish elections, all the news I’d seen had been predicting that Erdogan would finally be defeated, and the prices on Salem matched that consensus. Unfortunately, the opposite happened, but at least I managed to make a bunch of imaginary money on Salem off of it.</p>

<p>As usual, I knew absolutely nothing about the elections or where to go for good information, so I just repeatedly searched through the latest tweets on Twitter and tried to find people who looked like they knew what they were talking about. Early on, there was a lot of confusion, as the official government tallies showed Erdogan with a huge lead, while the pro-opposition tallies showed a close race.</p>

<p>Eventually, even the opposition tallies showed Erdogan’s lead starting to widen slightly, and I figured that that meant it was pretty much a done deal and started betting YES. I think that following the numbers on the pro-opposition Halk TV website (thank you, Google Translate) might have been an advantage for me, because the official numbers had Erdogan’s lead steadily dropping (from the absurdly high initial numbers), so people looking at that might have been more uncertain. Of course, some people (namely Zach Viglianco) were making really dumb NO bets even after the result was basically certain, so who knows.</p>

<blockquote>
  <p><strong>13:12</strong> - Well that sure was a rollercoaster on Salem today. It’s funny, because I actually considered holding onto my YES shares this morning just in case in order to avoid paying fees to sell, but decided to sell so I wouldn’t subconsciously be rooting for Erdogan.</p>
</blockquote>

<blockquote>
  <p>I started following the results at 11:00am, but it wasn’t clear what to think at first, with the widely varying numbers cited by pro and anti-Erdogan counts, warnings of a “yellow mirage”, claims that opposition ballots were being excluded from the official count en-masse, etc.</p>
</blockquote>

<blockquote>
  <p>However, with the pro-opposition Halk TV site showing Erdogan’s lead slowly widening, I put in $50 on YES (51%) at 11:34, followed by another $150 at 11:37. Those were against a 51% NO limit by Zach Viglianco, so no fees. 50P, Sid Sid, and Johnny were the main other ones who had bought it up.</p>
</blockquote>

<blockquote>
  <p>With Erdogan’s lead continuing to widen on Halk TV, I put in another $100 (62-&gt;63%) at 11:59, followed by 200 (64-67) at 12:06 and 500 (67-74) at 12:14. I went off to read the ISW’s Ukraine War assessment while I waited for results to finalize, since the outcome already seemed pretty certain. (I figured that even in a runoff, Erdogan would probably win again, if he really won the first round by 3% - in any case, the predicted groundswell of opposition support was markedly absent.)</p>
</blockquote>

<blockquote>
  <p>I came back at 12:28 and was shocked to see it down to 56%, courtesy of Zach Viglianco, 50P and a nobody (Alexander Mengden). I quickly checked around to try to figure out what news might have spooked them, but the last update from Halk TV showed Erdogan’s lead continuing to slowly widen, and I couldn’t find any sort of good news on Twitter either. Meanwhile, Noah Lafountain sold (56-&gt;68) and then quickly bought back (68-&gt;59).</p>
</blockquote>

<blockquote>
  <p>I put in another 100 at 12:35 (59-&gt;61), though I was nervous since I couldn’t help but wonder why so many others were suddenly bearish (well Zach has been bearish all along, but still). Also strangely, the Halk TV website died at that time, failing to load from 12:28 to 12:50. No idea what that was about - maybe an accidental DOS from many people accessing it?</p>
</blockquote>

<blockquote>
  <p>At 12:50, Zach bought down (61-&gt;54) and I put in another 100 (54-&gt;56). But with it looking very likely to go to a runoff now, I’ll have two more weeks of angst. It’s funny though, because the outcome that would be good for me on Salem would be very bad for Turkey and the world, and vice versa. Meanwhile if a miracle happened and Erdogan did lose, it would completely take me out of the running on Salem. But that seems so remote now that I can scarcely hope for it anyway. I do wish it hadn’t gone to a runoff though, so I could cash out quickly and not have to worry.</p>
</blockquote>

<blockquote>
  <p><strong>13:27</strong> - P.S. I checked the Salem leaderboards one last time just now out of curiosity and there was a weird glitch where it just showed only me (in first place) and noone else. Refreshing put it back to normal though.</p>
</blockquote>

<blockquote>
  <p><strong>15.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>17:48</strong> - Well, I’ve gotten pretty far behind again, and this time I won’t even have the full 30 minutes because my laundry comes out of the dryer at 6:14pm. I suppose per tradition, I’ll start by recounting the Salem news.</p>
</blockquote>

<blockquote>
  <p>Zach Viglianco continued trying to keep the Erdogan market down, but he couldn’t win against everyone else, and it is now up to 75%, a level it first reached at 5:56pm yesterday. I had put in a NO limit to cash out at 80%, as that seemed like a fair price to me given the opportunity costs of holding shares for two weeks until the runoffs and the slight risk that the opposition somehow manages to win the runoff, but never got any takers, even though it had gotten tantalizingly close.</p>
</blockquote>

<h2 id="in-other-news">In other news</h2>

<blockquote>
  <p>At 10:30pm, just before getting off the computer to get ready for bed, I randomly decided to check Salem one last time and discovered that “No-Confidence Vote on McCarthy?” had spiked. A nobody (Tim Fred) had suddenly bought $1000 of YES at 8:02pm, spiking it from 20% to 57%. Presumably, they just joined and that was their entire balance of starting money.</p>
</blockquote>

<blockquote>
  <p>At 8:04pm, another nobody, Henry A Long, bought it down to 47%. It’s amazing how fast they were. It made me wonder if they had a bot, though I didn’t recognize the name, so if so, they haven’t been making much use of it. I sure hope it was just a fluke so I don’t have as much competition.</p>
</blockquote>

<blockquote>
  <p>Speaking of the bot, I wondered why it didn’t trigger and discovered that my bot had died a bit after noon due to the Google API token expiring, as Google stupidly expires all tokens for test apps after a week and I had forgotten to manually regenerate it again this week due to all the excitement. That also explains why I didn’t get any bot emails for the spikes in the Erdogan market Sunday evening. Oh well.</p>
</blockquote>

<blockquote>
  <p>The good news is that after Henry A Long, it had been untouched at 47% until I saw it two and a half hours later, so I figured there was still profit to be made and bought $200 NO (47-&gt;41%) and put in a YES limit at 25%, hoping to flip it for a small profit. It is now down to 25%, so pretty close.</p>
</blockquote>

<blockquote>
  <p>The big news today was in the DeSantis market though. In recent weeks, I’d rarely bothered to check Salem during the day, or maybe only once, but today I checked several times.</p>
</blockquote>

<blockquote>
  <p>I checked before breakfast around 8:15 and saw that DeSantis was now up to 70%. I checked the leaderboard to see if I was in 3rd yet, but not quite. However, Johnny had finally regained the lead from zubbybadger. I briefly got on the desktop to run the stats and saw that I was close behind Mark (0.75%), but not quite there yet.</p>
</blockquote>

<blockquote>
  <p>I checked again at noon and DeSantis was back down to 60%, and with it, Johnny back in second. Then I checked at 2pm, and DeSantis was back up to 69%.</p>
</blockquote>

<blockquote>
  <p>More significantly, PPPP had left a comment at 1:20pm saying “Here we go… Wish I had some more $$” and linked to a news article confirming that DeSantis’s campaign moved into its new campaign headquarters (triggering the 15 day FEC reporting countdown), as was reported by the story on Friday. PPPP bought $318 of YES (60-&gt;66) and it looks like they had to dump their stake in “Trump Indicted Again?” to do it, tanking that from 54-&gt;50% (since restored by Johnny).</p>
</blockquote>

<blockquote>
  <p>Fortunately, I’m not so money constrained, and put down $650 (69-&gt;71%). The reason my buy moved the market so little was that Zach Viglianco had a NO limit at 70% (funny how he seems to be on the contrarian side of everything these days) and I sized my purchase to make sure I got it all. He had another limit at 74% and I still have $3025 in spare cash, but I was hesitant to risk it, especially for something that might not resolve for two weeks.</p>
</blockquote>

<blockquote>
  <p>I checked Salem again at 3:20pm and DeSantis was now up to 80% (where it still is), which finally put me in third on the leaderboard ahead of Mark. Hooray! I’ll rest easier once the DeSantis and Erdogan markets are cashed out and locked in though. PPPP is up to 9th. Perhaps he’ll be the first person in months to sneak past the slumbering ussgordoncaptain and break into the hitherto static top 8.</p>
</blockquote>

<blockquote>
  <p>Also, when I checked at noon, I discovered that Johnny had put a NO limit on Erdogan at 79%, right below mine. So rude! (I say despite doing the same thing myself many times, etc.) I moved my limit down to 78% even though that’s almost certainly the wrong move mathematically. I suspect that the optimal number is actually higher than 80, but I tell myself that it’d be nice to get cashed out just so I can start rooting for Kemal in the runoffs with a clean conscience.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s now 6:15 and my laundry is calling. Amazing how I only got through the Salem news and still went over the time I had available.</p>
</blockquote>

<h1 id="may-16-31">May 16-31</h1>

<p><img src="/img/salem2/may2.png" alt="Score graph" /></p>

<p>May 14th saw me finally overtake Mark and reach third place in the Salem competition. The only thing left to do was to try to catch up to Zubby and/or Johnny and see if I could nab <em>second</em> place, but they were both so absurdly far ahead of me that there was no plausible way that could happen. It would take <em>multiple</em> major lucky breaks for me to even have a shot at catching up to them. Unfortunately, the <em>opposite</em> happened, with May ending in one of the greatest disasters of the entire competition.</p>

<p>But first, there were still the DeSantis and Erdogan markets to worry about.</p>

<blockquote>
  <p><strong>17.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>19:27</strong> - Tuesday morning was mostly occupied with journaling again. I also decided to put down $1088 more on DeSantis on Salem at 81%. Conveniently, a nobody had a NO limit at 81%, and this time I calculated the exact amount required to buy it all up, rather than just eyeballing it.</p>
</blockquote>

<blockquote>
  <p>This put me down to only $2055 in free cash, which made me a bit nervous, but today someone finally pushed Erdogan up to 78% and partially cashed out my stake there, bringing my balance back up to 2999. Also, while double-checking the numbers on Salem just now, I discovered that the DeSantis market is now at exactly 1000 bets. The main reason is that 50P keeps spamming the logs with long strings of tiny bets. I really wish they would stop, as it is very annoying and makes it difficult to actually read the bet history, and it’s not like it’s even a good strategy for them either.</p>
</blockquote>

<h2 id="the-bot-wars-heat-up">The bot wars heat up</h2>

<p>In addition to Zubby and Johnny being <em>massively</em> ahead of me, it didn’t help that they were also faster and more active than me. In fact, it turns out that Zubby had built a bot to compete with Johnny. Additionally, their bots seemed to be a lot faster and more reliable now. Back in March and April, Johnny would typically take 10-15 minutes to actually respond to any prices spikes, but this time they both jumped in under two minutes, meaning I’d have no chance even if I did have a working bot to compete with them, as it would take me longer than that just to get out my laptop, confirm the alert and actually place my bets.</p>

<blockquote>
  <p>At 1:50pm… I took advantage of the elevator on the way down to check email on my phone and saw a bot email indicating a big drop in “Biden favorite in summer 2023” market from 12:20pm. I figured it was likely just a dumb nobody YOLOing in, since there was no obvious news that would change that market.</p>
</blockquote>

<blockquote>
  <p>I doubted it would still be there an hour and a half later, but checked Salem after getting back anyway, just in case. Sure enough, a nobody had bought down from 86-&gt;63% at 12:19 for no reason. The shocking part was that zubby bought back from 63-&gt;83% at 12:20pm, followed by Johnny buying 83-&gt;85% at 12:21pm.</p>
</blockquote>

<blockquote>
  <p>Such tight timing couldn’t be coincidence, and made me wonder if they were running bots now after all, so I left a comment later, asking about it. Sure enough, they responded confirming that they were:</p>
</blockquote>

<blockquote>
  <p><em>Johnny: Well I have a script that polls for market changes once a minute and happened to be at my computer anyway. Still I frankly felt quite good about how quick I was. Until I looked at the actual seconds via the API: My 107 second reaction time got easily outclassed by zubby’s 24 seconds.</em></p>
</blockquote>

<blockquote>
  <p><em>Anyway, congrats on having come for Mark!</em></p>
</blockquote>

<blockquote>
  <p><em>zubby: A couple months ago I saw J10 aka The Goat clearly had some sort of monitor running and I decided I needed to do the same. I was on a golf course when Josiah Neeley decided to rage quit in the Newsom market, which is why I was extra mad!</em></p>
</blockquote>

<blockquote>
  <p>Learning that the top two have bots made me a bit dispirited, since there’s little hope of competing with them, even if they weren’t massively ahead of me to begin with. I do wonder about the various opportunities in the past that I caught, but presumably either the movements there weren’t big enough to trigger their bots or they were busy/not at the computer at the time or something. Oh well. The good news is that I’ve already achieved third place, which was beyond my wildest expectations even as late as the end of March, and my position is pretty secure, assuming no upsets in the DeSantis or Erdogan markets, as it’s basically just Mark who could plausibly pass me. And the same dwindling number of markets which makes catching up to zubby implausible also makes it unlikely that anyone else will catch up to me.</p>
</blockquote>

<h2 id="desantis-1">DeSantis</h2>

<blockquote>
  <p><strong>18.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:33</strong> - …I checked Salem this morning and discovered that DeSantis went up from 85% to 92% this morning, mostly due to zubby and Johnny. It looks like a bunch of news articles came out saying that DeSantis plans to formally declare next week. It’s now basically the same odds as Newsom (which zubby sold up to 8% to buy DeSantis), though the former will presumably resolve early, so they aren’t quite comparable. Meanwhile, Erdogan is back down to 76%. I still think I’ll be rooting for Kemal, as much of a longshot as that is.</p>
</blockquote>

<blockquote>
  <p><strong>07:55</strong> - I just checked the Erdogan bet history, and it looks like the dip is just due to zubby selling (78-&gt;75%) this morning (followed by 50P spamming it back up to 76), so it’s not a real loss of confidence, just zubby freeing up money to pump DeSantis. It’s funny, since you wouldn’t think someone with ~14k would ever be short of liquidity like that.</p>
</blockquote>

<h2 id="50ps-bet-spam">50P’s bet spam</h2>

<blockquote>
  <p><strong>19.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:50</strong> - … I left a comment for 50P on Salem complaining about them spamming the bet history, and pointing out that it is not even good strategy as splitting up transactions results in slightly higher fees (which I hoped to change their behavior if nothing else).</p>
</blockquote>

<blockquote>
  <p>They responded, saying that it was due to them using the arrow buttons on the site, which are apparently a shortcut for buying just 10 shares at a time, and that they didn’t know about the fee thing.</p>
</blockquote>

<blockquote>
  <p>To be fair, that’s a subtle point I only realized after reading the source code. Basically, Manifold calculates the final market price after your bet if there were no fees, then subtracts 10% * (1-P) from your bet amount where P is the <em>final</em> price, and then uses that reduced amount to determine the actual shares and market movement. This means that all else being equal, moving the market price farther towards the tail in a single transaction will result in lower fees, though the difference will probably be negligible in all but the most extreme cases.</p>
</blockquote>

<blockquote>
  <p>Anyway, so far it looks like 50P has switched to normal bets, so that’s nice.</p>
</blockquote>

<p>Note: That switch was sadly short-lived.</p>

<h2 id="the-twin-spikes">The twin spikes</h2>

<blockquote>
  <p><strong>20.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>16:28</strong> - Last night, I checked in on Salem again and discovered that my 78% NO limit on Erdogan was fully cashed out, so now my interests on Salem are once again aligned with what is best for Turkey and the world. Although even if by some miracle Kemal does win, it would still be a very unfortunate situation, since they already lost parliament.</p>
</blockquote>

<blockquote>
  <p>…at 11:51 [on the 20th], I saw a Salem bot email from 11:11, “7.395%-18.458% Newsom to Run for President by Summer?”. I was pretty frustrated that I only saw it 40 minutes later, despite actively being on the Chromebook the entire time. I think I must have put it in fullscreen mode while reading. I normally use fullscreen mode whenever I’m reading anything in order to free up that extra bit of screen space and move the text I’m reading right up to the top edge of the screen in order to make the sight lines more comfortable. Presumably, I spent 40 minutes in full screen mode on Wikipedia and thus never noticed the new mail on my Gmail tab.</p>
</blockquote>

<blockquote>
  <p>Anyway, it looks like a nobody put $500 on YES (7-&gt;18%) at 11:10, and I bought $2000 NO (18-&gt;10%). I was nervous about being low on cash, down to only around 1k with the Turkish elections, etc. still coming up, so I put up a small YES limit at 9% to try to cash out a little.</p>
</blockquote>

<blockquote>
  <p>I was confused about why Johnny and zubby would have still not hit the spike 40 minutes later, despite being confirmed to have bots. I noticed that “Nuclear Use in Russia-Ukraine War?” was up to 22%, and discovered that the same person had put down $490 on YES at 11:11 (11-&gt;37%). Presumably it was a new player who had decided to YOLO their entire starting stake between two markets.</p>
</blockquote>

<blockquote>
  <p>Anyway, Johnny had bought it down from 37-&gt;29% at 11:13, just two minutes later (followed later by another nobody to 22%). I assumed that he had thus seen the spike and just didn’t think it was worth locking up his money in Newsom at 18% for some reason.</p>
</blockquote>

<blockquote>
  <p>However, I checked again a couple hours later and saw that Johnny had put down $500 NO on Newsom, cashing out $17/50 of my limit. So I guess I just got lucky that he only noticed the nuclear spike and missed the Newsom spike which happened at the same time. Anyway, after further thought, I decided to cancel the rest of my limit order. I figured that should I need to free up money, it’d be better to just eat the transaction fees and sell my lowest shares, and keep the money “invested” in the meantime.</p>
</blockquote>

<h2 id="more-leaderboard-adjustment-reverse-engineering">More leaderboard adjustment reverse engineering</h2>

<blockquote>
  <p><strong>21.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:33</strong> - Saturday evening, I chatted with my parents. I also spent a while, perhaps 45m plugging the old late-April Salem leaderboard dumps into the adjustment solver and debugging. No matter what I tried, there was an inconsistency, but it was related to PPPP and Alvaro de Menard, rather than Mark and Connor like might be expected, the inconsistency happened with just the constraints from the leaderboard dumps, not looking at historical first-day data, and it arose from the first leaderboard dump I did, not the later ones when I was manipulating the GDP market to try to push Mark past Connor.</p>
</blockquote>

<blockquote>
  <p>…I spent most of the morning up until around 1pm further investigating the Salem leaderboard data inconsistency. I figured out that it was due specifically to the out of place positioning of Alvaro de Menard in my first dump, where he had a portfolio value much lower than the surrounding players for some reason.</p>
</blockquote>

<blockquote>
  <p>The first point in time consistency with the balances from the leaderboard dump was at 9:14:33, and I looked at the ten points before that and calculated everyone’s balances then. It looks like I made the dump right after I dumped the 1% GDP market, bought up NO on the 3% market, etc. The last point where Alvaro de Menard’s score was consistent with his leaderboard position was before 9:12:21, when I first sold my 1% GDP shares.</p>
</blockquote>

<blockquote>
  <p>It seems that something I long feared is true - the leaderboard data isn’t actually atomic. It seems that the balance values shown are always up to date, but it may take several minutes for market value changes to be reflected in the rankings. I always wondered about that, since I wasn’t sure if the server would actually recalculate everyone’s portfolio value and recalculate the rankings every time anyone made a bet in any market. It wouldn’t be a problem with the relatively small scale of the Salem markets, but it probably wouldn’t scale to the main Manifold site, which the code was written for.</p>
</blockquote>

<blockquote>
  <p>Anyway, I just modified the history matching code to include points up to 2.5 minutes before the first point that matches the given balances when calculating the range of differences to associate with that ranking, and after that the constraint solving had no inconsistencies. I then applied the new constraints to the historical first day data, and there were now only two time points that were consistent with the data, so I now have either exact or near-exact adjustments for everyone.</p>
</blockquote>

<blockquote>
  <p>Of course, knowing the exact adjustment values is completely useless and not worth the considerable time I’ve devoted to the topic over the last couple months, but I wanted to investigate it just out of curiosity.</p>
</blockquote>

<blockquote>
  <p><strong>23.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:33</strong> - Monday morning before work, I checked my Linux desktop again… I also checked in on my Salem bot script and discovered that it had just frozen at 11:37am on Sunday. No errors or anything, it just wasn’t doing anything. In addition to restarting it, I remembered that Google stupidly requires the tokens to be regenerated every week and I’d forgotten to do that, so I once again performed the weekly ritual of deleting the token and going through the browser flow to manually re-authorize the app. I guess it’s a good thing I apparently didn’t miss much on Sunday when the bot was unknowingly dead for a day.</p>
</blockquote>

<h2 id="despair-and-determination">Despair and determination</h2>

<blockquote>
  <p>I checked my computer around 2 and found a bot email from 1:06 saying that McCarthy had spiked from 25% to 34%. Johnny had already bought $100 NO (34-&gt;32%) just a minute or two after the spike, but he evidently didn’t think it was worth pushing all the way. It wasn’t a good sign, but I decided to throw $100 in myself (-&gt;30%) and upped my YES limit to 26%.</p>
</blockquote>

<blockquote>
  <p>The last time this happened, the spike was still there two and a half hours later (though nobody Henry A Long jumped in just minutes later and took part of it) and Johnny only stepped in <em>after</em> I bought mine, but it seems that Johnny has fixed his bot or is paying more attention now or something, so I’m unlikely to get even the minor gains I saw from my bot before. Even if I ever managed to fix the bot to send SMSs, he would still probably be faster than me. It is annoying, although I guess it doesn’t matter that much since I’m massively far behind Johnny and zubby with no realistic chance of catching up, even if they weren’t taking all the best profit opportunities and constantly widening the gap, and also have little chance of being passed by anyone from below. But still, I can’t help striving to rise further.</p>
</blockquote>

<h2 id="desantis-declares">DeSantis declares</h2>

<blockquote>
  <p><strong>24.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:22</strong> - …Anyway, besides the previously evidenced journaling Tuesday morning, I also googled for DeSantis news as usual every morning and saw a story saying that he specifically planned to announce on Wednesday. I decided to throw in $300 of my remaining $1101 in cash on Salem, (91-&gt;92%). I figured if it would only be resolving in a day, then even relatively small gains are still favorable, since I could still use the money for other markets (Erdogan, Newsom, etc.) afterwards.</p>
</blockquote>

<blockquote>
  <p>Still, I was surprised how fast it went up. Around noon, I read that morning’s Money Stuff, which mentioned under “Things Happen” at the end that DeSantis was planning to announce with Elon Musk. A quick google showed that sure enough, there were news stories ~20 minutes old saying that DeSantis was now specifically planning to announce at a Twitter Spaces event with Musk on Wednesday afternoon.</p>
</blockquote>

<blockquote>
  <p>I threw in another 500, but of course other people had already seen the same story and pushed it up to 95%. Within hours, it had jumped to 98%, where it remains.</p>
</blockquote>

<blockquote>
  <p><strong>25.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:13</strong> - As far as Salem goes, besides the excitement on Tuesday I described yesterday, I also planned to</p>
</blockquote>

<blockquote>
  <p>(p.s. Just got a bot email at 7:31 while writing this and went to check it, but it turned out to be nothing useful, just KDM selling Trump Twitter back down, 54-&gt;45%, and then down to 40% while I was checking)</p>
</blockquote>

<blockquote>
  <p>Anyway, I thought DeSantis would declare in the afternoon, sometime after 3pm. I was planning to check the news periodically to try to find out when he officially declared so I could quickly dump in my last 300 at 98% to earn a few extra pennies before the market resolved.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, I first randomly checked the news at 12:52 and discovered that he had already declared and the market had already resolved nearly an hour before, so so much for that. Not that it matters that much, since $6 is pretty trivial, but it was still annoying.</p>
</blockquote>

<blockquote>
  <p>The main reason for not dumping my last 300 in before was because I wanted to keep some dry powder until right before resolution in case some other opportunity came up, but in retrospect, that is pointless if I’m not going to be checking the markets during that time anyway.</p>
</blockquote>

<blockquote>
  <p>I think I did check once in the midmorning, but normally, I don’t bother checking my email and/or Salem much during the workday, and thus wouldn’t have been able to deploy that 300 to jump any opportunities that improbably arose anyway, and thus I should have gone ahead and thrown it in that morning. Oh well.</p>
</blockquote>

<blockquote>
  <p>The other thing I was planning was to buy some more Newsom as soon as the market resolved. I figured that lots of people would have money tied up in the market suddenly freed and this would probably lead to major moves in various markets, and that would probably include buying up the free interest in Newsom (and likewise the two Ukraine markets), and thus I thought about trying to buy some after resolution before the inevitable drop.</p>
</blockquote>

<blockquote>
  <p>It’s funny, because that morning, I was debating to myself how much Newsom I would buy at 9% after resolution, since I wanted to preserve most of my money for the Erdogan market. I had decided on just getting 100 or 200. However, that turned out to all be for naught, since I only discovered the resolution an hour later after everyone had already started buying stuff (and Newsom was suddenly down to 6%).</p>
</blockquote>

<blockquote>
  <p>But of course, those were all trivial amounts. It’s not like I’m going to catch up to zubby or not based on winning $6. The real game-decider will be if A) something highly improbable happens and B) I am somehow the first person to find out and trade on it. I think that’s the only way I could hope to catch up with Zubby and Johnny at this point. The most plausible way that could happen is if Kemal wins the election, but that’s a longshot, and it’s even more of a longshot that I’ll be able to take most of the profit in the process. Realistically, the rankings are already fixed (at least for the top 8 - the bottom half of the leaderboard has been a lot more fluid).</p>
</blockquote>

<h2 id="the-debt-ceiling-debacle"><strong>The debt ceiling debacle</strong></h2>

<p>Near the end of May, I got blindsided when the debt ceiling market was suddenly revealed to actually be a deceptive trick question. I already wrote about this at length in the <a href="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html">first part</a>, but I’m still frustrated about it. You know things are bad when even <em>Richard Hanania</em> himself, the <em>founder</em> of the contest, was deceived by this market. But ranting won’t change the outcome.</p>

<p>I guess the one positive thing that can be said about this farce is that I’m lucky I didn’t lose <em>more</em> than I did. If I had actually had a working bot, it probably would have woken me up during the night when Malte starting his massive NO bets, and I probably would have assumed it was dumb money and starting buying it back up, and thus lost even more money.</p>

<p>In fact, this is actually exactly what happened to Johnny. For a while, he kept buying YES while Malte continued buying NO. However, Malte then posted a comment explaining the ruse, and Johnny dumped the market himself, and thus made a huge profit to compensate for his earlier losses trading against Malte.</p>

<blockquote>
  <p><strong>28.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:29</strong> - Salem: Last night around 8:10, following the chat with my parents, I checked the news and saw that a tentative debt ceiling deal had been reached, so I put in $500 (92-&gt;93%), although I immediately regretted it after it occurred to me that it likely wouldn’t resolve until after May 31st, and that it would be better to keep the money to put in the Erdogan and 5/31 markets, and put in a NO limit at 94%, hoping someone would bail me out.</p>
</blockquote>

<blockquote>
  <p>I also checked the news about the Turkey elections, and saw that there was no sign of a turnaround and everything pointed to Erdogan winning the runoff, so I reluctantly put down $300 on YES (84-&gt;86%).</p>
</blockquote>

<blockquote>
  <p>Unfortunately, disaster struck, as I woke up to two bot emails this morning saying that the Debt Ceiling market had tanked. Several months ago, zubbybadger had commented on the market asking Salem whether suspending the debt limit would count or not, and they said it would count as NO. I’m really kicking myself for not paying attention to that now.</p>
</blockquote>

<blockquote>
  <p>Overnight, Malte Schrödl (who jumped onto the leaderboard after profiting the most off the DeSantis bounce) dumped the market and commented pointing out that the current plan is to “suspend” the debt ceiling rather than “raise” it. Later on, Johnny also dumped it much harder, down to 27%.</p>
</blockquote>

<blockquote>
  <p>It was extremely frustrating since it feels like the whole time the market has been a secret “gotcha” that was not actually predicting what the title suggested and what everyone thought it was. I’m probably still going to end up in 3rd, but this pretty much permanently slams the door on my hopes of advancement, and it feels like continuing to play is pointless.</p>
</blockquote>

<blockquote>
  <p>At first I decided not to do anything, but later on, it went up to 35%, and after agonizing over it for a while, I just decided to sell (6:40, 35-&gt;30%), thus locking in my loss. My portfolio value is now back down to where it was a week ago, before the DeSantis bounce. But of course, I’ve lost far more ground than that relative to Johnny and Zubby. It’s so frustrating how weeks of hard work could be undone in an instant over a stupid gotcha. I guess at least I should be thankful that I didn’t put more in.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s now 6:42, I guess hopefully I can forget about things until the Turkish election results start coming in, although it all seems so pointless now.</p>
</blockquote>

<blockquote>
  <p><strong>06:56</strong> - I ran the stats script on my desktop for the first time since Sunday afternoon last week. It looks like I was 38.6% away from second place as of last week, although I likely got closer following the DeSantis pop. But all that’s history now, obviously. I’m currently 44.1% behind, which would go down to 27.9% if the market somehow resolves YES and up to 51% if it resolves NO as expected. (I sold my own shares, but Johnny and Zubby are both betting heavily on NO now, so the resolution is still significant).</p>
</blockquote>

<blockquote>
  <p>As impossible as making up a 30% deficit seemed a week or two ago, making up a 50% deficit with a few less weeks of playtime and several less markets left to resolve seems even more impossible.</p>
</blockquote>

<h2 id="the-turkish-runoff-election">The Turkish runoff election</h2>

<blockquote>
  <p><strong>09:24</strong> - A bit after 7, I decided to watch the first episode of Wednesday (in English) in order to try to distract myself from the Salem debacle and wait for the election results to come in. I’ve heard it’s really popular, but it didn’t seem especially appealing to me. I was also surprised that the episode kept going after the cello montage, since that seemed very much like an end-of-episode kind of scene.</p>
</blockquote>

<blockquote>
  <p>After that, results still weren’t in, so I forced myself to go through a dialog on Satori Reader, not paying much attention due to thinking about Salem. I thus started following the results at 8:18am, checking HalkTv periodically while constantly searching Twitter for news and analysis.</p>
</blockquote>

<blockquote>
  <p>This time around, HalkTV showed Kılıçdaroğlu with a lead hovering around 2% which only started to slip a bit around 8:37. It seemed improbable, but that was enough that he might win if it held up (HalkTV notably never showed a lead like that in the first round).</p>
</blockquote>

<blockquote>
  <p>It was hard to find any election analysis this time around, but I eventually managed to find one guy, Grady Wilson around 8:28, and saw a post where he said that even though the Anka showed the opposition in the lead, Erdogan was still “a clear favorite”.</p>
</blockquote>

<blockquote>
  <p>At 8:43, I saw another post from Wilson with a chart of six high reporting districts, showing that Erdogan was beating his 2018 numbers in all six, and the lead on HalkTV had started to slip a bit as well, so I finally became near certain that Erdogan would win.</p>
</blockquote>

<blockquote>
  <p>However, nobody had touched the market since last night, and I foolishly thought that meant that noone else was paying attention and I could afford to wait for another update or two, just to be safe. While I was wavering over whether to bet yet, at 8:46 zubby jumped in and bought it up 86-&gt;89%, so I flew too close to the sun. I immediately panicked and put in 3500 on YES (89-&gt;96%), out of my 3507 in free cash.</p>
</blockquote>

<blockquote>
  <p>I checked again a couple minutes later and discovered that oddly, zubby and Johnny had actually sold down to 93%. I can’t understand why they would do that when the outcome was even more obvious (by then, HalkTV’s numbers were in freefall), but I guess I can’t complain too much if they’re going to waste their money for no reason. It almost makes up for the big miss of me not jumping in at 86%.</p>
</blockquote>

<blockquote>
  <p>I discovered that I could sell my 222 Kherson shares for $210, which would fetch 232 on the Erdogan market, a very slightly profit even excluding the ability to reinvest the money once this resolves, so I went ahead and did that (and threw in the last $7, too). I went for a walk to the bay (thinking about Salem the whole way) and there was no further action.</p>
</blockquote>

<blockquote>
  <p>I left a comment on the market about missing out to zubby at 8:43 and wondering why they sold later, and then wrote this. It looks like Zubby jumped back in at 9:30 (93-&gt;94%), which is a bit unfortunate, since he will still be getting some more money. I was hoping nobodies would swarm in and take the remaining profit, but no such luck.</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s the morning’s excitement. I think I did gain some ground on Erdogan, but only a little, and with one more opportunity for a longshot win off the table (i.e. if the opposition had won and I was the first to recognize it and made a killing), my odds of taking second probably actually went down further.</p>
</blockquote>

<blockquote>
  <p>I just checked, and I’m currently 43.3% behind second (which is Johnny again, as he fell to second following the Debt Ceiling drop). Assuming that the Erdogan, Debt Ceiling, and 5/31 markets all resolve as expected, I’ll be 45.1% behind (compared to around 49.5% behind when I checked earlier this morning.) So I did get slightly closer but it is still an extreme longshot. Anyway, it’s now 9:41. I wonder how long I’ll be distracted by Salem today.</p>
</blockquote>

<blockquote>
  <p><strong>09:46</strong> - P.S. I ran the numbers, and it looks like I’ll be at a total of 10753 once Erdogan resolves, compared to 10781 last night before the debt ceiling debacle. In a stupid way, it almost seems fitting that the Erdogan boost was just enough to <em>almost</em> make up for my blunder last night. Anyway, I guess that really, I should be happy that the US is probably not going to default on the debt and tank the economy now, regardless of what happens to the imaginary internet points on Salem. Shame about what happened in Turkey.</p>
</blockquote>

<blockquote>
  <p><strong>13:07</strong> - This morning, I kept waiting for the Erdogan market to resolve,  but the message never came. I was hoping that nobodies would flood the market and punish zubby and Johnny for their mistake, but if anything, the opposite happened. Bizarrely, 50P actually sold a bit and put down some NO limits, even though the election was already decided, giving a slight extra boost to Johnny when he bought back in.</p>
</blockquote>

<blockquote>
  <p>Anyway, I checked in again at 1:04 just now and saw that it had finally resolved (at 12:59). I put in 2329 of cash (leaving me with 2000) into the three 5/31 markets, using my script to optimally divide them up. For a long time this morning, I kept thinking about whether I should just give up and stop playing Salem. It certainly doesn’t seem worth all the time and effort now. But I’m already heavily invested in the Newsom market, so I might as well do that at least. I think my current plan is to keep playing until the Debt Ceiling deal goes through and see if in some miracle, the market resolves YES then, which would at least give me a chance. If not, I guess I’ll probably just stop playing then. Or at least I intend to: knowing me, it will be hard to give it up.</p>
</blockquote>

<h2 id="scooped-by-zubby">Scooped by Zubby</h2>

<p>Besides the debt ceiling debacle and the Turkish elections, Sunday held one last notable minor event, a price spike in the afternoon. I successfully got the bot email and was (presumably) the first person to see it, but I waited too long to bet and Zubby stole it anyway.</p>

<blockquote>
  <p><strong>30.05.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>18:18</strong> - [May 28th] at 3:57pm, I saw a Salem bot email, “24.720%-48.221% Trump Indicted Again?”. Dylan Levi King had made a massive NO bet just minutes before, something that Dylan does on various markets from time to time for some reason. I quickly checked the news to see if there were any news stories that would have prompted the selloff and was still busy researching and thinking to myself about whether I should risk just throwing in $100 before researching when two minutes later, zubby jumped in obviating the issue. So that’s another minor loss for me (as usual a double loss, since not only did I not get the profit, but my competitor did, putting them that much farther out of reach). Oh well, catching up would have been an extreme longshot anyway, and things like these probably involve relatively small amounts compared to the Debt Ceiling fiasco.</p>
</blockquote>

<blockquote>
  <p><strong>01.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:29</strong> - Speaking of Salem, I also noticed Sunday that Malte Schrödl (the person who first dumped Debt Ceiling) shot up to 7th place, which I believe is the first time anyone new had entered the top 8 since the beginning of March (when I did). It made me think that I have a bit of extra competition now.</p>
</blockquote>

<blockquote>
  <p>He’s still way behind me, but the fact that he shot up from nowhere to 7th place in less than a week was pretty alarming. The other thing is that in addition to me having a large lead, most of the top players weren’t even playing at all, further increasing my security in 3rd. Besides Johnny and Zubby bitterly duking it out for first, the only other top player who was still active was Mark. But Malte could conceivably pass me if he somehow pulls another rabbit out of the hat like that.</p>
</blockquote>

<blockquote>
  <p>Incidentally, while it was frustrating that I got screwed over on a trick question with the debt ceiling market, it could have gone a lot worse. It would have been a real disaster if I had put in 1000 instead of 500, or if I had actually had bot notifications working at the time and saw Malte dumping the market as dumb money and bought it back up.</p>
</blockquote>

<h2 id="the-final-night">The final night</h2>

<p>The night of May 31st (Wednesday), I attempted to build a bot that would automatically check Trump’s Twitter for new tweets and bet my money on the Trump Twitter market when that happened. Making bets on Salem programmatically turned out to be easier than I expected, but unfortunately, finding new tweets on Twitter turned out to be much harder, or rather impossible, and I never finished the bot. (Fortunately, it didn’t end up mattering as Trump never tweeted anyway.)</p>

<p>I also put my last bit of money down on Newsom to earn a free 2.5% return overnight, though I regretted it in the morning.</p>

<blockquote>
  <p><strong>03.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>09:32</strong> - Anyway, back to Wednesday evening. After Avalon, I spent half the evening working on the Salem bot. For a long time, I’d been thinking about trying to make the bot scrape Twitter as well and send me an alert if Trump tweeted again, and later it occurred to me that it would be even better to just have it directly spend all my money on YES shares on Salem when that happened. Going by recent weeks, there’s no way I’ll ever win a race against Johnny and Zubby if it comes to me having to get an email from my bot and use human judgment, so the Trump Twitter market, where the outcome can conclusively be judged by a bot, seems like my one hope for advancement. Assuming of course that they didn’t write such bots themselves (which I highly doubt) and that Trump actually does tweet in the next two months (which seems pretty unlikely) and that everything actually works.</p>
</blockquote>

<blockquote>
  <p>I’d always assumed that scraping Twitter would be the easy part (it’s just fetching a webpage, right??) but wasn’t sure if I could successfully make bets on Salem from my bot. However, the opposite turned out to be the case.</p>
</blockquote>

<blockquote>
  <p>I first tackled the Salem half. Manifold does have an API, but I discovered that the documentation says there is an extra transaction fee applied to all bets and comments made via the API. I then looked at the network requests to see what happens when you place a bet normally in the browser, and fortunately, it turns out that it is the exact same as the normal API, just with a different URL.</p>
</blockquote>

<blockquote>
  <p>I successfully wrote some Python code to replicate this API and place bets (but substituting my API key for the JWT bearer token used in actual requests, since I worried that might expire) and tested it with a couple $1 bets. All in all, it took perhaps 30-40 minutes.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, Twitter proved to be more of an obstacle. Twitter does have an API, but unfortunately they charge for it. Meanwhile, you can’t just fetch a webpage either, as the tweets are not part of the html, but rather loaded dynamically via json requests. After a little while, I gave up and decided to put off Twitter for later.</p>
</blockquote>

<blockquote>
  <p>I also put my remaining $200 (well six $1 test bets followed by $194) into Newsom (one of the test bets was for Kramatorsk instead to make sure I could place bets on different markets) and examined the standings with my script. I noticed that Zubby and Johnny had opposite bets on the outcome for Trump Twitter and Trump Indictment, although the amounts involved were small and liable to change over time (case in point, when I checked again Friday night, they were both YES on Twitter), so I wouldn’t benefit from much of a paradox.</p>
</blockquote>

<h1 id="june-1-15">June 1-15</h1>
<p><img src="/img/salem2/june1.png" alt="Score graph" /></p>

<p>I ended May secure in third place, but impossibly far away from second. For a while, I was tempted to stop even trying, since the final ranks were practically fixed in stone already.</p>

<p>Fortunately, I decided to keep playing anyway, just so I would be in a slightly better position in the unlikely event that a bunch of miracles happened and I actually did get within striking distance of Johnny (which is what actually happened later on.)</p>

<p>The first half of June was quiet, partly because there were few active markets left and because I no longer had any incentive to obsess over Salem, but also because I was <em>on vacation</em> from June 6th through June 14th. The most notable event was that I programmed a new tool I called <strong>Salem Plus</strong>, which made things a bit easier later on.</p>

<p>But before all that, the <em>very beginning</em> of the month held another trivial disappointment for me:</p>

<blockquote>
  <p>Wednesday night, I went to bed at 11:01 or 11:16. I woke up during the night at 4:08 (probably not the only time), but had trouble falling asleep again for long and at 4:42, I finally gave up and decided to get up. …I went back to bed at 5:31 and woke up again at 5:57.</p>
</blockquote>

<blockquote>
  <p>I had been planning to put down perhaps $500 NO on Trump Twitter at 43%, since I figured that the risk of betting NO would be low once I got the Twitter bot working (which means I likely get huge gains in the unlikely event he does tweet) and the odds seemed pretty good at 43%.</p>
</blockquote>

<blockquote>
  <p>I knew that once the 5/31 markets resolved, everyone else who had their money locked up would likely rush into other markets and mess around with the prices, but I hoped that I could get in first. Unfortunately, the markets weren’t resolved yet when I woke up during the night, and only resolved at 5:39, while I was asleep, and by the time I had gotten up again, people (mostly Mark) had bought Trump Twitter down to 39%.</p>
</blockquote>

<blockquote>
  <p>In retrospect, I should have put my last $194 on Twitter rather than Newsom Wednesday night. But of course, I thought I could get the free 2.5% return on Newsom and then also jump into Twitter first. Oh well. I resignedly bought $300 NO (39-&gt;34%). Oddly, a couple people seemed to think it was undervalued. When I checked again in the afternoon, it was back up to 40%, so I put down another $100 (40-38). I think those odds are just about high enough that I’d probably close the gap with Johnny, assuming it resolved NO <em>and</em> I could magically invest my whole stash at that rate. But of course, you can only put in a little bit before the price slips and I wouldn’t risk my whole fortune on that anyway, even if I could. In any case, it is now down to 35%, so it doesn’t seem like I’ll be getting any more deals there.</p>
</blockquote>

<blockquote>
  <p><strong>16:12</strong> - One other amusing Salem thing Thursday morning: I got curious what following people did on Manifold, and so Wednesday evening, I commented “BTW, what does following someone here do? For some reason, I can’t find anything about this online.” on the Newsom market, hoping Johnny would explain (which he did). The amusing part is that my comment was somehow inexplicably chosen as “Proven Correct” with a cheerful announcement below it that “Robert made $0!” (presumably interpreting my comment as relating to one of the $1 test buys I made around that time).</p>
</blockquote>

<p><img src="/img/salem2/newsom_proven.png" alt="Proven correct screenshot" /></p>

<h2 id="johnnys-debt-ceiling-mistake">Johnny’s debt ceiling mistake</h2>

<p>Johnny misinterpreted the resolution criteria and foolishly rushed into the Debt Ceiling market, which meant that he lost a little money on transaction fees, buying in and then having to sell again, and thus he was <em>very slightly</em> less impossibly far ahead of me. Unfortunately, <a href="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html">as described previously</a>, I underestimated Johnny’s willingness to sell, and thus failed to take advantage and further punish the mistake by buying YES shares myself. This would have netted a small profit for me and more importantly, inflicted further losses on Johnny. Since Johnny was my only real competition by this point, his loss was my gain and vice versa, so buying YES would have effectively netted a double profit here.</p>

<p>Also, I again tried and failed to build a bot to watch Twitter.</p>

<blockquote>
  <p>…Also, when I checked Friday afternoon and evening, I discovered that the Debt Ceiling market was down to only 2%. For some reason, Johnny (and to a lesser extent, Sid Sid) decided to dump massive amounts of money into the market, as if they expected it to resolve imminently.</p>
</blockquote>

<blockquote>
  <p>I actually considered buying a few YES shares on the assumption that people would likely sell out of the market at some point to pursue other opportunities, but decided that the tiny potential profit wasn’t worth the effort and risk. Zubby, however, bought $60 YES for the same reason (and 50P later put in $10 as well).</p>
</blockquote>

<blockquote>
  <p>Johnny said that he misinterpreted an update that was added to the market description on the 28th, saying “A debt limit suspension without a raise would cause this market to settle as NO. For the difference between a suspension and a raise, see the first two paragraphs of this document.”</p>
</blockquote>

<blockquote>
  <p>I can see how that would make him (and Sid Sid) think that it would resolve NO immediately, even though normal common sense would say that a market which asks “will X happen?” can’t resolve NO until the end of the specified time period, since it is still theoretically possible that congress could decide to actually raise the debt ceiling, not just suspend it.</p>
</blockquote>

<blockquote>
  <p>Anyway, I was pretty happy to see Johnny dump half his money into this at dumb rates, since it means that either that money is tied up and not deployed in other markets where he could earn a lot more profit, or else he has to sell out early and eat huge transaction fees. Either way, the prospect of passing him is very slightly less absurdly improbable than it would have been otherwise (still not going to happen though, barring a miracle). Incidentally, when I ran the numbers Friday night, I saw that a YES resolution to the Debt Ceiling market would drop Johnny to 4th and Zubby would be a full 1.70x above the second place person (me). I jokingly wondered what it would take to bribe congress to raise the debt ceiling by a dollar.</p>
</blockquote>

<blockquote>
  <p><strong>08:38</strong> - Friday evening, I tackled the Twitter thing again. I found the JSON request that the browser was using to fetch Krugman’s tweets and replicated it in a Python script, and programmed the bot to email me when new tweets showed up as a test. It’s a good thing I decided to test it in just email-only mode before hooking it up to actual bets because it soon resulted in false positives.</p>
</blockquote>

<blockquote>
  <p>My assumption is that this was due to ads or promoted tweets showing up in the timeline and changing every once in a while, but there’s no way to know. I tried to investigate further Saturday morning, but by then, the exact same code was just returning 403s. Presumably the authorization token it was using expired. Seeing that made me give up on Twitter for the time being, since it seems hopeless unless I pay for the API.</p>
</blockquote>

<blockquote>
  <p><strong>05.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:46</strong> - I forgot to mention that as far as the Debt Ceiling market on Salem goes, Johnny sold most of his NO shares Sunday morning, going up to 5% (and it looks like he’s been using 5% limits to try to sell the last few). It looks like Zubby sold the $60 in YES shares for $97. I really regret not buying some YES shares myself, especially as I’d profit doubly, both from getting money myself as well as from costing Johnny more when he sells. I really underestimated Johnny’s willingness to sell and take a loss, as well as how much the price would go up if he did. I guessed that the price would be unlikely to even hit 3% after the selling, which is why I decided that the possible profit was negligible. Oh well, it’s comparatively minor in the scheme of things.</p>
</blockquote>

<h2 id="the-second-trump-indictment">The second Trump indictment</h2>

<p>I’d been ignoring the Second Trump Indictment market and not bothering to check for news, and thus missed out on the spike. The good news is that at least Johnny missed it too, so I didn’t fall further behind.</p>

<blockquote>
  <p>…I happened to check my Chromebook at 3:11pm, and that happened to be exactly when I got a bot email of a spike in the Trump Indictment market (68-75). Unfortunately, it seems that I was late to the party. It started the day at 51%, but people slowly bought it up, particularly from around 11-12 and again around 2-3:15. The email I got was just from one purchase by PPPP that happened to be large enough to bump it up by 7% in one go.</p>
</blockquote>

<blockquote>
  <p>I ended up putting in $400 (at 73-75 and 75-77), but I was pretty much the last person in, and it has been quiet since. The ironic part is that I had actually been thinking about buying NO shares recently, but had decided to wait until after I arrived in Atlanta to research the market. Which of course means that I seem to have missed all the excitement. (Of course, if I had decided to buy NO now rather than later, I would have actually researched it and seen the news stories from yesterday indicating a likely indictment soon.) Oh well, at least it doesn’t seem like Johnny made much more than me on the market either, as he invested relatively small amounts.</p>
</blockquote>

<blockquote>
  <p>As of this evening, Zubby is now well ahead of Johnny, thanks to the Debt Ceiling sale, and probably the Trump Indictment stuff as well (Zubby did buy a bunch of YES this morning 51-&gt;54%, as well as more later in the day.), when they had previously been neck and neck for a while. Meanwhile, Johnny is currently “only” around 42% ahead of me. I’ve probably gained perhaps 2% on him thanks to the debt ceiling blunder, which is not enough to actually make a difference, but still better than nothing. The real problem though is that there are only 21 markets left in the contest at all, and most of them are already pretty much decided.</p>
</blockquote>

<h2 id="salem-plus">Salem Plus</h2>

<p>Previously, all my Salem analysis and calculator scripts were done in Python on my Linux desktop, but I was about to go to Atlanta for a week and a half on vacation, and I obviously couldn’t bring my desktop with me. Fortunately, I came up with the bright idea of re-implementing everything in Javascript and embedding it into a custom website I dubbed Salem Plus.</p>

<p>By publishing Salem Plus to Github Pages, it would be a publicly accessible website, and hence I could use it from my Chromebook, even while on vacation. Unfortunately, I never got around to implementing any more than the most bare-bones possible functionality of displaying recent market activity (read-only) in a plain text dump. But even that turned out to be surprisingly useful.</p>

<blockquote>
  <p><strong>06.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>09:53</strong> - After work, I quickly set about working on the “Salem Plus” custom website concept. It wasn’t hard to replicate the web requests from my Python script in Javascript using the fetch api, and I even made another $1 test bet from JS, but the work of actually designing and coding a website by hand is more annoying, and I didn’t get beyond just listing the current market probability for each open market in a bare text list. I had grand dreams of adding all sorts of calculators and scripts, or even just stuff like highlighting markets in different colors if they had seen recent activity, but I never got around to that.</p>
</blockquote>

<blockquote>
  <p>After perhaps 30-40 minutes of working on the website, I got a headache and felt tired, so I took an ibuprofen, lay down on the bed for a little while, then watched an episode of Bojack Horseman.</p>
</blockquote>

<blockquote>
  <p><strong>14:11</strong> - I forgot to mention that Johnny sold part of his Trump Indict shares last night (77-&gt;74), meaning he took a loss on the 75-77 batch (though he did buy shares at much lower prices as well). I guess this means that if it does resolve YES, I’ll gain a bit of ground on him.</p>
</blockquote>

<blockquote>
  <p>Anyway, I worked for a while (perhaps 45m) on the Salem Plus website again this morning and then pushed it to Github. I’m writing the website in pure html using JS to assemble html elements by hand (e.g. with appendChild, createTextNode, etc.) which is pretty annoying and error prone. I probably should learn how to set up and use React, TS, etc., but I figured doing it all by hand would be good enough for something quick and simple like this. Anyway, the page is now at the point where it will display the last 10 bets in each market, with each market sorted by the time of the most recent bet. It’s all plain text and has no scripts or bet functionality built in, although the fact that it displays the exact decimal of the current market price rather than rounding might be useful.</p>
</blockquote>

<h2 id="vacation">Vacation</h2>

<p>While I was on vacation, I was obviously busy and preoccupied with other activities, but I still continued checking Salem (via Salem Plus) a couple times a day in spare moments to keep abreast of major market activity. I basically didn’t bother to do any actual bets though, apart from one calculated bet on World GDP that didn’t go well.</p>

<blockquote>
  <p><strong>09.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>09:46</strong> - …When we got back, I checked my Chromebook at 8:32 and saw a Salem bot email for Trump Indictment, and quickly checked the news and saw that the indictment came in and put my entire fortune on YES (97.67%-&gt;99.28%). Of course, I was late to the party this time, and everyone else had already bought in (Johnny in particular put in tons of money in the 80s and 90s) and it was already at 98% so I’d barely get anything, but I guess every little bit helps. It does mean though that Johnny presumably shot much farther ahead and now I really have no chance of beating him.</p>
</blockquote>

<blockquote>
  <p>For some reason, the market still hasn’t resolved yet. Normally, I’d worry about the opportunity costs of putting all my money in, but I assumed it would resolve imminently, and since I’m on vacation, I wouldn’t be trading much normally anyway. By pure coincidence, when I first got up this morning and checked my email, I got another email and saw that PPPP had made major investments in a couple markets just minutes before (YES on World GDP &gt;3%, NO on Trump Twitter). Although even if I did have money, I probably wouldn’t trade on them, especially the latter.</p>
</blockquote>

<blockquote>
  <p><strong>10.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:35</strong> - …When I got back (~2:30), I found that the Salem Trump Indictment 2 market had finally resolved. Strangely, Johnny sold ~2k of YES (at 99.3) shortly before resolution for no apparent reason. It’s almost like he doesn’t understand transaction fees at all. Of course, he’s made so much money over the last couple days that it won’t matter, if it ever would have (for example, he made a total of over 600 on just the Trump Indict 2 market, even after the dumb blunder at the end, and he’s been trading a lot in other markets too.)</p>
</blockquote>

<blockquote>
  <p>Salem also added their first new market in months, will Trump be indicted a third time. I put in 183 on NO at 35%. Also, PPPP had been buying up the “World GDP &gt;3%” market all day and posted a comment arguing that it should resolve YES immediately because the World Bank published an official document saying “Our baseline scenario calls for global growth to slow from 3.1 percent in 2022 to 2.1 percent in 2023”.</p>
</blockquote>

<blockquote>
  <p>I’m guessing that Salem will wait until an official GDP estimate is published using the particular linked data source and thus it won’t resolve until the end of the contest, but I threw in $500 (at 90%) just in case. In this case, the risk isn’t losing my money (probably) but just the risk that that it takes until the end to resolve and my money is locked up with a return of only 10%, so even though the actual chance of the early resolution was small, I figured the cost of taking a chance was relatively small. Johnny has been heavily betting against that market and now has it down to 85% again, so that’s hopefully going to cost him, though the amounts involved are small and there’s no way it will matter.</p>
</blockquote>

<blockquote>
  <p><strong>12:20</strong> - …Despite it being very barebones, I’ve been using my “Salem Plus” page more than the actual Salem website when checking in on the markets lately. I think it loads faster, and having all the markets on one page sorted by recency and with recent bets listed on one page is convenient.</p>
</blockquote>

<blockquote>
  <p>This morning, I tried to make some improvements for the first time. Of course, there’s no code editor - I had to modify it by typing the code into Github’s web editor, committing it, waiting a minute for it to deploy to Github pages, and then hoping that the changes worked. And this kind of thing has the worst edit-&gt;debug cycle even on the best of circumstances.</p>
</blockquote>

<blockquote>
  <p>I just made two minor changes - getting the bet timestamps to display in local time instead of UTC and merging bets by the same person on the same outcome within two minutes into a single line, in order to avoid the display being clogged up by “50P spam”. Incidentally, 50P is back to the old tricks, making eight consecutive $10 bets on Trump Twitter this morning, and other nobodies do it too, including one streak of seven this morning, so at least I had good test cases. This logic took me three tries to get working, since I couldn’t actually test the code other than deploying it and hoping for the best. Obviously more complicated and involved changes will have to wait until I get home.</p>
</blockquote>

<blockquote>
  <p><strong>17.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:57</strong> - While I was on vacation, I ended up checking Salem via my Salem Plus website several times a day, especially when I got home after a long time out at e.g. a restaurant. It doesn’t seem to have done me any good though. The most notable event was that someone suddenly dumped the World GDP &gt;=3% market down to 62%. By the time I saw it, Johnny had bought it up a bit, but then sold back almost to where it was. I was nervous buying into a dip that Johnny refused for some reason, but I ended up putting in $400 at up to 70%. (I put in a limit at 70%, buying 216 immediately and the rest at 70 when Johnny traded against the limit later). It was only when I checked Salem again this morning that I discovered why he was skeptical - he left a comment saying that the World Bank report PPPP cited listed the 2022 figure as an estimate.</p>
</blockquote>

<blockquote>
  <p>Other than that, the Iran deal market spiked to 48%, and later went down to 36% yesterday afternoon, but I stayed out of that. By pure coincidence, I was on my chromebook at the time and saw the bot email for the dip to 36% just minutes later, meaning I would have quite possibly beat Johnny to it, but I decided not to try to trade on that dip, which is just as well, as Johnny never bought it either, meaning I couldn’t have flipped it to him.</p>
</blockquote>

<blockquote>
  <p>Anyway, I checked the rankings with my script this morning and saw that I’d lost a bit of ground (currently 45% behind Johnny, but of course it will be much higher or lower depending on how the World GDP market resolves). It’s funny how before I left on vacation, I was really gung-ho about Salem and the Twitter bot and so on, but nowadays I barely care about Salem since there’s no hope of advancement anyway, and I haven’t been able to work up the motivation to work on Salem Plus or Twitter or anything else.</p>
</blockquote>

<h1 id="june-16-30">June 16-30</h1>
<p><img src="/img/salem2/june2.png" alt="Score graph" /></p>

<p>By the middle of June, I was barely even bothering to check Salem at all, since there was no realistic prospect of the final rankings changing anyway, no matter what I did. Fortunately, my luck was about to take a dramatic turn for the better.</p>

<h2 id="the-supreme-court-dress-rehearsals">The Supreme Court dress rehearsals</h2>

<p>Previously, I’d almost completely ignored the Supreme Court markets, but in late June, I heard that the Supreme Court’s calendar was almost over and they’d be releasing the decisions soon, and it occurred to me that I should try to find out when the decisions would be released to see if I could trade off the news.</p>

<p>As usual, I had no idea where to look for information at first, so I turned to Twitter, where I eventually came across the website <strong>SCOUTS Blog</strong>, which has a really good and timely liveblog of the Supreme Court Decisions, that I relied on for all subsequent days.</p>

<blockquote>
  <p><strong>22.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:19</strong> - I’d barely thought about Salem at all for the last week and rarely bothered to even check Salem Plus, but this morning I decided to try to follow the news of the Supreme Court decisions in the hopes of being the first person to find out and trade in the two Supreme Court markets (college affirmative action and student debt forgiveness). I started with a “live update” post from The Guardian, but eventually discovered that looking at Twitter is a lot more timely (albeit with lots of irrelevant crap to wade through, not that the Guardian liveblog didn’t also have irrelevant crap).</p>
</blockquote>

<blockquote>
  <p>However, they only released four decisions this morning, and it was all over pretty quickly. It sounds like tomorrow is the last day so they’ll be releasing a massive number of decisions then. It’s nice to have a dress rehearsal so I have more practice at knowing how to look for news of the decisions being released ahead of time.</p>
</blockquote>

<blockquote>
  <p><strong>23.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:30</strong> - At 7am, I once again spent eighteen minutes anxiously checking for news of the Supreme Court opinions. This time, I mostly relied on the live blog at https://www.scotusblog.com/, though I also refreshed the official Supreme Court website while waiting around. Once again they just released four opinions. It seems that there’s another non-argument day scheduled for the 27th, when they’ll presumably release all the remaining opinions.</p>
</blockquote>

<blockquote>
  <p><strong>07:51</strong> - P.S. I also briefly got on the desktop this morning to delete the Google API token and authenticate again. It’s so annoying that Google makes you do that. Incidentally, when I checked Salem Thursday morning last week after getting back from vacation, I discovered that I’d missed several market moves in the last day because of the expired token. I refreshed it before leaving the Tuesday before, but it only lasts a week. Not that it matters - market movements that are actually worth trading against are rare and Johnny always pounces on them in only two minutes in the cases where they are profitable, so there’s basically no point in even trying.</p>
</blockquote>

<h2 id="a-new-hope">A new hope</h2>

<blockquote>
  <p><strong>24.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>09:47</strong> - Friday night, I had a rare stroke of luck on the Salem front. At 9:08pm, a new face (Guangyu Song) randomly bought up Russia-Ukraine Ceasefire from 12.3% to 62.5%. (They put in 2142, presumably yoloing all they had in the hopes of jumping to the top.) I was researching DisneySea travel on r/japantravel at the time and just happened to notice the bot email at 9:10, only two minutes later.</p>
</blockquote>

<blockquote>
  <p>I was extremely lucky because big spikes like that are rare and Johnny always snaps them up in only two minutes. I hurriedly checked Google News, and then put in $100 before researching further since I assumed Johnny was racing me and every second counted. A couple minutes later, after I had checked the news more carefully and confirmed no signs of a plausible ceasefire, I put in $1000 more, and then at 9:22, I threw in 400 more to bring the total investment to a round 1500 (leaving it at 30.9%).</p>
</blockquote>

<blockquote>
  <p>I put in a YES limit at 18%, which if hit, would leave me with a total profit of $705, enough to at least make up for the debt ceiling debacle. I think that Johnny must have just been asleep or busy at the time or something, because he would normally never miss a spike like this, so I got doubly lucky. It did of course make me nervous, with him not jumping in, since there’s always the risk that the spike was real, but overnight, Johnny threw in 400 (30.9-&gt;26.0%) at 3:24am, reassuring me. (Of course, that means Johnny is making a bit of profit too, reducing the relative advantage, but you can’t win them all, and I still did pretty well.)</p>
</blockquote>

<blockquote>
  <p>Incidentally, Guangyu Song shot way up the leaderboard as the result of the spike. Even after my purchases last night, he was up to 11th place, but as of this morning, he has disappeared again.</p>
</blockquote>

<blockquote>
  <p>Anyway, even the profit from the ceasefire market is nowhere near enough to close the gap and advancing to second is still an extreme longshot, but at least I have a tiny amount of hope now. Perhaps if I get very lucky on the Supreme Court markets next week, I might be able to get in striking distance of Johnny. And I guess this incident proves that Johnny’s bot is not infallible and it actually is theoretically possible for me to reap a spike, albeit very unlikely and not something I can expect to happen again before the contest is over.</p>
</blockquote>

<p>Spoiler: It didn’t happen again.</p>

<h2 id="the-wagner-rebellion">The Wagner rebellion</h2>

<p>I didn’t even mention it in my journal at all, but the Wagner Rebellion happened during this time as well. I did notice that the “Ukraine to Take Major city?” market suddenly jumped up into the 40s in my cursory checks of Salem Plus, but I didn’t bother to investigate further or check the news, and didn’t even find out about the rebellion until several days later, after it was already over. I guess it’s for the best, since it meant I avoided making any trades I’d later regret.</p>

<p>P.S. It’s only just now as I was writing this that I realized that Guangyu Song’s spike of Russia-Ukraine Ceasefire was probably triggered by news of the rebellion. I guess that explains a lot.</p>

<h2 id="another-paradox">Another paradox</h2>

<blockquote>
  <p><strong>25.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>10:33</strong> - …I also worked a bit on Salem yesterday evening. I modified Salem Plus to filter out limit orders from the bet history (and added Guangyu Song to the names list). I also ran the Python script again, curious how the rankings would fair under various scenarios.</p>
</blockquote>

<blockquote>
  <p>I also used the multi-market bet allocation script to simulate what would happen under the ideal circumstances where I knew the resolutions of the two Supreme Court markets with certainty in advance and had the opportunity to be the first to bet on them. That’s unlikely to happen, but it’s what I’m hoping for, and it’s important to at least be prepared to take advantage of it.</p>
</blockquote>

<blockquote>
  <p>I modified the code to print out the total profit and the marginal values of an additional $1 bet as well as the bet amounts. If both markets resolve YES as expected, I’d have a profit of 1733 with a marginal return of 9.2%. If they both resolve NO, I’d have a profit of 3459 with a marginal return of only 7.2%.</p>
</blockquote>

<blockquote>
  <p>That was completely counterintuitive to me. I’d always assumed that if the current market probability is farther away from the resolution and you’re making more total profit, the marginal gains from additional bets would be higher as well, but somehow the opposite is true in this case. (The same pattern applies to each market individually as well.)</p>
</blockquote>

<blockquote>
  <p>The markets each have a liquidity probability, which is the initial probability they set when creating the market, and Manifold’s automated market making algorithm is weighted to allocate more of the liquidity to values closer to the initial liquidity probability. In this case, the initial probabilities were set to 65% and about 66.2%, so bets would move the market faster on the NO half, but I’m still very surprised that it would lead to lower marginal rates like this.</p>
</blockquote>

<blockquote>
  <p>It’s all irrelevant though, since profit is profit, and in any case, this is already assuming the best possible scenario. The hard part will be even being the first, and there’s also a big risk that I misread the resolution. The resolution criteria on the affirmative action market is particularly confusing, and I worry that if the decision results are ambiguous, I’ll get it wrong and lose all my money even if I am first.</p>
</blockquote>

<h2 id="selling-out">Selling out</h2>

<p>I tried to sell my other shares in order to free up money to bet on the upcoming Supreme Court decisions, but unfortunately, this turned out to be a terrible idea, because the money I lost by selling my shares early turned out to be vastly more than the marginal profit from putting extra into the first Supreme Court market, and that’s despite the fact that I <em>won</em> on it!</p>

<p>Especially painful was the World GDP market, where I sold half my stake at 67%, only for it to resolve YES (i.e. 100%) just days later. It’s ironic that I managed to lose a bunch of money in that market even though I was <em>right</em> about the eventual resolution when I first bought in.</p>

<p>The best that can be said is that, irrationally afraid of transaction fees like usual, I used limit orders to try to sell my shares, and thus fortunately only managed to sell part of them.</p>

<blockquote>
  <p>I also set limit orders at just above market price for all the markets I bet on to try to sell my bets to free up more money (to cash in at 7.2% if I’m lucky) ahead of the expected Supreme Court announcements on Tuesday. Of course, the problem with limits is that that relies on someone else to actually buy you out, and so far things have only gone the wrong way.</p>
</blockquote>

<blockquote>
  <p>It was also a bit discouraging, since even that total profit of 3459 in the best possible scenario is still less than the amount that Johnny is currently ahead of me, though I’d at least be close. If the markets resolve YES, then I’d only catch up half way even under ideal circumstances, and I’d still require another major stroke of luck or two to have a hope at catching up. And probably, I won’t even get the 1733. The ceasefire windfall at least gave me hope again, but it will still take several more bits of extreme fortune to actually change things.</p>
</blockquote>

<blockquote>
  <p><strong>26.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:37</strong> - …Also Sunday afternoon, Malte Schrodl bought part of my World GDP shares (at 67%). It feels bad to sell them at a loss, but I guess that’s the sunk cost fallacy in action. Other than that, Salem has been remarkably quiet.</p>
</blockquote>

<h2 id="the-waiting-game">The waiting game</h2>

<blockquote>
  <p><strong>28.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:06</strong> - Tuesday morning, I again closely followed the Supreme Court decisions, but it ended at 7:13 with only three decisions released. I was surprised since the 27th was the last day on the calendar, but they later added the 29th. It seems like they’re just going to keep releasing 3-4 decisions a day until they’re done, adding days to the calendar as necessary, and it is impossible to know when the last day will be.</p>
</blockquote>

<h2 id="affirmative-action">Affirmative action</h2>

<p>On the 29th, I successfully managed to be the first to bet on the Supreme Court’s affirmative action decision. However, for some bizarre reason, everyone bet <em>against</em> me, leading to an extremely terrifying two hours while I wondered whether I would finally be knocked out of the contest on a dumb technicality after having come so far against such long odds.</p>

<p>In fact, the experience was so terrifying that I resolved to never bet my entire balance again in order to avoid that fear. I decided to only bet part of my money in the future, so that even if I lost, I’d still be guaranteed third place. (Of course, this was largely only possible because the AA win also gave me a much larger margin for error ahead of fourth place.) I did fudge that limit somewhat (putting 5.1k into the other Supreme Court market the next day, and a bit more during the GDP fight in late July, but I didn’t invest <em>most</em> of my money again until minutes before the end of the contest.</p>

<blockquote>
  <p><strong>29.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:13</strong> - Well the die is cast. Either I’m completely dead on Salem, or I’ll have marginally closed the gap towards second place. The Supreme Court decisions came out faster than normal this morning, and I put all my money down on YES for “Supreme Court Ban Race in College Admissions?”. I was pretty nervous, since there’s always the risk of some gotcha like with the debt ceiling debacle, but based on the resolution criteria, I think it will probably resolve YES. However, I’m especially nervous because Johnny, Malte, and Mark are all betting NO on the market even after the decision was released. I guess either way I’ll find out soon. It’s pretty hard to concentrate on anything right now though and my heart is pounding.</p>
</blockquote>

<blockquote>
  <p>Update: zubby just put in $350 on YES (72-&gt;76%), so I guess that’s a positive sign. Of course I feel like a chump for buying it up to 95% on the assumption that I was racing everyone else for YES votes.</p>
</blockquote>

<blockquote>
  <p>… and now it’s down to 60%. It will be pretty frustrating if this is what knocks me out of Salem after so many months and several turns of extreme luck.</p>
</blockquote>

<blockquote>
  <p><strong>30.06.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:40</strong> - Salem update time. Yesterday morning before 7, I once again opened up my Python script and ran the numbers to determine the optimal bet allocation for all four possible combinations of market outcomes. However, it occurred to me that it was pointless because I wouldn’t actually know both market outcomes at once as the opinions are announced one by one. I decided to use the larger number (i.e. as if the other market resolved NO) to be conservative.</p>
</blockquote>

<blockquote>
  <p>Thus at 7:04, I put in 4715 (68-&gt;89%). I was a bit worried about whether the outcome would actually resolve YES, but I thought it probably would and that I was racing Johnny and zubby to bet. At 7:06, 50P put in $100, and then at 7:09, when it was clear that there were no more opinions that day, I put in the rest of my money, 4354 (90-&gt;95%). Unfortunately, then everyone started betting NO for some reason.</p>
</blockquote>

<blockquote>
  <p>Johnny only put in 170. Malte put in a lot more, but sold part of his stake for a profit later. The big loser was Mark, who kept betting NO the entire time. Interestingly, David Hasset later showed up and bet YES with his free money, which was surprising since he’d barely done anything since getting hammered over the Chicago Mayor election nearly three months ago.</p>
</blockquote>

<blockquote>
  <p>As mentioned, my heart was pounding, and I couldn’t concentrate on anything, so I spent the rest of the morning reading some blog posts while watching the flurry of comments come in, with people arguing about whether the market should resolve YES or NO.</p>
</blockquote>

<blockquote>
  <p>At breakfast, I started thinking of custom card designs and quickly posted one after getting to the office, and thus discovered that it had resolved YES, which was a huge relief. (My custom card didn’t get any comments at all, but that’s a minor disappointment compared to the crushing loss that getting kicked out of Salem would have been.)</p>
</blockquote>

<blockquote>
  <p>At around 9pm yesterday, I checked the standings with my Python script again. The relevant changes since that morning were:</p>
</blockquote>

<blockquote>
  <p>Me: 12089 -&gt; 13448</p>
</blockquote>

<blockquote>
  <p>Johnny: 16919 -&gt; 15962</p>
</blockquote>

<blockquote>
  <p>Malte: 8048 -&gt; 7866</p>
</blockquote>

<blockquote>
  <p>Mark: 9123 -&gt; 6739</p>
</blockquote>

<blockquote>
  <p>% behind Johnny: 40.0% -&gt; 18.7%</p>
</blockquote>

<blockquote>
  <p>Johnny only actually lost around 400 in the market (170 that morning and 227 already on NO) but there were other market movements yesterday, notably the World GDP jumping up to 85%. Likewise, I’d only actually made 1280 in the affirmative action market but also got a minor boost from my remaining shares in World GDP.</p>
</blockquote>

<blockquote>
  <p>It was amazingly good news, since Johnny was now realistically in reach if I just got lucky one or two more times. And even better, Mark took a massive hit and dropped out of contention, and Malte went down a bit too. With the competition farther behind me, it means I can afford to be more aggressive with my betting and still be in 3rd place if I lose.</p>
</blockquote>

<h2 id="my-gdp-blunder">My GDP blunder</h2>

<blockquote>
  <p>Sadly, it’s not all good as I made a stupid mistake then. This morning, I got up to emails saying that the World GDP and China GDP markets had resolved (YES and NO respectively). In all the excitement over the Supreme Court rulings, I’d completely forgotten that the China GDP market was supposed to resolve around now, and should have put my money in for a bit of extra return.</p>
</blockquote>

<blockquote>
  <p>As of this morning, the standings are now</p>
</blockquote>

<blockquote>
  <p>Me: 13448 -&gt; 13544</p>
</blockquote>

<blockquote>
  <p>Johnny: 15962 -&gt; 16114</p>
</blockquote>

<blockquote>
  <p>Malte: 7866 -&gt; 7998</p>
</blockquote>

<blockquote>
  <p>% behind Johnny: 18.7% -&gt; 19.0%</p>
</blockquote>

<blockquote>
  <p>I got a minor boost from my remaining World GDP shares resolving, but Johnny got a bigger boost from his China GDP shares. I definitely missed out there. Of course, in retrospect I also regret selling half my World GDP shares at 67%. And of course I really missed out yesterday morning too, because if I had waited a bit before betting, I could have made massively more money after Malte and Mark jumped in. But there was no way to know that would happen. Oh well.</p>
</blockquote>

<blockquote>
  <p>Anyway, that was a bit disappointing, but I’m still far closer to reaching Johnny than ever before. And it’s now 6:56, so the Supreme Court decisions will be starting in a few minutes again, my best shot at closing the gap. Hopefully the debt forgiveness decision is less ambiguous. I’m also conflicted about whether to go all in or just bet 4000 to be safe (which would keep me in 3rd if I lost), since confronting the possibility of being out of Salem entirely yesterday was really scary. I’ll probably still go all in though.</p>
</blockquote>

<h2 id="student-debt-relief">Student debt relief</h2>

<blockquote>
  <p><strong>07:41</strong> - Well that was interesting, over half an hour of extreme boredom followed by an incredibly wild minute. While the opinions were released faster than usual yesterday, the opposite happened today, with them taking forever to read the 303 opinions, and I so I sat there for over half an hour checking the livestream and getting increasingly bored (I started checking Reddit, etc. in between, but there wasn’t much to read there.)</p>
</blockquote>

<blockquote>
  <p>Around 7:34, they finally got to the student loan cases, and the liveblog announced that the first case was unanimously ruled “no standing”. I decided not to bet, since there were two student debt cases outstanding, but others were not so cautious, and I worried that I’d missed my opportunity.</p>
</blockquote>

<p>Note: I only knew there were two cases outstanding thanks to the liveblog. It was a really good source.</p>

<blockquote>
  <p>At 7:33, Malte bought NO 72-&gt;67%, then zubby dumped in $1000 (67-&gt;39%) and PPPP sold 39-&gt;19% (there were also some trivial bets from 50P mixed in). Then immediately afterward (7:35 by now), zubby sold 20-&gt;31% and Malte bought 31-&gt;38%. I put in $100 on YES (38-&gt;41%) because the liveblog had just announced a 6-3 decision in the second case (but not the outcome), but it was probably a repeal given the votes.</p>
</blockquote>

<blockquote>
  <p>Malte bought 41-&gt;43%, and then I dumped in 3000 (43-&gt;85%), having now had a chance to glance at the decision and confirm. A couple minutes later, I decided to put in another 2k (93-&gt;95%), 50P and zubby having brought it back up to 93%. It’s now at 97%.</p>
</blockquote>

<blockquote>
  <p>Edit: Just as I was writing this, the market resolved YES. So that’s a relief. It looks like I made a total profit of 1582. But more importantly, this seems like the best possible outcome, better than I could have even imagined. The dip down allowed me to make a much larger profit than expected while still betting on YES and only putting in the money I could afford to lose. And since it resolved YES, Johnny lost the $640 he put down on NO this morning before the decisions were released, while still granting me a much larger profit than would have normally been expected had it resolved YES normally. Time to check the standings again.</p>
</blockquote>

<blockquote>
  <p>I’m now only 3.67% behind Johnny! Callooh callay, o frabjous day! I’m now within the margin that I could plausibly make up with smart trading over the next month. With only 17 markets and a month left in the contest, I was worried that I would end up, say, 15% behind Johnny and it would be a tall order to make that up (especially since Johnny will be gaining over time as well). But 3.67% certainly seems doable. I’m sure I’d already be ahead if it weren’t for the debt ceiling debacle, but it’s not healthy to think about things like that, and I’ve been enormously lucky three times over in the last couple weeks, first with the ceasefire bump and then the two SC decisions, so it’s not sensible to curse the few dark spots of my luck, as crushing as it seemed at the time.</p>
</blockquote>

<blockquote>
  <p><strong>17:13</strong> - While it is at least possible for me to overtake Johnny now, it will still be an uphill battle. As of 5pm this afternoon, he is back up to 5.12% ahead of me. Part of that is due to Third Trump Indictment (which I bet NO on and Johnny YES) spiking up to 59% and part of it is that Johnny has a large fraction of his portfolio invested and most of the markets moved closer to 0/100 today as people reinvested their winnings from all the markets that resolved recently.</p>
</blockquote>

<blockquote>
  <p>I simulated what would happen if every market &lt;15% immediately went to 0 (and vice versa over 85), and in that case, Johnny would be 9.79% ahead of me, so that’s a better picture of what I have to beat. I still need some unexpected event to go in my favor, and there are very few opportunities left for that to happen.</p>
</blockquote>

<blockquote>
  <p><strong>21:01</strong> - I went to bed at 11:23 Wednesday night. I set an alarm for 6:10 to make sure I’d have enough time to go through Wanikani and then check the Salem script and calculate the optimal bet allocations before the SC opinions started at 7am, but I ended up not needing it, as I woke up at 6:01/6:08.</p>
</blockquote>

<p>(And of course the Python script thing ended up being completely pointless anyway, as I only realized that morning and explained above.)</p>

<h1 id="july-1-19">July 1-19</h1>
<p><img src="/img/salem2/july1.png" alt="Score graph" /></p>

<p>For one heady moment the morning of June 30th, it seemed like I was about to overtake Johnny and snag second place against the odds, but reality soon set in. I was close after the Supreme Court wins, but still too far to easily pass him, and would require a lot more things to go my way in order to close the gap. It didn’t help that immediately afterwards, I lost money in the Trump Indictment market, widening Johnny’s lead. In fact, I somehow managed to buy NO low and then sell at the peak <em>twice in a row</em>.</p>

<p>I noticed that Johnny had large contrarian NO bets on several markets and concluded that my best hope of catching up to him would be if they all went against him. In particular, I would need Trump to stay off Twitter, and then either ATACMS or Ukraine To Take Major City to resolve YES. Unfortunately, Johnny sold his YES bet on Twitter early, limiting his losses there, and the latter two never happened.</p>

<blockquote>
  <p><strong>04.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:07</strong> - I went to bed at 11:29 Sunday, but soon woke up again and couldn’t sleep… I finally went to bed again at 1:34 and got up at 5:36. I checked Salem Plus as usual and discovered market movements the previous day that should have triggered my bot. It turns out my bot froze all the way back on Friday night, so I had to restart it.</p>
</blockquote>

<blockquote>
  <p><strong>08:26</strong> - I haven’t mentioned how Salem has been going. In short, not well. Saturday afternoon, I again asked Salem for clarification about whether a superseding indictment would count for the “Third Trump Indictment” market, and this time they responded, saying it would count, so I immediately sold my stake (59-&gt;64%). It was pretty painful to take a big loss like that, but I worried that after the Salem Center’s comment, everyone would be rushing to push it up. Instead, it has been mostly bouncing around the 55-&gt;60% range for the last couple days.</p>
</blockquote>

<blockquote>
  <p>As of this morning, Johnny’s lead is now up to 5.69% and if &lt;15% markets are counted as 0, he would be 10.24% ahead. And even that understates the real magnitude, because I’d have to make up the difference using funds that aren’t already invested, so the denominator should be my uninvested money, not the entire portfolio value.</p>
</blockquote>

<blockquote>
  <p>For a brief moment Friday morning, it looked like I might overtake him just through normal trading, but of course that was an illusion and things rapidly slipped out of my grasp again. I’m back to the point where I need to get lucky several times to actually beat him. Fortunately, I am in range where a couple of lucky breaks could still turn things around, but I do have to get lucky.</p>
</blockquote>

<blockquote>
  <p>First off, I need Trump to stay off Twitter. Since I have a large NO bet and Johnny a large YES bet, I have no hope of winning if it resolves YES (unless I somehow manage to get in first when it happens, which is very unlikely without the ability to write a bot, and even if I did, that would barely outweigh Johnny’s profit.). Then I need one of the markets where Johnny has a large NO bet to resolve YES, such as “Ukraine to take Major City” or “Send ATACMS to Ukraine”. (“Third Trump Indictment” resolving NO might work as well - I sold my stake but Johnny still has a sizable YES stake).</p>
</blockquote>

<blockquote>
  <p>But most likely, I’ll just end up in third place. It’s frustrating to be so close and yet not make it, but there are far worse fates. I did get pretty lucky on the Supreme Court markets, even if I’ve been continuously cursing myself for not going all in on the debt relief one, as the extra profit would be critical to closing the gap with Johnny (same with the China GDP market).</p>
</blockquote>

<blockquote>
  <p><strong>05.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>22:33</strong> - On the Salem front, Johnny sold part of his Twitter YES stake this morning (19.5-&gt;16.8%), which presumably improves my relative standing on paper a bit, although it decreases the eventual gain, if as seems likely, it ultimately resolves NO. Also, 50P massively bought up ATACMS today (29.3-&gt;37.5%) today, which should give me a nice relative boost on paper as well. On the other hand, some other markets moved downwards a bit, increasing Johnny’s paper standings. Overall, things have continued to be really quiet. Which is unfortunate when I need a (lucky) upset to take the lead and there is increasingly little time left in the contest.</p>
</blockquote>

<blockquote>
  <p><strong>07.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>08:08</strong> - Afterward, I got on the desktop in order to check the Salem bot script and restart it, as I assumed the morning’s internet outage would have killed it. I discovered that it had actually died all the way back on July 4th at 1:01pm due to some sort of https error.</p>
</blockquote>

<blockquote>
  <p>Meanwhile, still not much on the Salem front. Johnny put 250 more on NO for “Ukraine to Take Major City” on the 5th (32.3-&gt;28.1%) and it has continued to drop (now 24.87%), so that’s bad news. Things have mostly been quiet, but of course no news is also bad news in my position. I just have to pray for a lucky upset on ATACMS, Third Trump Indictment, etc.</p>
</blockquote>

<h2 id="chromebooks-and-covid">Chromebooks and COVID</h2>

<p>On July 8th, two non-Salem events in my life that would play a role in the remainder of the contest coincidentally happened on the same day.</p>

<p>The first is that I caught COVID for the first time and had a high fever for three days, and more importantly, had a persistent cough and thus worked from home for the remainder of the contest in order to avoid spreading it to coworkers at the office. (I’d previously been going into the office two or three days a week.)</p>

<p>The second is that I returned my Chromebook. As previously mentioned, I’d been using my Chromebook as my main computer, but all my Salem stuff was on my Linux desktop. However, when I worked from home, I used the same desk, monitor, keyboard, mouse, etc. with my work macbook, and it was a hassle to have to switch between the two. When I set up the bot, I started leaving my desktop <em>on</em> 24/7, but only plugged in the mouse, keyboard, etc. on the weekends.</p>

<p>However, my new Chromebook had a rapidly dwindling battery life, and in late June, I finally got fed up enough with it to research it online and realized that I just got unlucky with a defective battery and began the return process. Fortunately, it was just under a year since I’d bought it, so I was still able to return it. After a week or two of back and forth with customer service, I put the defective chromebook in the mail on July 8th, and coincidentally first had symptoms of COVID on the way back.</p>

<p>Thus, I was forced to switch to using my Linux desktop for everything. I would unplug it and plug in the macbook every morning before work, and do the reverse every evening after work. Even after the replacement Chromebook came in, I was no longer in the habit of using it, and only used it on the rare occasions when I needed to make a bet on Salem during the workday. I did check my custom Salem Plus website on the macbook frequently, but never bothered to log in to the actual Salem website, which in retrospect would have been simpler than having to get out the Chromebook to make my bets. But that only happened once or twice anyway.</p>

<h2 id="iran-nuclear-deal">Iran nuclear deal</h2>

<blockquote>
  <p><strong>10.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>14:50</strong> - Also, there was some excitement on Salem yesterday, very slightly in my favor.</p>
</blockquote>

<blockquote>
  <p>First off, Noah Lafountain spiked ATACMS from 26-&gt;38% Sunday 15:52. I saw the bot email and bought it down to 34% at 16:15, figuring I could flip NO shares for a quick profit. At first it seemed to fail as Spencer bumped it back up to 37%, but then David bought it down to 30%.</p>
</blockquote>

<blockquote>
  <p>Also Sunday evening, Spencer spiked “Trump back on Twitter” from 16.6% up to 20.6%. A noname got in first, but I bought another $100 NO at 19.35-&gt;18.7%. (It’s now at 15.78%)</p>
</blockquote>

<blockquote>
  <p>This morning (7:40am), PPPP bought $1004 YES on “US GDP Growth 1% or More in 2023 Q2”, spiking it from 72.8-&gt;80.5%. At 10:20am, after seeing that GDPNow’s latest forecast is up from 2.1% to 2.3%, I later put in $100 of YES myself (up to 81.2%).</p>
</blockquote>

<blockquote>
  <p>The most extreme movement came in the “New Iran Nuclear Deal” market though. Sunday at 15:52, Noah Lafountain dumped it from 17.6%-&gt;7.05%. I nervously put $20 down on YES at 16:17, since while it is a longshot, it doesn’t seem that unlikely. I soon regretted my caution, as Johnny sold a large part of his stake, driving it up to 9.1%. This morning, David and some no names also sold out, leaving it at 13.85% currently, so I have made a small profit on-paper.</p>
</blockquote>

<blockquote>
  <p>Lastly, there were a few other minor market movements, some in Johnny’s favor, some against him. For example, “Third Trump Indictment” is now back down to 48.1%. I really regret selling out at 64% now, but hindsight is 20/20.</p>
</blockquote>

<blockquote>
  <p>The end result is that I’m slightly closer to Johnny again now, though not enough to be game changing. At current market values, I’m 4.46% behind, while I’m 9.48% behind with &lt;15% markets zeroed out. A lot hinges on the outcome of a few markets, such as Trump Twitter, ATACMS, Q2 GDP, and Third Trump Indictment. If I can get most of the major uncertain markets where we have opposite bets (or even the same bet but different amounts in the case of ATACMS now) to break my way, I have a decent chance of surpassing Johnny. But a lot could go wrong still as well.</p>
</blockquote>

<blockquote>
  <p><strong>15:27</strong> - Out of curiosity, I wrote some code to see what would happen if all bets were frozen and each remaining market randomly resolved either yes or no according to its current probability. Under those circumstances, I have a 32.2% chance of coming out ahead of Johnny. However, a lot of that is near-certain markets that don’t actually have any chance of failing. If I forcibly set a few already certain markets (Debt Ceiling, Nuclear Attack, Taiwan, Russia Takes Donbas, and Ukraine Ceasefire) to 0, my winning probability is only 30.0%. Still, there’s at least a chance I’ll get lucky.</p>
</blockquote>

<blockquote>
  <p>Also, David just bought NO on ATACMS again at 15:13, bringing it down to 28.0%. This means that I’m now behind Johnny by 4.57% at market rates.</p>
</blockquote>

<blockquote>
  <p><strong>12.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>21:36</strong> - After all that was done, I checked Salem Plus as usual and saw that Noah had spiked ATACMS (24.7-&gt;30.7%) at 8:22pm. I did a quick search and found a news article from almost exactly that time, suggesting that it was still under consideration. For a while, I was hoping for ATACMS to be the thing that let me triumph over Johnny, but recently, I’ve become increasingly pessimistic about it. I’ve still been irrationally reluctant to actually bet on the NO side though.</p>
</blockquote>

<blockquote>
  <p>Anyway, I would have normally jumped on a spike like that, but the article gave me enough uncertainty that I decided to continue staying out of it. Which is a shame as it is now down to 22.8%. Oh well.</p>
</blockquote>

<blockquote>
  <p>Also noteworthy is that Johnny sold part of his Trump Twitter stake yesterday (16.4-&gt;14.3%, it is now at 11.6%). If I were uncertain about the market, I’d be happy that he crystallized his losses, but as it is, it is bad news since I already thought it was almost sure to be NO and even if it wasn’t, I have no chance if it does resolve YES so I have to act under the assumption that it is NO, and this means that Johnny basically just gained the money he got from selling for free compared to the alternative.</p>
</blockquote>

<blockquote>
  <p>I’ve made a sprinkling of minor bets recently, but I doubt it will matter. My main hope now is the GDP market, since while I haven’t checked the numbers, I put 200 on YES (including the previous bet) and Johnny has been betting NO on it a lot.</p>
</blockquote>

<blockquote>
  <p>Also when I checked Salem Plus last night, I also noticed that Noah had sold a bunch of shares in Trump Indictment right before he got ATACMS, bumping it from 45.5 to 51.8 (I threw 100 on NO). One unanticipated benefit of Salem Plus is that it makes it easy to see where people sold shares in order to buy shares in a different market, assuming it happened recently, since those will be the top two markets on the page. For a long time, I could guess that people were selling shares in one market to buy another, but the only way I could actually tell is if I happened to notice the price change manually and manually investigate the transaction history of each website on the incredibly slow and battery hungry official Salem website.</p>
</blockquote>

<blockquote>
  <p><strong>14.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>19:03</strong> - …I got back at 5:30, quickly hooked up the desktop to sell my Iran Nuclear Agreement shares on Salem ($30.55), as I had convinced myself to sell ASAP on the way home.</p>
</blockquote>

<blockquote>
  <p><strong>18.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>06:55</strong> - Well crap. The funny thing is that I’d been planning to check in on the current Salem standings last night, but was too lazy to do so. I think it would have been about the same as it has been for the last week though. I checked Salem Plus again when I woke up several times during the night, but there was relatively little action.</p>
</blockquote>

<blockquote>
  <p>And then when I checked after waking up this morning, Trump Indictment was up to 70%! (The spike began at 6:26, not long before I got up.) Even worse, it went up to 79% and Johnny sold all his YES shares, meaning he has now locked in his profit, and even if it ultimately resolves NO, it will barely help me.</p>
</blockquote>

<blockquote>
  <p>I’m now down to 8.3% behind Johnny at market prices, and with a 20% odds of victory according to the “resolve markets randomly based on current market probability” metric, which is probably really overstating things. Even assuming Trump Twitter resolves NO and Q2 GDP resolves YES, I’ll still be 2.5% behind Johnny. For the last couple weeks, I was just one lucky break away from overtaking him, but now I need multiple miracles to occur again, which is not a good position to be in with only a couple weeks left in the contest.</p>
</blockquote>

<blockquote>
  <p><strong>07:05</strong> - I went ahead and sold my shares (72-&gt;74%), getting just $47 for my original $100. I feel like at this point, I should stop even trying and worrying about Johnny and just accept my likely third place victory, but hope springs eternal. I suppose I can be glad I at least didn’t put any additional money in on NO while it was hovering at 40% for the last week.</p>
</blockquote>

<blockquote>
  <p><strong>07:45</strong> - There was more excitement on Salem from around 7:28-7:31, while I was doing Wanikani, as the Trump Indictment market swung all the way down to 60.8% and back up. It looks like Johnny bet on NO, while 50P and Zubby are still betting YES. Hopefully it resolves YES then, though that would still only put a tiny dent in Johnny’s lead.</p>
</blockquote>

<blockquote>
  <p><strong>19.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>20:12</strong> - …As for the <strong>Salem</strong> side, I had some minor wins yesterday, but also some bad news today. I continued checking Salem Plus periodically throughout the day, including on my work macbook.</p>
</blockquote>

<blockquote>
  <p>At 1:53pm yesterday, Johnny bought $50 more NO on Q2 GDP (80.3-&gt;78.9), so I decided to put in $100 on YES (-&gt;79.7%) when I saw it at 2:03. Yesterday’s GDPNow forecast was up from 2.3% to 2.4%, but I keep worrying that Johnny knows something I don’t. I know in the past, the GDPNow forecasts have often overshot, but not by that much. Still, it’s convenient that he’s betting against it, since him making bets I disagree with like that is the only hope I have of narrowing his lead (assuming I actually win them and he doesn’t sell first).</p>
</blockquote>

<blockquote>
  <p>The big win (relatively speaking) came in the evening, as a no-name bought 200 NO for “Trump the Favorite in Summer 2023” (89.6-&gt;84.5) at 4:45pm. I happened to check at 4:55, again coincidentally ten minutes later, and put down $250 on YES.</p>
</blockquote>

<blockquote>
  <p>The same person also bought $200 YES on “Republicans Favored by Summer 2023” at 4:45, shooting it from 16.07% up to 23.73%. I quickly put down $500 NO, bringing it back down to 18.48%. I was nervous about it though, and quickly regretted my decision, castigating myself for going too deep and not buying 300 or 400 instead. However, it ended up working out for me, as I put down a 15% YES limit, which zubby cashed out for me this afternoon.</p>
</blockquote>

<blockquote>
  <p>Of course, that’s only a tiny profit, but every little bit helps. The problem is that today brought some bad news, as Johnny sold his small stakes in Trump Twitter and Trump Favorite, meaning that’s a bit less money that he won’t be losing now if those markets resolve as I’ve been assuming. Oh well.</p>
</blockquote>

<blockquote>
  <p>Also notable is that zubby has been buying a lot of high probability markets over the last week or so, in order to try to invest his stash with a bit of return at the end, pushing many of the markets closer towards 0 in the process. The last bet was $500 NO on “Russia-Ukraine Ceasefire” this afternoon, bringing it down to 13.4%. I think those bets are at the end though, as he now has only $500 in cash, presumably as much as he wants to keep on hand. It doesn’t really matter much, but it’s good to know, since zubby already being fully invested decreases the rate that the markets are likely to decay further in the coming weeks.</p>
</blockquote>

<blockquote>
  <p>But overall, not much has changed. Overtaking Johnny will be a long shot and will rely on me getting lucky on the Trump Indictment and Q2 GDP markets (and taking the right gambles on those, and not losing any of the near-certain markets, etc.)</p>
</blockquote>

<h1 id="july-20-26-the-final-week">July 20-26 (The final week)</h1>
<p><img src="/img/salem2/july2.png" alt="Score graph" /></p>

<p>Obviously, July 20-26 wasn’t <em>actually</em> the final week of the competition (it ended at midnight on July 31st), but it turned out to de-facto be the final week, as the only two remaining markets with any doubt towards their outcomes both happened to resolve on July 27th.</p>

<p>By late July, I realized that ATACMS wasn’t going to save me. Fortunately, Johnny had started betting NO on GDP for some reason, and that alone was enough to account for a large part of the gap between us. If GDP went YES <em>and</em> I somehow managed to win on Trump Indictment, I’d probably pull ahead, but that is of course easier said than done.</p>

<p>I couldn’t do much on the indictment side, other than check Twitter and hope for the best, but I did have a strategy for GDP. I was really worried about Johnny selling his NO stake early, and so I continually bought more YES shares in order to push up the price, in the hopes of persuading Johnny to buy more NO shares, or at least not sell the ones he already had. And of course, buying more YES shares would marginally increase the winnings on my own account as well. Fortunately, this part worked like a charm.</p>

<p>Additionally in late July, I started checking Salem (via Salem Plus) increasingly frequently, in the hopes of getting lucky and randomly happening to be the first person to see a good deal. By the end, I was checking it every 15-40 minutes throughout the day, depending on how bored/busy I was, and I took advantage of my tendency to wake up frequently during the night by <em>also</em> getting up during the night to quickly check Salem Plus, just in case.</p>

<blockquote>
  <p><strong>20.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:54</strong> - There have been no bets at all on Salem since 5:01pm yesterday, so the standings are the same as before, but I might as well mention them now. I’m currently 7.32% behind Johnny at market prices, although that of course understates his true lead.</p>
</blockquote>

<blockquote>
  <p>On the bright side, I discovered that his NO bet on GDP is much larger than I had thought, currently worth $709 compared to a total gap of around 1126 between us. This means that if it were to immediately resolve YES, I’d only be 2.2% behind him. Of course, history shows that he’d probably sell his stake long before that and take only a minor loss, and that’s assuming it even resolves YES in the first place.</p>
</blockquote>

<blockquote>
  <p>On the other hand, his NO stake on Third Trump Indictment is relatively small, so I won’t gain much from that unless I actively bet on it myself (and manage to get it right <em>and</em> somehow get in earlier on the news than Johnny himself, a triply tall order.) But for now, it seems like all I can do is continue sitting and praying for a miracle.</p>
</blockquote>

<blockquote>
  <p>My “winning probability” assuming markets resolve at random according to the current probabilities is just under 20%. However, that is presumably almost all based on longshots that won’t actually happen. The market probabilities are structurally biased away from 0/100 thanks to limited capital.</p>
</blockquote>

<blockquote>
  <p>If I add/subtract 2% from every market probability to make up for that, my “chance of winning” goes to 18%, failing almost exactly 2%, so it really is a made up number. The problem is that right now, there is no longer any combination markets that are actually plausibly in doubt that would net me the victory. Of course things could still change, but it means that I have to get a lucky break somehow or other, probably multiple lucky breaks.</p>
</blockquote>

<blockquote>
  <p><strong>21.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:27</strong> - Salem-wise, I put down $100 on Q2 GDP Thursday morning. I wouldn’t have normally invested at this time, but I was hoping to goad Johnny into betting more on the NO side (in addition to slightly raising my own winnings in the event of YES). Unfortunately, that was a failure, and it ended up being one step forward, two steps back. At 3:35pm, Malte Schrodl put down $50 on NO, and I immediately put $100 more in when I saw it (4:04pm). I figured it was important to keep the price up to reduce the temptation for Johnny to sell his shares.</p>
</blockquote>

<blockquote>
  <p>…One thing I forgot to mention is that on Tuesday when I made a couple Salem bets during the day, I used my Chromebook. Prior to getting the replacement Chromebook, I would have had to quickly unplug my Macbook and plug in my personal desktop (and then the reverse), which is a huge pain. I’ve only used my Chromebook for a few minor things like that so far though. It’s hard to get back into the old routine once it is disrupted and I’m used to using the desktop.</p>
</blockquote>

<blockquote>
  <p>…Also, around 7:50 while I was working on this journal, I checked Salem Plus once just for the heck of it, and discovered that at 7:30, Malte had dumped Trump Indictment (68.4-&gt;66.4%). That market had been edging down slowly in recent days due to repeated tiny sales from 50P. Ironically, 50P saw the dip first and bought $10 YES at 7:34.</p>
</blockquote>

<blockquote>
  <p>Anyway, I’d been thinking about buying some YES and that dip seemed like a big enough push to justify it, so I put down $25 on YES myself. Especially with the GDP market setback, I’ve been thinking that the only way I can win is if GDP goes YES and I somehow massively profit off Trump Indictment as well.</p>
</blockquote>

<blockquote>
  <p>Signs still point to an indictment coming soon, but there’s also little time left, making it risky. I’d planned to wait until I found positive news of an indictment to pile in on YES, but of course the problem with that is that Johnny is way better at following the news and will almost certainly beat me.</p>
</blockquote>

<blockquote>
  <p>Speaking of which, I checked the Kalshi GDP market last night and the forecast went from 1.5% to 1.7% over the last couple days (between Johnny’s last buy and his sale at near identical price last night) which might explain why he’s dumping it now, even though the Salem market price barely moved. The &gt;0.9% market on Kalshi is now at 87%, for whatever that’s worth. It made me think I’ll have to push up the Salem price even more to stop Johnny from selling further, but I plan to wait a bit more for that, and my firepower is limited. I can’t just risk all my money, because then I’d stand the risk of not even being third place anymore.</p>
</blockquote>

<blockquote>
  <p><strong>08:17</strong> - As far as Salem goes, I am now down to 6.76% behind Johnny at market prices, although the apparent improvement is just an illusion, since it is presumably a consequence of Johnny selling a bunch of GDP shares and bumping up the prices which both improves my standings at current market prices <em>and</em> worsens my <em>actual</em> position assuming the market resolves YES. The also meaningless “win probability” is up from 18% to 20.9%.</p>
</blockquote>

<blockquote>
  <p>Meanwhile, if GDP resolves YES, I’ll now still be 2.71% behind (and that’s despite investing $200 more into it myself). If Trump Indictment also resolves YES, I’d still be 1.58% behind under the current circumstances. Of course, as usual things can always change, with people making various bets at any time. The problem is that the most likely change (Johnny selling more of his shares) is really bad for me, but there’s always the slight chance that I manage to profit handsomely off indictment or some no-namer YOLO-bets and I manage to profit off that.</p>
</blockquote>

<blockquote>
  <p>But in the meantime, there’s basically nothing I can do other than continuing to periodically check Salem Plus and hope I get really lucky and see an actionable bet.</p>
</blockquote>

<blockquote>
  <p><strong>20:42</strong> - On the Salem front, as usual there were a bunch of minor transactions that ultimately meant nothing, and some more bad news at the end. First off, I put down $100 more on GDP (82.8-&gt;83.4%) at 10:54am in an attempt to further discourage Johnny from selling.</p>
</blockquote>

<blockquote>
  <p>I also continued checking Salem Plus frequently throughout the day. It was mostly 50P up to his usual tricks, but zubby also surprisingly stepped in. For some reason, 50P tends to buy small amounts of shares and then sell part of them back soon afterwards. The repeated small sales are presumably due to using the “buy 10 shares button” as they previously explained, but that doesn’t explain at all why they keep seemingly overshooting their intended buy and selling back part of it soon afterwards.</p>
</blockquote>

<blockquote>
  <p>In any case, the first major jump was 50P buying ATACMS up to 17.3% around 12:22. I considered buying some, but decided the jump wasn’t big enough to justify the effort and risk. Just minutes later, 50P sold back part of their shares.</p>
</blockquote>

<blockquote>
  <p>Then, at 1:17, zubby jumped in with $100 YES and 50P sold some then immediately bought more, spiking it up to a high of 22.1% at 2:07, although they’d already sold back down to 20.1% by the time I happened to check Salem Plus. I considered buying in again, but zubby’s involvement made me nervous, and I thought there was a risk it would actually resolve YES.</p>
</blockquote>

<blockquote>
  <p>Later this evening, 50P and zubby sold it back, and it now down to 16.6% again. Zubby also dumped Trump Twitter from 11.1% to 7.9% this evening.</p>
</blockquote>

<blockquote>
  <p>The other main action was in Third Trump Indictment. As mentioned, this morning I saw it go down and bought $25 YES. This evening, 50P sold it some more, down to 65.0% and I hesitantly bought $15 more YES. I got back from the ice cream trip to discover that zubby had dumped it all the way to 48.56%.</p>
</blockquote>

<blockquote>
  <p>That is major bad news, since it means that not only has the market value of my shares declined, but there’s a high chance that Johnny will sell his NO shares and lock in a large profit. I’m also worried that the market will resolve NO now, since my only path to victory relies on it resolving YES next week. And as usual, my decision to panic sell when it originally spiked last week is looking dumber and dumber by the day. I don’t know how I managed to get caught out multiple times in the <em>same market</em> panic selling at a big loss, but it’s going to make it very hard for me to overtake Johnny.</p>
</blockquote>

<blockquote>
  <p>Oh well, I guess I just have to keep trying and hope for the best. For what it’s worth, I’m currently 7.0% behind at market value, 3.0% with GDP=YES and 1.14% if Trump also gets indicted. But the latter is now looking dubious, and in any case, there’s a big risk of Johnny making additional trades. I really wish I knew what zubby was thinking as well.</p>
</blockquote>

<blockquote>
  <p><strong>23.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>10:24</strong> - Friday night, I went to bed at 11:41. I slept comparatively well, only waking up briefly around 4:37, IIRC. I checked Salem Plus, but fortunately no rude surprises from Johnny this time, just Malte Schrodl dumping Trump Indictment at 4:21am (down to 45.8%)</p>
</blockquote>

<blockquote>
  <p>I woke up at 6:22/6:27 Saturday morning. Saturday morning, Malte did a bunch more transactions, pushing “near certain” markets a bit further towards 0. Nothing important, although it is a little disappointing, since my path to victory was relying on being able to invest my money in near certain markets to make up the last percent or two once victories on GDP and Trump Indictment got me back within striking distance and the more people who buy into them first, the lower the margins remaining will be. Still, it barely matters compared to the major upsets of previous days, and Salem has been very quiet since then.</p>
</blockquote>

<blockquote>
  <p>…I didn’t make it to bed until 11:52 Saturday night, and unfortunately had considerable trouble sleeping. …I also vaguely remember waking up other times, including around 4:30ish, which seems to have become an almost nightly ritual for me lately. This time however, I didn’t even bother getting out of bed and checking Salem Plus most of the times I woke up, which is just as well, since there were literally no transactions overnight this time.</p>
</blockquote>

<blockquote>
  <p>As far as Salem goes, I put another $100 down on GDP last night (84.0-&gt;84.5%) to further slightly increase my potential winnings and discourage Johnny from selling. Kalshi is still at 87%. I was really worried Johnny would sell on the Trump Indictment market, but he hasn’t done anything yet. Of course, I’m also worried that the market will end up NO. In order to win, I need everything to go right for me.</p>
</blockquote>

<blockquote>
  <p>This morning, there was brief excitement when a no-name bought up Trump Indictment (46.5-&gt;56.6) at 6:27, followed by zubby buying it back down to 50.0 at 7:04. But other than that, the markets have been very quiet the last couple days, and the few transactions that did occur were just stuff like 50P buying and selling tiny bets.</p>
</blockquote>

<blockquote>
  <p>Oh, I guess there’s one other thing worth noting. Friday evening, zubby suddenly dumped Trump Twitter from 11.07% down to 7.92%. I put in a YES limit at 7%, hoping to free up capital, since the other markets were still in the 12-15% range, but so far no such luck (it’s currently 7.71%).</p>
</blockquote>

<blockquote>
  <p><strong>24.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:35</strong> - I went to bed at 11:35, and again had trouble sleeping… I do remember waking up around 4:11 and checking Salem Plus. Nothing of note had happened, just some minor purchases in several markets by 50P at 3:40am, but I had trouble sleeping again anyway somehow, constantly waking up from bizarre dreams about Salem. I think I eventually got up once or twice more to check Salem Plus, but nothing further happened.</p>
</blockquote>

<blockquote>
  <p>Anyway, I woke up at 6:16/6:25 this morning.</p>
</blockquote>

<blockquote>
  <p>As for Salem, it has been frustratingly quiet. Last night I checked Kalshi again and saw that &gt;0.9% was now up to 91%, so I put 200 more on YES (84.5-&gt;85.6%). So far, there’s fortunately been no sign of activity from Johnny. I’m more surprised that he hasn’t sold his shares in Trump Indictment or “Republicans Favored by Summer 2023?”, but I’ll take what little good news I can get. (Hopefully I didn’t just jinx it).</p>
</blockquote>

<blockquote>
  <p>Also, one of 50P’s 3:40am purchases bumped Trump Twitter back up to 8.086%, meaning I can now place limits at 8%, so I replaced my $64 7% YES limit with a $73 limit at 8%.</p>
</blockquote>

<blockquote>
  <p>The real problem though is that everything hinges on Trump Indictment. It’s at 49.2% right now, almost a coin flip. If I knew how it would resolve in the end, I could make a killing either way. I haven’t actually checked the numbers, but I’m guessing that if I magically knew the outcome and beat heavily on it, that alone would be enough to overtake Johnny (assuming the other markets go my way of course). Meanwhile, if I don’t get it right, I’ll have no chance of winning, no matter what else happens (barring some extreme lucky break). It’s a bit frustrating, since I have the possibility of winning still, but there’s nothing I can actually do. Well other than keep checking the markets for the increasingly slim chance of a YOLO whale that I can profit off of.</p>
</blockquote>

<blockquote>
  <p><strong>08:06</strong> - I did some calculations, projecting my cash balance assuming that GDP resolves YES, and comparing it to the difference in scores between Johnny and I assuming all other markets resolve as expected. Because after all, being 3% behind is useless in a vacuum, since Johnny has a lot invested in markets that will continue to tick up, and I have to make up that gap using only my uninvested funds (including winnings from GDP).</p>
</blockquote>

<blockquote>
  <p>If Trump Indictment goes YES (and nothing else changes), the difference would be 14.47% of my uninvested cash, which would be impossible to make up since the remaining markets are mostly in the 10-12% range and will continue to go down over time. If Trump Indictment goes NO, the difference would be 19.55%, which is extra impossible.</p>
</blockquote>

<blockquote>
  <p>So not only do I have to get really lucky on the coin flip (in addition to winning GDP, etc.), but I have to somehow call it in advance and make a large profit on it to even have a hope of catching up. (Well, there’s always the longshot possibility of ATACMS going YES, but I don’t think that’s going to happen now and I certainly can’t count on it.)</p>
</blockquote>

<blockquote>
  <p>Anyway, that’s pretty disappointing to learn that my odds are far worse than the market value ratios had made it seem. Oh well.</p>
</blockquote>

<blockquote>
  <p><strong>08:19</strong> - I just put $100 more down on GDP and “Republicans to be favorites in 2023”, bringing the ratios down to 14.31%/19.44%. But of course that’s just pointless fiddling around the edges that will be swamped by whatever happens in the Trump Indictment market or any adverse actions that occur, and there’s barely any point in even bothering. (Note that the latter market was at 13.93%, so that was actually below par, especially after transaction fees, but I figured I should put a bit in anyway, because that’s the best offer available right now (apart from GDP and Trump Indictment) and because Johnny has a few YES shares there and pushing down the price makes him less likely to sell.)</p>
</blockquote>

<blockquote>
  <p><strong>18:07</strong> - Well I guess I finally got my wish for players to YOLO bet on Salem, just not in a way that I was able to actually profit off of. The day started fairly quiet, just with Jack jumping in at 11:21am to buy down some markets a bit, followed by Malte at 1:03.</p>
</blockquote>

<blockquote>
  <p>At 1:12 (well really a series of spam bets from 1:12-1:15), 50P bought Trump Indict up to 54.3%, $10 at a time like usual. I noticed this relatively quickly, but didn’t have any firm opinions to merit trading against it, especially since I was still praying that the market would actually resolve YES. 50P then partially sold it back at 1:43 for some reason (53.1%), as 50P tends to do.</p>
</blockquote>

<blockquote>
  <p>The real action, however, happened at 2:19pm, when PPPP suddenly spiked it 53.1-&gt;63.8%. I hadn’t been checking Salem Plus that often, perhaps every 15-40 minutes, depending on how bored I was at the time, but by pure coincidence, I happened to check at 2:20, and thus saw it right after it happened.</p>
</blockquote>

<blockquote>
  <p>I considered whether to buy NO on indictment, but decided to continue staying out of it. A minute later, I noticed that PPPP had sold $507 of GDP in order to fund their bet (as well as a bit of ATACMS and Trump Twitter, it looks like), so I quickly put down $500 YES on GDP, bringing it almost all the way back up to 86%.</p>
</blockquote>

<blockquote>
  <p>I was shocked when I refreshed Salem Plus immediately afterwards and discovered a betting frenzy in the indictment market. PPPP’s bet there was at 14:19:15, and at 14:21:35, barely two minutes later, Johnny bought some NO in the market, followed by zubby at 14:21:35, and then Johnny again at 14:21:49.</p>
</blockquote>

<blockquote>
  <p>It was shocking on multiple levels. For one thing, Johnny hadn’t done anything in days, and I’d been hoping that he was pretty much checked out at this point, so seeing him pounce on a bet in two minutes was dismaying. It was also dismaying because it meant that his bot is still active and he will easily sweep any profit opportunities that arise (assuming they trigger his bot). There was one that he missed last month, so I’d been hoping that his bot was no longer working or something, but no such luck. My theory is just that he had the threshold set high enough that the one last month didn’t trigger it, but if so, that means it would require a very specific kind of profit opportunity for it to even be possible for me to snag the prize.</p>
</blockquote>

<blockquote>
  <p>And of course, it also shows that zubby was hot on his heels with his own bot. I’d only seen zubby act with such speed once before (not counting the pre-bot time he just got lucky), so I’d assumed that he’d given up on the bot or something. It’s disheartening to see that they both still have bots and they’re both way better and faster than my bot. Of course, I wouldn’t have acted on this anyway. due to indecision over the fair value of the indictment market, but it’s still a bad sign.</p>
</blockquote>

<blockquote>
  <p>For reference my own GDP bet was at 14:22:09, <em>after</em> their bets, though to be fair, it took me a minute to even notice that the GDP market was down. And that’s despite me getting incredibly lucky on the timing and just happening to check Salem Plus at the right time.</p>
</blockquote>

<blockquote>
  <p>That wasn’t all though. I checked Salem Plus again around 2:55 and discovered that I’d just missed another bout of excitement.</p>
</blockquote>

<blockquote>
  <p>At 14:53:06, a no-namer (DfromBham) yolo’d even more (973, compared to 547 from PPPP earlier) into indictment, spiking it from 54.3 to <strong>70.9%</strong>! And then just seconds later at 14:53:28, zubby bought it back down to 60.7% (followed by another buy from Johnny at 14:56:49, the slowpoke).</p>
</blockquote>

<blockquote>
  <p>I couldn’t believe it. Zubby somehow managed to bet only 22 seconds after DfromBham. I wouldn’t have been able to manage that even if I had happened to check Salem at the exact right time. Heck, even my <em>bot</em> only checks Salem every 15 seconds, and there’s a delay of several seconds before the server returns updated data as well.</p>
</blockquote>

<blockquote>
  <p>I left a comment, and zubby replied “Just running a page monitor and was at my computer.”, so I guess that explains that. Maybe I should consider modifying Salem Plus to autorefresh and then leaving it open onscreen somewhere all the time. Of course, that would probably cause it to drain battery rapidly, like the actual Salem website does, but that wouldn’t be a problem if I only use it on my desktop and macbook. Of course, screen real estate would still be a big limitation, plus I’d have to actually implement that. And even then, it would probably take me more than 22 seconds just to get out my Chromebook and actually make the bet, let alone make the decision to do so.</p>
</blockquote>

<blockquote>
  <p>Lastly, DfromBham also sold some markets to fund their big bet, in particular selling 319 of GDP. I quickly put yet another 100 down on GDP, but that only brought it back up to 84.8%. I’m nervous to put in more though, because I’m down to only $9098 in uninvested cash. I was hoping to stay above 9026, because that’s how much Connor has, and thus keeping more than that in cash would guarantee I stay above him no matter how perversely the markets resolve, and hence nearly guarantee me third place at worst. But I suppose there’s not that much risk of market upsets, and I’ll have to take more of a gamble if I want to overtake Johnny.</p>
</blockquote>

<blockquote>
  <p>Anyway, the silver lining of all this is that it meant Johnny put a lot more down on NO for Trump Indictment, which means that the outcomes are a lot more polarized. He’ll make a killing if it resolves NO, and lose a lot if it resolves YES, and thus I have a decent chance of overtaking him if only that somehow happens.</p>
</blockquote>

<blockquote>
  <p>Using the same methodology as this morning’s numbers, the afternoon’s chaos resulted in the uninvested cash ratio to Johnny changing to 9.59% YES/22.84% NO (compared to 14.31/19.94 this morning).</p>
</blockquote>

<blockquote>
  <p>However, I realized there were two mistakes in the original calculation. First, I forgot to include the (negligible) winnings from indictment as investable cash in the YES scenario (dropping the ratio from 9.59 to 9.54%). More importantly, I forgot to subtract Johnny’s adjustment.</p>
</blockquote>

<blockquote>
  <p>Ironically, Johnny was the one player whose adjustment I was unable to nail down exactly (it’s either 847.7 or 852.8). To be conservative, I’m using the lower figure. This brought down the ratios to 1.951%/15.20%. So if the indictment somehow comes down in time, I’ll be well within striking distance, while if it resolves NO, he’ll be out of shot, but tantalizingly close. (The current best market price is 13.2% on Russia-Ukraine Ceasefire, but there are also transaction fees, and more importantly, the market prices go way down when you (or anyone else) buy them, so 15% is definitely still impossible, barring surprises.)</p>
</blockquote>

<blockquote>
  <p>Also, PPPP cashed out a bit of my Twitter shares at 8% while selling to fund their bet.</p>
</blockquote>

<blockquote>
  <p>Anyway, it’s now 6:39, so I just spent a whole 32 minutes just talking about the afternoon’s Salem excitement. At least the non-Salem news today should be shorter.</p>
</blockquote>

<blockquote>
  <p><strong>18:42</strong> - P.S. zubby previously sold a bit of their indictment NO stash at 15:51 and at 16:18, and sold a bit more at 18:31, while I was writing this. (Market price now up to 61.4%). I guess it’s good news, since it means that zubby thinks that Johnny is overconfident on the NO shares. Johnny never sold his even when it dipped below 50% and bought more NO shares as low as 58.2% this afternoon.</p>
</blockquote>

<blockquote>
  <p><strong>25.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:30</strong> - …After Wanikani this morning (and brushing my teeth), I modified Salem Plus to update the data in the background every 15 seconds. I didn’t program it to have any obtrusive indicators of new data though, so I’ll still have to just happen to notice the changes while looking at it, but it’s better than nothing. As far as Salem goes, I put 100 more into GDP last night, and there have been no other transactions at all since zubby’s little sale at 6:30pm last night. Today’s probably going to be a volatile day though, since either Trump gets indicted, or the chances go down significantly.</p>
</blockquote>

<blockquote>
  <p>…Anyway, it’s now 7:58, so all that ranting took almost half an hour. In the past, I would have tabbed over to Salem Plus and refreshed it, but now I can just glance over and see it hasn’t changed at all, so that’s nice.</p>
</blockquote>

<blockquote>
  <p><strong>22:18</strong> - The new Salem Plus worked reasonably well, though it still has some minor issues. However, today turned out to be pretty quiet anyway, especially compared to yesterday.</p>
</blockquote>

<blockquote>
  <p>The biggest action was early in the morning, when Spencer Henderson bought $214 NO on GDP, pushing it down to 79.8%, despite my limit. I quickly bought 200 more YES, bumping it back up to 81.3%. That’s still much lower than it’d been before, but fortunately, Johnny doesn’t seem particularly interested in selling (knock on wood). Also, I had previously set a 100 YES limit at 82% back when I first started manipulating it upwards, which Spencer blew through this morning, so I effectively bought $300 YES this morning.</p>
</blockquote>

<blockquote>
  <p>Other than that, there were a few minor buys, pushing near-certain markets further down (or occasionally up slightly, when people sold one to buy another). At 2:01, 50P sold a tiny bit of Trump Indictment. The only other big action was at 7:54pm when Stevie Miller bought 50 NO on Indictment, pushing it down to 59.8%.</p>
</blockquote>

<blockquote>
  <p>Overall today, I had some minor good news on the GDP front, in the sense that I was able to buy shares at a slightly higher margin and Johnny still hasn’t sold any, but bad news on the indictment front. It really seemed like they were going to indict today, but instead the grand jury didn’t even meet today. There’s still a good chance they do it on Thursday, but it’s less certain than it seemed yesterday, when I’d really gotten my hopes up.</p>
</blockquote>

<blockquote>
  <p>Anyway, this evening, I did some calculations to try to figure out what would happen if I split the difference between the YES and NO scenarios on indictment by buying a bunch of NO shares myself, so I’d have the same relative position either way. It was hard to calculate exactly, particularly because it turns out that Johnny has a YES limit at 50%, and thus buying NO shares at the margin would also result in him selling some, magnifying the effect. Also, Stevie tanked the market while I was working on this, annoyingly forcing me to redo the calculations.</p>
</blockquote>

<blockquote>
  <p>In any case, I estimated it would take a buy of $600-700 NO, and I’d have a margin of 7% to make it up either way. 7% is possibly doable, but it would be really tough. Still, I wasn’t planning on actually following through, I just calculated it out of curiosity. It’s not something that can really be estimated in advance, because no matter which way the market goes in the end, some people at least will make a huge profit or loss on it.</p>
</blockquote>

<blockquote>
  <p>For example, if the indictment does come down, the market will spike before resolution, and whoever breaks the news first will make a killing (hopefully me, rather than Johnny), with people coming later still making a small profit. Meanwhile, under the assumption that it does resolve NO at the end, it would be by far the most profitable market to do so, at 60% compared to only 12.5% for the best of the near-certain markets (they keep going down because people who aren’t me just have to go and invest in them.) :( And that means that the calculations about what kind of final margin could be overcome would be hopelessly skewed by the question of who invests how much and when in the indictment market. Still, it was interesting just to see the numbers.</p>
</blockquote>

<blockquote>
  <p><strong>26.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>19:59</strong> - …As for Salem, I put another 100 on GDP down last night. Under normal circumstances, I would have waited for the final GDPNow report this morning, but the same is true of all my previous bets. I was already so heavily invested in the market that there’s no point in trying to hedge my bets and no plausible information that could actually change my strategy. (As it turned out, the final GDPNow forecast was unchanged at 2.4% anyway.)</p>
</blockquote>

<blockquote>
  <p>Anyway, today was mostly quiet, just the usual occasional minor buys, with one major exception. Just after midnight, a no-namer bought 50 YES on GDP, and then at 2:12pm, zubby bought 549 YES (82.4-&gt;85.5%).</p>
</blockquote>

<blockquote>
  <p>It’s funny because since July 11th, I’d been the only person to buy YES shares. The only other YES bet at all was that one time Johnny sold part of his NO shares. Other than that, I’ve been repeatedly buying YES these last two weeks while other people would throw out the occasional NO bet. It’s so weird to see people suddenly buy YES today for a change, and two different people at that.</p>
</blockquote>

<blockquote>
  <p>It was a bit annoying since it meant I would get a lot less profit off of my final YES buys tonight, but on the other hand, I guess it’s nice to have help keeping the price high to reduce the risk of Johnny selling, and the vote of confidence from zubby.</p>
</blockquote>

<blockquote>
  <p>This evening, I put in 500 more on YES (85.5-&gt;87.8%), netting a potential profit of only $69 over 500. But that’s still a lot better than nothing, especially when the margins are so close.</p>
</blockquote>

<blockquote>
  <p>I was originally planning to leave it at that. I’d already dipped slightly past the Connor cash limit. I’m still guaranteed to stay ahead of him even if the biggest markets (Ukraine Ceasefire and GDP) both go against me, but no longer if every market somehow goes against me. But that’s not a realistic concern, and every little bit helps when trying to catch up to Johnny.</p>
</blockquote>

<blockquote>
  <p>In fact, I’m planning to put more in later after running the script again this evening and realizing how close we are. Following my last purchase, I would only be around $40 behind Johnny if GDP resolves YES and nothing else changes. The actual margin ratio would still be higher because I also have to make up the margin from all his near-certain bets with my own in order to stay ahead of him at the end of the contest. But it occurred to me that this puts in sight an intermediate goal - to simply get ahead of Johnny on the leaderboard at all tomorrow morning, even if it is only temporary. That would be worth a lot of bragging rights, even if I ultimately failed (most likely due to losing on indictment).</p>
</blockquote>

<blockquote>
  <p>Anyway, I guess tomorrow is the big day with Salem. In just a little bit, it will all be over. I’ll find out if I won on GDP or am out of the running. And most likely we’ll also find out if Trump is going to be indicted tomorrow morning. If he doesn’t get indicted tomorrow, he could theoretically still be indicted before August, but it would be much less likely, so tomorrow is a pivotal day for both remaining uncertain markets.</p>
</blockquote>

<blockquote>
  <p><strong>22:43</strong> - Well, here goes nothing. I just put one last $500 down on GDP (87.8-&gt;89.5%), with a potential $57 profit. The marginal profit isn’t great, but every little bit helps. Assuming no other transactions happen before tomorrow morning (admittedly a big if) and GDP resolves YES, that should be enough to temporarily put me ahead of Johnny. Also, I happened to notice just now that zubby and Johnny have nearly the exact same number of NO shares on Trump Indictment. It’s probably coincidence, but it made me wonder if zubby deliberately sold the extras in order to match their positions.</p>
</blockquote>

<h1 id="july-27th-decision-day">July 27th (Decision Day)</h1>
<p><img src="/img/salem2/july3.png" alt="Score graph" /></p>

<blockquote>
  <p><strong>27.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>04:04</strong> - I went to bed at 11:33, and as usual, woke up several times during the night and checked Salem Plus each time, just in case. Nothing happened until around 3:30am, when I woke up for what would normally have been very briefly.</p>
</blockquote>

<blockquote>
  <p>This time however, I decided to get out of bed and check Salem Plus just in case, and unusually, there had been a flurry of activity. At 1:41, Johnny bought 80 NO on GDP, then sold 43.9 of YES on Republicans Favored at 2:46. Meanwhile, at 2:48 and 2:55 respectively, 50P and Malte Schrodl randomly bought YES on Trump Indictment, leaving it at 62.6%. (50P also sold $2 of Trump Twitter, not that that matters at all.)</p>
</blockquote>

<blockquote>
  <p>Johnny finally selling his Republicans Favored shares was unfortunate, but more than made up for by him deciding to buy even more NO shares on GDP. And the increased market price on Trump Indictment also flatters my relative position, and thus if GDP resolves YES, I’ll now have a much more comfortable (temporary) lead over Johnny, around $243.</p>
</blockquote>

<blockquote>
  <p>Anyway, I quickly went back to bed, but unfortunately, despite constantly trying to force myself to… not think about Salem, the excitement had still been enough to render me incapable of sleeping. At 3:56, I gave up and got on the computer, did a JPDB session, then wrote this. Now it’s 4:13, and I still have no idea how I’m going to get back to sleep again. (No further transactions on Salem since 2:56am.)</p>
</blockquote>

<blockquote>
  <p><strong>05:51</strong> - I ended up spending quite a while on the computer. …I finally went back to bed at 5:07, and even though Salem was now far removed from my thoughts, it was still hard to fall asleep and in any case, I quickly woke up again at 5:21 and again at 5:35. I stayed in bed, trying to fall back asleep, but 5:42, I gave up and got up to see how I did on GDP. I still wore my orange glasses though, in the hope of that making it easier to fall asleep later this morning, since I’m likely going to be very sleepy.</p>
</blockquote>

<blockquote>
  <p>Anyway, the good news is that I won! I immediately went to the leaderboard page and took a screenshot of myself now being in 2nd place.</p>
</blockquote>

<blockquote>
  <p>Then I tried to figure out what to do about Trump Indictment, and whether I could hedge my bets by buying NO to ensure that I came out on top either way, now that I had a small lead over Johnny. However, his 50% YES limit still made it too complicated to try to figure out, and in any case, I reasoned that there will be a lot of volatility which would make a mockery of my attempts to hedge, so I wrote this instead.</p>
</blockquote>

<blockquote>
  <p>Ironically, just as I was writing this, there was a sudden burst of volatility at 5:53. It looks like Mark bought a huge amount of NO tanking it from 62.6% to 50%, where Johnny had his limit and cashing out most of Johnny’s limit. Then 50P bought a bunch of YES, zubby sold some NO, and 50P bought more. And then at 5:57, just as I was writing this, Mark bought more NO and zubby sold more NO. Also, Mark just bought a bunch of NO on “Republicans Favored by Summer”.</p>
</blockquote>

<blockquote>
  <p>Anyway, it looks like Trump Indict is currently at 56.8%, but seemingly every time I write about it, it changes. 50P is currently buying more, bit by bit as usual. And I have no idea what the positions even are, now that Johnny’s mostly been cashed out, although it is bad news since it means he locked in a profit. Oh well. It sure is ironic though that everything went to chaos right after I considered buying/selling but didn’t. It’s a real shame I didn’t sell my YES shares at 62 at least though.</p>
</blockquote>

<blockquote>
  <p><strong>06:04</strong> - As soon as I said that, 50P stopped buying, and it quieted down again for now. I noticed that Mark also bought NO on a bunch of other markets. Presumably this is the thing where he got a bunch of money from the GDP resolution and immediately decided to reinvest it. Shame he decided to put so much on Trump Indictment.</p>
</blockquote>

<blockquote>
  <p>I thought about buying, say, 200 NO to try to hedge my bets, which wouldn’t keep up with Johnny if it does go NO, but would at least lower the amount I’m behind by. But it doesn’t really seem worth it to me. I think I just have to wait and see how the indictment goes and hope that I manage to profit off it (and profit off it more than Johnny does). But in any case, I managed to get ahead of Johnny on the leaderboard, at least for a little while, which is a huge achievement by itself, and something I never expected to happen. I’m actually still ahead of him for now, but just barely, thanks to swing on Trump.</p>
</blockquote>

<blockquote>
  <p><strong>06:12</strong> - At 6:09, another burst of activity began, still ongoing, where some no-names as well as Johnny made large NO bets on various near-certain markets, and one no-name also bought 300 NO on indictment (followed by 100 YES from 50P). It’s annoying that this means there will be a lot less profit opportunity left in the near-certain markets, but it’s really going to all come down to indictment anyway. For now, I just have to wait for the smoke to clear (also 50P just bought another 99 while I was writing this.) It sure is funny how I seemingly woke up early enough to beat the huge rush as people got up in the morning and started investing, but my being early didn’t actually help me at all, since I had no idea what to do about it, or what other people were going to do or when.</p>
</blockquote>

<blockquote>
  <p><strong>06:34</strong> - Well this is weird. I just ran my script again and it now shows that Johnny should be ahead of me, by about $5. Since the uncertainty in his adjustment is only about 5 (i.e. +-2.5), he should be ahead of me either way. However, when I go to the leaderboard, it still shows me in 2nd, no matter how much I refresh it. I guess this means that despite all the data and effort I put into it, my adjustment values still aren’t quite right, although I’m not sure how that could have possibly happened, since it was pretty locked down. Oh well, it’s a good thing the discrepancy seems to be in my favor.</p>
</blockquote>

<blockquote>
  <p>Also, it sounds like the grand jury is at least meeting today, so that’s a somewhat promising sign.</p>
</blockquote>

<blockquote>
  <p><strong>07:05</strong> - Well I just officially gave up on wearing the orange glasses and going back to bed at some point. It’s pretty late now, and there’s no way I’d be able to sleep with all the Salem excitement anyway. Right now, it feels like I have to keep watching the markets and Twitter and so on in the hopes of jumping on any indictment news. But for now, I plan to fix some of the previous bugs in Salem Plus, like the fact that the background refresh doesn’t update the market prices, meaning you have to hard refresh the page to see the current market prices. It’s a bit late now that the competition is practically over, but I might as well.</p>
</blockquote>

<blockquote>
  <p><strong>07:12</strong> - That turned out to be a trivial fix. Now I guess I’ll try to study Japanese for a while to pass the time.</p>
</blockquote>

<blockquote>
  <p><strong>07:26</strong> - P.S. Around 6:49, I invested 2000, using my bet allocation script to distribute it optimally between all the remaining unresolved non-indictment markets (which involved bets in quite a few markets since they’re so even now). And then another 2000 around 7:21. It is a risk, but I figured if I’m going to do that, I might as well do it now while I still can. I really regret not doing it earlier this morning before the others bought down the markets a bunch. In fact, right at 6:48 while I was doing the original calculation, a no-name bought down one market a bunch, forcing me to redo the calculations.</p>
</blockquote>

<blockquote>
  <p>Anyway, I left some money on the table there, and my “NO” ratio is back up to 11%, which is obviously unachievable when my purchases brought down the maximum market price to 9.5%. But hopefully that won’t happen anyway, or if it does, I’ll manage to profit off of it. It’s still all going to come down to the indictment, but I figured I should at least try to eke out a little margin where I can.</p>
</blockquote>

<p>Here are my bets from the first round of 2000 using the optimal bet allocation script. Note that the final market prices are slightly different in the different markets (ranging from 10.10% to 10.20%).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2023-07-27 06:48:17 Russia-Ukraine Ceasefire by 7/31/2023?
  $196 for 216.650 NO shares (market price 10.75% -&gt; 10.16%)
2023-07-27 06:48:35 New Iran Nuclear Deal by End of July 2023?
  $237 for 262.168 NO shares (market price 10.90% -&gt; 10.14%)
2023-07-27 06:48:55 Chinese Military Action against Taiwan?
  $59 for 65.127 NO shares (market price 10.48% -&gt; 10.19%)
2023-07-27 06:49:13 Recognition of the Taliban by End of July 2023?
  $40 for 44.118 NO shares (market price 10.31% -&gt; 10.20%)
2023-07-27 06:49:33 Bolsonaro Kicked out of the US?
  $221 for 244.296 NO shares (market price 10.76% -&gt; 10.16%)
2023-07-27 06:49:58 No-Confidence Vote on McCarthy?
  $413 for 457.772 NO shares (market price 11.31% -&gt; 10.11%)
2023-07-27 06:50:19 Biden the Favorite in Summer 2023?
  $355 for 393.126 YES shares (market price 88.88% -&gt; 89.88%)
2023-07-27 06:50:35 Send ATACMS to Ukraine?
  $464.708716906 for 515.300 NO shares (market price 11.42% -&gt; 10.10%)
</code></pre></div></div>

<p>You might naively expect that the optimal bet allocation would involve buying each market so the final prices are the same. However, this is actually not the case due to the way the transaction fees are calculated. Transaction fees are calculated based on the <em>final</em> market price after your bet, or more precisely, what the final price would be if there were no fees, and the <em>same rate</em> is applied to your <em>entire</em> bet.</p>

<p>This means that the marginal $1 increasing the size of a bet profits you not just from the additional profit at the marginal market price, but <em>also</em> by very slightly reducing transaction fees on the <em>rest</em> of the bet. This means that the optimal bet allocation involves <em>overshooting</em> on market price slightly, with the difference larger the higher the original price was (and thus the larger your bet). Fortunately, I had a script to calculate that all for me.</p>

<p>Of course, none of this <em>really</em> matters, since the differences involved are extremely tiny, but I figured it was worth pointing out anyway, just due to the interesting way the math works out.</p>

<blockquote>
  <p><strong>12:20</strong> - Well crap, so much for that. I had trouble focusing on anything all morning, desperately waiting for news about the indictment. Around 11:36, Johnny bought down to 54% with a limit order, which 50P and zubby traded against, racking up his leverage.</p>
</blockquote>

<blockquote>
  <p>My stomach jumped when I saw it suddenly go from 54% to 33%, as 50P, who had been buying it all morning, mass sold at 11:57:39. I didn’t see any news on Twitter or Google, and quickly got out the Chromebook and bought 50 YES, hoping it was a dumb trade.</p>
</blockquote>

<blockquote>
  <p>Johnny got in first though, selling at 11:57:53 (and locking in yet another huge profit), so my buy at 11:58:18 went from 38.5-&gt;39.9%. At 11:58:23, zubby bought 256 NO, followed by 100 YES from 50P 30 seconds later, and then nothing.</p>
</blockquote>

<blockquote>
  <p>Ordinarily, I would have bought a lot more, assuming it was a big profit opportunity, but the fact that zubby and Johnny both seemed to think the 30s were a fair price, and in particular the fact that they weren’t buying it up themselves when they’re so much faster than me about such things gave me pause, so I stayed out. I soon found messages on Twitter saying that a clerk had reported that no indictment was filed today.</p>
</blockquote>

<blockquote>
  <p>I don’t know what the numbers look like now, but I don’t have to check to know they’re really bad for me, especially after Johnny bought a lot more NO at 54% this morning, and my foolish YES buy. At least I didn’t go in more than that, I guess. There’s still a slight possibility of a sealed indictment announced tomorrow or something, but for now, it seems that my hopes of finishing in second are dead.</p>
</blockquote>

<blockquote>
  <p>…Oh well, at least I can stop worrying about refreshing Twitter for news now. It will be hard to stop thinking about the Salem disappointment for a while, but I’m sure I’ll get over it eventually.</p>
</blockquote>

<blockquote>
  <p><strong>15:21</strong> - I pretty much gave up hope on Salem, so my jaw dropped slightly when I happened to notice at 3:20 that Trump Indictment was back up to 62.6%. It looks like zubby started massively buying it up at 3:16, with 50P selling a bit in response. In fact, zubby is currently selling shares in other markets (e.g. Ukraine ceasefire) and even just now, it is up to 70%. I feel like I should do something, but I have no idea what is going on.</p>
</blockquote>

<blockquote>
  <p>Update: Now 54.3%, courtesy of 50P.</p>
</blockquote>

<blockquote>
  <p><strong>15:28</strong> - After writing that last entry, I checked Twitter for news (in retrospect, I really should have done that <em>first</em>) and saw mentions of a superseding indictment against Trump for the Mar-a-lago case. I dithered for several minutes about what to do, but ultimately decided to tentatively put in 100 on YES, since after all, I had no real chance of winning if it didn’t resolve YES anyway.</p>
</blockquote>

<blockquote>
  <p>Sadly, by then, 50P had seen the news too and bought it up to 74.8%. And following my bet, zubby put in 446 more (74.8-&gt;79.8%). I really wish I had access to my linux desktop so I could run the script and see what the relative position with Johnny is, so I know how much I need to buy to get ahead of him if this does go YES.</p>
</blockquote>

<blockquote>
  <p><strong>15:35</strong> - I quickly plugged in my desktop just to check (not bothering to move the monitors into place, just plugging in the keyboard and mouse.) It turns out that at current market prices, I’m already way ahead of Johnny, though perhaps he could catch up if he immediately sold everything and bought lots of YES.</p>
</blockquote>

<blockquote>
  <p>Even better, I ran the hypotheticals to see what the rankings would be if it resolves YES or NO, and either way, I’d be in second under current circumstances! Zubby loaded up on so many YES shares that he’ll sink to 3rd place if it were to immediately resolve NO. The normal instinct would be to load up on more shares myself to maximize profits, but only the ordinal position really matters, so I guess I’ll just sit tight and hope for the best. Now I’m REALLY glad that I didn’t try to load up on NO at 38% in a futile attempt to catch up with Johnny earlier.</p>
</blockquote>

<blockquote>
  <p><strong>15:39</strong> - Just got the resolution email. I guess that’s that. I can’t believe that miracle came through for me at the end. I was pretty dejected earlier this afternoon, feeling like I came so far and saw so many miraculous successes only to falter at the last obstacle. But it’s all over now. I can’t believe it.</p>
</blockquote>

<blockquote>
  <p><strong>28.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>07:27</strong> - One other thing I didn’t mention - I discovered a bug in Salem Plus when Johnny placed his 54% limit at 11:36. I was looking at Salem Plus and noticed zubby and 50P both bought at exactly 54%, which implied that someone had added a limit order, so I went to Salem to check, and discovered there was a transaction from Johnny that didn’t appear on Salem Plus at all.</p>
</blockquote>

<blockquote>
  <p>Back when I edited Salem Plus that one time while on vacation in Georgia, I modified Salem Plus to filter out limit orders, since it’s generally not useful to bump markets up to the top just because someone placed a new limit order, and not useful to clog up the betting history with $0 bets at weird prices and so on.</p>
</blockquote>

<blockquote>
  <p>However, in this case, Johnny placed an “in the money” limit order, which meant that it was partially filled with a normal buy from the current market price down to 54%, and then the rest would be filled as a limit order whenever people (i.e zubby and 50P) traded against it.</p>
</blockquote>

<blockquote>
  <p>Unfortunately, this meant that Johnny effectively had a massive NO buy that didn’t show up in Salem Plus at all, as I didn’t account for that possibility. But when it comes to Salem Plus fixes, I figured there was no point in trying to fix it now, given how the competition was almost over anyway.</p>
</blockquote>

<blockquote>
  <p>There’s another bug in Salem Plus that I’ve known about for months, but never got around to fixing. Whenever someone buys YES while holding NO shares or vice versa, Manifold will insert two extra transactions into the history for some reason, showing them immediately selling the YES and then the NO (or vice versa) in the amounts that canceled out. This clogs up the bet history (as Salem Plus only shows the last 10 bets for each market) and makes it harder to see the real trades, but it seemed complicated to detect and I never got around to actually fixing it, and by this week, the end of the competition was so close that it didn’t seem worth the effort.</p>
</blockquote>

<blockquote>
  <p>…As for Salem, once the indictment market resolved, I was firmly in second place again. My lead over Johnny was huge, around 2k IIRC, I’d made a little profit off my YES shares, but it was mostly due to Johnny holding huge amounts of NO shares.</p>
</blockquote>

<blockquote>
  <p>As I commented later on Salem, the competition was effectively over for us, with huge gaps between the top players (and no markets left with real uncertainty). In order for Johnny to overtake me, it would take something really surprising like a Ukraine ceasefire deal and Bolsonaro getting deported in the next four days. That or someone pulling another Josiah Neeley.</p>
</blockquote>

<blockquote>
  <p>I continued keeping an eye on the markets to try to guard against the unlikely event of someone pulling a Josiah, but I was watching them a lot less intently and desperately than before, and didn’t plan to bother checking them at all when I woke up in the middle of the night. Of course, past experience showed that Johnny and zubby are way faster than me and would likely take any profit opportunities that did arise, but I might as well keep watching, just in case.</p>
</blockquote>

<blockquote>
  <p>Following my win, I was filled with euphoria for a while, and if I hadn’t been at work, I might have very well went out to Salt and Straw right then, in the middle of the afternoon. As it is, I often got distracted and kept checking for new comments on Salem (among other things, zubby congratulated me on the win and PPPP jokingly proposed a <em>fourth</em> Trump Indictment market.)</p>
</blockquote>

<blockquote>
  <p>After work, I spent a while on Salem, looking through the comments and betting history on the Supreme Court markets to reminisce about past glories, and then finally left for Salt and Straw [to celebrate] at 5:46pm.</p>
</blockquote>

<blockquote>
  <p>…Thursday evening, I marveled at how much things had changed over the last 24 hours. Wednesday evening, I was still desperately watching Salem and hoping I would somehow manage to catch up to Johnny, and a day later, everything was over and I miraculously did win. Incidentally, the indictment win propelled DfromBham onto the leaderboards (19th place), so he’s no longer a “no-name” and I added him to my scripts, even though it doesn’t matter now.</p>
</blockquote>

<h1 id="july-28-aug-1">July 28-Aug 1</h1>

<p><img src="/img/salem2/july4.png" alt="Score graph" /></p>

<p>Even with the contest effectively over, I knew there was a slight risk of someone pulling a Josiah Neeley and putting Johnny back into the lead at the last minute, so I still had to keep watching Salem Plus, if not quite as intently as before. As it turned out, this actually happened twice on Friday, but then there was no more notable activity for the rest of the contest, just random people putting last minute money into the near-certain markets.</p>

<p>I also started researching more about the contest online and came across an extra prize announced back in February that I had no idea about. I also learned more about Johnny and Zubby, particularly the latter, who got profiled in a news article (apparently he has made six figures trading the <em>real money</em> prediction markets in the past.)</p>

<blockquote>
  <p>I went to bed at 10:31/10:53, still earlier than usual. I didn’t plan to check Salem Plus if I woke up during the night like I’d been doing, but I was hoping to get up for a different reason - Wanikani…</p>
</blockquote>

<blockquote>
  <p>Anyway, I slept better than usual, presumably due to the extreme lack of sleep the night before. In particular, this was the one night that I didn’t wake up between 3 and 5am. I think I woke up around 2, but stayed in bed, and didn’t wake up again until 5:24.</p>
</blockquote>

<blockquote>
  <p>I got up to start the WK session as planned so that at least it wouldn’t be polluted by the 6am reviews, and naturally looked at Salem Plus, and sank when I saw that ATAM CMS had spiked.</p>
</blockquote>

<blockquote>
  <p>At 3:58:52, Stevie Miller decided to do a Josiah impression and bought 551 YES on ATACMS, spiking from 9.3% up to 23.0%. And Johnny, who presumably has a bot alerting him at all hours of the day (and tends to trade in the early AM hours a fair bit anyway), bought 1700 NO (23.0-&gt;13.0%) just two minutes later at 04:01:39.</p>
</blockquote>

<blockquote>
  <p>I quickly ran the python script and discovered that fortunately, the standings hadn’t changed much. Fortunately, I had had such a huge lead over Johnny that this barely made a difference. IIRC, my “uninvested cash ratio” was negative 22-something% when I checked yesterday evening, and was now down to “only” -17.8%. Still, it was a reminder that the contest isn’t over yet, and Johnny still could potentially get really lucky and win, if someone pulls a <em>real</em> Josiah.</p>
</blockquote>

<blockquote>
  <p>I quickly went back to bed, but the Salem scare meant I had no hope of sleeping if I ever did, and I got back up at 5:35.</p>
</blockquote>

<blockquote>
  <p>I spent a long time pondering Salem, looking at Johnny and my positions with the script, etc. and ultimately decided to buy 1000 NO (at 6:07, 13.0-&gt;10.0%). I figured that now that Johnny was holding a much larger position than me (3163 NO shares), there was little risk in buying ATACMS, since Johnny would lose more than me if it went YES. And while I didn’t bother to calculate it, I figured that even if he sold and then it went YES, he would probably lose so much on the sales that he would still be behind. And of course, the ATACMS price was still elevated and way above the other markets, and that little bit of extra profit would provide an additional buffer in case other fortunes drop into Johnny’s lap.</p>
</blockquote>

<blockquote>
  <p>Coincidentally, less than a minute after my purchase, zubby also made some buys, grabbing 500 NO in three other markets (Taiwan, Iran, and Ukraine Ceasefire.) I wonder why he’s even bothering, since he’s guaranteed to take first almost no matter what happens, and investing his money just increases his downside risk in the event of an upset. And the amounts don’t seem designed to maximize profits either (he should have gone for ATACMS, which was still the highest at just under 10% and would also correlate his position more strongly with mine, to boot, reducing the risk of an upset.) But whatever.</p>
</blockquote>

<blockquote>
  <p><strong>08:29</strong> - P.S. my ATACMS NO buy increased my uninvested cash ratio over Johnny back up to 22.0%. Of course, my cash is basically meaningless to Johnny’s chances. A more useful number to track is what my lead will be (assuming all the markets go as expected). That number is up to 1570 (compared to a lead of around 1933 at current market prices, as he has more invested than me.)</p>
</blockquote>

<blockquote>
  <p><strong>29.07.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>11:46</strong> - During breakfast yesterday, it struck me just how much things had changed for the day before. On Thursday morning, even while eating breakfast, I would walk over and check Salem Plus on the computer in between bites, as the indictment news could come at any time. Of course, that’s partly because it takes a lot of chewing to eat the apple and overnight oats. On Friday, I paced around the room a bit and adjusted the window blinds twice while eating breakfast, but only bothered to look at Salem Plus on the computer once.</p>
</blockquote>

<blockquote>
  <p>…I randomly decided to google “salem center prediction market contest” to see if people had said anything about it. I expected lots of posts from the beginning of the contest and nothing since, which was mostly the case. However, I came across an announcement from February of an extra prize.</p>
</blockquote>

<blockquote>
  <p>In order to try to fight the declining participation rate in the contest, they announced an additional $5000 prize for the person with the highest percent increase in their portfolio value from February 15th 6am until the end of the contest (which also requires you to end with at least $2000 and bet at least $1000). They hoped that rewarding people for a large increase ratio would encourage participation among people who had a low net worth (and thus could most easily increase it) and had no chance of winning the main contest.</p>
</blockquote>

<blockquote>
  <p>It was announced back in February, but I’d never heard of it until now. At first, I figured that I had probably won it just by chance, because the China COVID market fiasco would have greatly suppressed my net worth in February, and I made massive gains since then. However, I tried my best to temper my hopes, reasoning that I had no idea when in February the COVID market tanked and also that one of the newer rising stars like Malte Schrodl might have a much larger ratio than me either way.</p>
</blockquote>

<blockquote>
  <p>After lunch, I got back to the computer to see a second surprise. At 14:41:53 a no-name (Greg Simitian) had suddenly bought 1000 YES on  “US Debt Limit Raised”, spiking it from 7.0 to 28.4%. Zubby had already bought 571 NO (to 22.3%) at 14:43:05.</p>
</blockquote>

<blockquote>
  <p>I quickly got out my chromebook and went to Salem and bought 200 NO (at 14:46:51) followed by 1000 more at 14:49:19, down to 14.2%. In the process of checking the bet history on Salem, I discovered that Greg had actually bought it $10 at a time, over the course of a minute or two. Clicking the “bet 10” button a hundred times must have taken some dedication. I’ll never understand why 50P and the like always spam that instead of making bets the normal way, but this is by far the most extreme I’ve seen of that. It also means that zubby was even faster at responding to the spike than it looked like from the timestamps on Salem Plus (which only shows when the transactions started if someone spams a bunch in a row).</p>
</blockquote>

<blockquote>
  <p>I also discovered that Malte Schrodl was a major beneficiary, as he had coincidentally put a number of NO limit orders down at 13, 15, and 20% at 11:24am. (He later explained that he put the limit orders down after seeing the Stevie ATACMS spike that morning, just in case someone else did the same thing, which was good thinking.)</p>
</blockquote>

<blockquote>
  <p>It seemed a bit suspicious to me, since it made no sense that a new player would join just three days before the end of the contest and put all their money down on one market. Although I guess if you’re going to join right before the contest ends, that’s the way to do it, since you have no hope of reaching the leaderboard otherwise. Not that you’d actually be eligible to win, since they’d obviously exclude people who just yolo’d one bet and got lucky.</p>
</blockquote>

<blockquote>
  <p>The circumstances made me suspicious of cheating, but I figured if someone were actually cheating by creating an alt account, they would have had their main account ready to buy the spike, and there was no sign of that.</p>
</blockquote>

<blockquote>
  <p>I put down the extra 1000 on NO because I figured that if I didn’t do it, Johnny would come along and take that profit instead. And I figured that it was a relatively safe bet since Johnny already had a large number of debt ceiling shares and thus wouldn’t jump ahead of me if it somehow resolved YES (not as many as I assumed it turns out, only 900 or so.)</p>
</blockquote>

<blockquote>
  <p>The thing I found weird was why zubby and Johnny didn’t jump on the spike, when they usually do so so quickly, much faster than I ever could. And it got even weirder when I left it at 14% and the minutes dragged on with noone touching the market.</p>
</blockquote>

<blockquote>
  <p>I knew that zubby had been 100% invested when I checked in the morning, and probably didn’t want to sell too much to buy the spike, but that didn’t explain Johnny. I’d long suspected that his market spike bot was not as sensitive as mine, and it might miss movements that happened as a long series of bets rather than one giant one. Or maybe he was just in the bathroom at the time or something, though that excuse wore thin as time stretched on.</p>
</blockquote>

<blockquote>
  <p>It was even weirder when Johnny left a comment on the market at 3:34pm, showing that he’d seen it, but still didn’t invest. The first person to buy it was PPPP at 4:14. Maybe Johnny has just given up. After all, my lead is way too big for him to catch me even at a 14% margin, though that doesn’t explain why he bothered with the Stevie spike the previous night. Oh well.</p>
</blockquote>

<blockquote>
  <p>Speaking of the debt ceiling, the February 15th announcement post also commented on some of the markets and wrote</p>
</blockquote>

<blockquote>
  <p><em>The debt limit standoff is one of the main issues in Washington, with both sides seemingly unwilling to compromise. The market seems optimistic about finding a solution, with 77% thinking that the debt ceiling will be raised by the end of July.</em></p>
</blockquote>

<blockquote>
  <p>So that shows/implies that even <em>Richard Hanania himself</em>, the <em>organizer</em> of the contest, was also misled by the trick question on the Debt Ceiling market, treating it as “will congress come to a deal to avert the debt ceiling default”, the natural question and the one that was on everyone’s mind, rather than “what color will the resulting law happen to be”, the question it actually turned out to be about. I think it’s pretty ridiculous to have a trick question that even the founder didn’t understand, but whatever. I still managed to get second place in the end in spite of that.</p>
</blockquote>

<blockquote>
  <p>In further Salem news, after work I quickly got on my computer and modified my script to figure out who would win the Feb 15th prize. It turns out that under current circumstances, I’ll only be fifth, after Malte Schrodl, Sid Sid, DfromBham, and PPPP.</p>
</blockquote>

<blockquote>
  <p>However, I would have won if they used February 7th as the reference point instead of the 15th, and also would have won if they used the 21st. Unfortunately, February 15th was basically smack in the middle of a dip between the two peaks of the market. Oh well, it’s not like I needed the money, and the outcome was pretty much pure luck based on the exact starting date used anyway.</p>
</blockquote>

<blockquote>
  <p>In the process of calculating that, I noticed another interesting statistic. As of yesterday evening, there were exactly 999 players who had placed at least one bet. However, Greg was actually not even the most recent. He was the second most recent (the 998th), with the 999th player being someone named Lorenzo Buonanno. Lorenzo was smarter and split his bets among multiple markets and bought NO instead of YES, though that of course ensures that he’ll only end 5-10% above where he started. I can’t imagine why anyone would bother joining the tournament three days before the end, and it seems even more pointless if you’re just going to bet conservatively like that. Oh well.</p>
</blockquote>

<blockquote>
  <p>I commented on Salem with the statistics I found about the Feb 15th contest, and zubby responded “That was announced a long time ago! Also, totally wild that some of you guys knew how much money everyone had the whole time.” while PPPP said “how did you know how much each player had on 2/15?”.</p>
</blockquote>

<blockquote>
  <p>I explained that the bet data is publicly available, so I just wrote a Python script to add it up, and that I’d assumed all the top players had done the same thing, since Johnny had alluded to doing it as well. I’m surprised that zubby seemingly never did. It’s extra amazing that he managed to win without having any idea what the margins were.</p>
</blockquote>

<blockquote>
  <p>After that, I went to Manifold out of curiosity, and spent a while searching for all the Salem contest related questions there. There were a bunch of questions related to the Salem contest, mostly created around when it first started, though some people (Johnny mostly) had created a lot of more recent low-activity markets about e.g. “will Johnny win” or “will zubby win”, “who will be in the top 5”, “what will be the final score for the top player”, etc.</p>
</blockquote>

<blockquote>
  <p>Most of the markets had little activity and no comments, but a couple of the early ones did have extended discussion in the comments, and in particular, there was one discussion between Johnny and Henri Lemoine (well I assume it’s Henri, his avatar is the same as on Salem anyway) about the possibility of writing scripts to figure out everyone’s stats from the public api data, and that sort of thing.</p>
</blockquote>

<blockquote>
  <p>At one point, Johnny talked about how he keeps a spreadsheet with his subjective probabilities for each market, and has a script to highlight the markets with the best return relative to his estimates, and even posted the code of a Jupyter Notebook that he wrote to do this.</p>
</blockquote>

<blockquote>
  <p>This was all the way back in the first month of the contest. I wish that it had occurred to me to check Manifold before, because I could have gotten some valuable intelligence on Johnny. I do wonder if he continued doing the spreadsheet thing after August. Myself, I almost never tried to put my subjective beliefs into concrete numbers, and I only occasionally made speculative bets on “undervalued” possibilities that I didn’t think were guaranteed to actually happen. I think putting your beliefs into numbers and trying to trade on that might actually be a trap, since the nature of transaction fees makes it impossible to profit from small market swings, even if you’re right.</p>
</blockquote>

<blockquote>
  <p>One comment also linked to the source code for Salem, which is apparently on Github. I’d looked at the Manifold source code back in November, but it never occurred to me that Salem was a code fork of Manifold and that source code was also publicly available. I knew pretty much how things worked, and the formulas and so on, but I didn’t know the exact value they had the transaction fees set to, and only bothered to reverse engineer that in early January. If I’d known about the source code, I probably could have found the value there and saved myself some trouble.</p>
</blockquote>

<blockquote>
  <p><strong>02.08.23</strong></p>
</blockquote>

<blockquote>
  <p><strong>18:13</strong> - Ever since I started the contest, or at the very latest since November, I’d often found myself mentally narrating my history in the Salem contest, as if I won and people actually cared what I did, and that of course grew more frequent over time, as I rose through the ranks.</p>
</blockquote>

<blockquote>
  <p>I’d long planned to write a giant blog post about my experiences in the contest, and had originally been hoping to write it the previous weekend (the 22-23rd). Of course, I didn’t know quite how things would turn out at that point, but I knew I’d end in either third or possibly second place, and could write most of the post and fill in the end later. But of course, I got busy with the Dave Barry stuff and never even started the blog post, and thus it fell to the final weekend.</p>
</blockquote>

<blockquote>
  <p>And of course even on the final weekend, I procrastinated until Sunday afternoon and didn’t start work on it until 12:10pm. I worked on it all afternoon and evening and didn’t stop work until 10:55pm (or arguably more like 11:08pm, since I naturally kept thinking about it for a while afterwards). Of course, I did take a few breaks during those 11 hours, but even during the breaks I would naturally be thinking about the blog post the whole time. It was hard work, but I really wanted to have it ready for the end of the contest, and that Sunday was the last opportunity.</p>
</blockquote>

<blockquote>
  <p>I went to bed at 11:48 on Sunday and then continued working on it all morning Monday before work. My original plan was to have two sections in the post, first a “quick” list of major lessons I learned during the contest, and then a detailed chronological account of the contest. However, after spending all Sunday and Monday morning, I still hadn’t even finished the former, so it was clear that I wouldn’t be able to finish it all on time. Instead, I decided to break it into the two parts and just try to finish the first before the contest ended.</p>
</blockquote>

<blockquote>
  <p>Anyway, I continued working on the blog post after work Monday evening. I’d mostly finished part 1, but still had the last two sections to write, and then I needed to proofread and edit it. It was a bit more relaxed though - I didn’t finish it until ~11:30pm, but I also took a couple breaks…</p>
</blockquote>

<blockquote>
  <p>…As for Monday night, I was up late due to working on the blog and all the excitement around the end of the contest and so on. I’d originally planned to keep my remaining cash uninvested, just to reduce the tail risks, since increasing my score couldn’t actually affect the ranks at all, but I figured that I might as well make a little extra profit with negligible risk, since if/when they revealed the final scores, having my number be slightly bigger might look slightly more impressive to people, even if it couldn’t change the rank.</p>
</blockquote>

<blockquote>
  <p>Since it was so close to the end of the contest (midnight Pacific time), there was effectively no chance of any risk from the <em>outcomes</em> (unless someone on Salem was say, actively conspiring with Trump to post on Twitter right before midnight in order to win the contest), but there was a slight tail risk that Salem would arbitrarily decide to resolve some of the markets incorrectly or something, so I wouldn’t be completely secure until they actually resolved the markets and announced the winners.</p>
</blockquote>

<blockquote>
  <p>Thus around 11:45, I used my optimal bet allocation script one last time and invested my final $5939 for an extra $360.8 of profit. I was really surprised when Johnny had the same idea a few minutes later, especially since he hadn’t made any bets since the Stevie spike early Friday morning, and I’d assumed that he’d just given up. And then a few minutes later, midnight rolled around, and that was that.</p>
</blockquote>

<blockquote>
  <p>I felt like posting the blog post before the markets resolved was tempting fate, since there was still the slight chance that Salem screwed up the resolutions, and thus planned to wait until everything was officially announced. I didn’t go to bed until 12:16 Monday night, and slept fitfully. Every time I woke up during the night (more often than usual), I would quickly check the Gmail app on my phone to see if the resolution emails had come in yet.</p>
</blockquote>

<blockquote>
  <p>I also got out of bed a couple times, just to use the bathroom or get a drink of water, but one time, around 4:09am, I decided to get on the computer for a while. Coincidentally, Zubby had just left a comment at 4:03am saying “Great contest everyone!”, good luck, etc. PPPP and Johnny would later respond an hour or two later.</p>
</blockquote>

<blockquote>
  <p><strong>19:44</strong> - I initially assumed that the markets would resolve by 5:30-6am, if not sooner, since that’s when they’d often resolved in the past, so I was increasingly surprised when they didn’t resolve all morning. Eventually, I gave up and decided to just go ahead and publish the blog post but not link it anywhere, so I could link to it later once they finally did resolve.</p>
</blockquote>

<blockquote>
  <p>Apart from that, I mostly spent the morning searching for news about Salem. I expected at least a bunch of perfunctory posts announcing the end of the contest, and probably mentions on prediction market focused sites like LW, ACX, etc. Thus I was very surprised by the complete radio silence. It was very eerie, how nobody was talking about it at all.</p>
</blockquote>

<blockquote>
  <p>Salem didn’t put out a single post about the contest, nor did Hanania, etc. Also disappointing was that Scott Alexander wrote a “Manic Mondays” post on ACX (posts that focus on prediction markets) and didn’t even mention Salem at all.</p>
</blockquote>

<blockquote>
  <p>…Throughout the day, I checked Gmail on my phone to see if the markets had resolved yet. I finally got fed up and tired of waiting, and went ahead and linked my blog in the comments on Salem at 3:19pm, and also posted it to r/slatestarcodex on Reddit. It’s not a subreddit I’ve ever frequented, but it seemed appropriate since Scott loves prediction markets and I only found out about the contest via ACX.</p>
</blockquote>

<blockquote>
  <p>Also, I found Zubbybadger’s Twitter and read through the last year of posts. Apparently he is really active on Kalshi and even a community manager for Kalshi, but he also spent a lot of time tweeting about the debt ceiling predictions, and back in November, about forecasting the midterms. I guess it would make sense that he did so well when he already has tons of experience and is highly active in forecasting.</p>
</blockquote>

<blockquote>
  <p>I arrived home from work to a pleasant surprise - the barrage of emails from Salem that they had finally resolved all the remaining markets. It looks like they resolved at 4:35pm, which was odd, since I could have sworn I checked my phone after that before leaving work, but whatever. I also got an email for a comment left by PPPP on Salem, responding to my blog post. I was surprised that people actually read it, and so quickly. Later on, I got comments praising the blog post from Zubby and DfromBham as well.</p>
</blockquote>

<h1 id="on-the-number-of-players">On the number of players</h1>

<p>As mentioned, on Friday, July 28th, two new users joined, bringing the total number of users who had placed at least one bet to exactly 999. However, while going through the data while working on my first blog post, I discovered that the first of those 999 users was actually Salem Markets itself, which placed a number of bets in the week before the contest started for some reason, and thus there were only 998 “real” users. Fortunately, on the very last day of the contest, another user joined, bringing the total back up to 999, or a round thousand if Salem Markets is included.</p>

<p>Note that three of these users <em>placed</em> a bet but never had a bet <em>filled</em>. Presumably, they placed a limit order, canceled it, and then never did anything else during the contest and thus stayed at the starting $1000. So the total number of real users who had a bet go through is only 996.</p>

<h1 id="conclusion">Conclusion</h1>

<p>It’s amazing how much the Salem contest occupied my life over the last year, as demonstrated by the sheer volume of journal entries I wrote about it. I knew I’d been spending massive amounts of time on it, but it was only by compiling this post that I realized just how much I’d written about it as well.</p>

<p>It was an interesting experience to do once, but I’m not eager to try it again due to the sheer time investment required and the amount of luck involved. Still, it was a fun adventure, and it’s really amazing how everything lined up for me to rise through the ranks.</p>

<p>In case you’re curious, here are the final rankings. For users subject to score adjustment, the adjusted score is in parenthesis next to the raw score.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) zubbybadger  23182.0525265
2) Robert  17820.5689235
3) Johnny Ten-Numbers 16622.399872 (15772.1474041)
4) David Hassett  9554.89409126 (9366.72822662)
5) Malte Schrodl  9049.16293444
6) Connor Pitts 9026.83812428
7) Ben  7791.8542649
8) Mark 7852.03582088 (7414.1097106)
9) ussgordoncaptain 6633.64996396 (6629.13922078)
10) PPPP  5592.71033033
11) Sid Sid 4244.47124376
12) Jack  4061.42438528
13) Krum-Dawg Millionaire 3821.79230486
14) Henri Lemoine 3844.80835926 (3808.41219121)
15) Alvaro de Menard  3521.88368323
16) Jack G-W  3518.11552372
17) Asher Gabara  3307.75799278
18) Oliver S  3248.5177568
19) DfromBham 3135.85072837
20) Henry A Long  2836.65664724
21) KbBFc7EDIThLfHZlXDubsLbO4Sn1  2571.08099949
22) Alex Radcliffe  2560.22134358
23) 50P 2527.33043929
24) xUhM61t0YrfOzqs6WsG1Ri9Puyl1  2472.42382728
25) Charles Paul  2458.1823912
</code></pre></div></div>

<p>The top player, Zubbybadger, has years of experience <a href="https://washingtonmonthly.com/2022/04/03/the-art-of-the-pump/">and has made over $150,000 of real money on PredictIt</a>, constantly watching C-Span and the like to get an edge on predicting political questions. Meanwhile, the third place player, Johnny Ten-Numbers, is an active participant on Manifold Markets, the play-money prediction site that Salem was based on. I think it’s especially amazing that I managed to reach second place despite having no experience with prediction markets at all when the contest started.</p>

<p>Two other active players on Manifold, Henri Lemoine and Adrian Kelley, also joined the Salem contest and thus were considered early favorites. However, they only finished in 14th and 47th place respectively.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">How I came second out of 999 in the Salem Center prediction market tournament without knowing anything about prediction markets, and what I learned along the way - Part 1</title><link href="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html" rel="alternate" type="text/html" title="How I came second out of 999 in the Salem Center prediction market tournament without knowing anything about prediction markets, and what I learned along the way - Part 1" /><published>2023-08-01T14:36:00+00:00</published><updated>2023-08-01T14:36:00+00:00</updated><id>/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1</id><content type="html" xml:base="/2023/08/01/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-1.html"><![CDATA[<p>Last August, the Salem Center at the University of Texas <a href="https://www.cspicenter.com/p/introducing-the-salemcspi-forecasting">announced a year-long prediction market tournament</a> in partnership with the Center for the Study of Partisanship and Ideology in an attempt to find people who are good at predicting the future. Despite having absolutely no experience with prediction markets, I decided to give it a try and amazingly managed to place second out of nearly a thousand participants.</p>

<p>This post is divided into two parts. The first part (what you’re reading) begins with a brief description of how the tournament worked, then the overall lessons I learned while participating in the contest. <a href="/2023/08/28/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-2.html">The second part</a> will be a detailed chronological account of the contest from my perspective, explaining how my strategy changed over time.</p>

<h1 id="how-does-a-prediction-market-tournament-work">How does a prediction market tournament work?</h1>

<p><img src="/img/salem_china_covid.png" alt="Graph of Salem China COVID market" /></p>

<p>Every player starts with $1000 in imaginary money and can bet on various questions like “Will Republicans win the House of Representatives?” or “China Reaches 100,000 Covid Cases by Winter?” to increase their imaginary money, with the player who has the most money at the end of the year being the winner.</p>

<p>However, the odds of the bets are not fixed. Instead, they take the form of a <em>prediction market</em>. In a prediction market, there is a “market price” which goes up and down depending on how people bet.</p>

<p>To place a bet, you buy “shares” in the market, with the number of shares depending on the current market price. For example, suppose that the current market price for “Will Republicans win the House of Representatives?” is 0.80 (i.e. 80%), and you think that it will happen. In this case, you can bet $1000 on YES and receive 1000/0.80 = 1250 YES shares, which will each pay out $1 if the Republicans win the House, and thus, you will end up with $1250 if you were right and $0 if you were wrong. Alternatively, if you think that it <em>won’t</em> happen, you can bet on NO instead. In this case, you would receive 1000/(1-0.80) = 5000 NO shares, so you will end up with $5000 if Republicans <em>don’t</em> take the House and $0 if they do.</p>

<blockquote>
  <p><strong>Note:</strong> In reality, the number of shares you would receive is much lower than this due to transaction fees and slippage, but I’m ignoring that for the sake of simplicity in this example.</p>
</blockquote>

<p>Additionally, the market price changes over time. Every time someone bets on YES, the price goes up, and every time someone bets on NO, the price goes down. Therefore, you get better odds if you bet the opposite of the way most other people have bet.</p>

<p>Lastly, you can also <em>sell</em> your shares early, instead of waiting for the market to resolve and pay out to the winners. For example, suppose you bought 1250 YES shares for Republicans to take the House, and then a bunch of polls come out that favor Republicans and everyone thinks they are more likely to win, so they bet YES as well and increase the market price from 0.80 to 0.90. Then you could sell your shares early for 1250 * 0.90 = 1125 (again, ignoring transaction fees and slippage), and thus make a $125 profit off of your original $1000 bet.</p>

<p>If it all came down to just one bet like this, the contest wouldn’t be very interesting. Fortunately, the real contest took place over the course of a year with 91 markets in total to bet on, and people could reinvest the winnings from early markets in later markets to further increase their money (assuming they managed to consistently predict the outcomes correctly.)</p>

<p>Over the course of the year, I learned a number of lessons while participating in the contest. Here are my top 15 takeaways.</p>

<h1 id="1-its-not-just-about-predicting-the-outcomes">1. It’s not just about predicting the outcomes</h1>

<p>You might think that a prediction market contest is all about who can most accurately predict the outcomes of the markets.</p>

<p>In reality, Salem is a game where the objective is to maximize your score (or rather the <em>ordinal rank</em> of your score), and predicting the outcomes of the questions is one skill that is important for doing this, but it is not the only one. Among other things, you need to be quick to find relevant news, you need to be able to predict <em>when</em> the markets resolve, you need to correctly allocate your bets taking into account transaction fees and opportunity costs, and you need to predict what <em>other players</em> will do.</p>

<h1 id="2-breaking-news-is-easier-than-predicting-it">2. Breaking news is easier than predicting it</h1>

<p>The fastest way to make a profit is to find important relevant news which will determine resolution or massively swing the market price and be the first to (correctly) trade on it.</p>

<p>Of course, this is easier said than done. The markets I did best in involved following election results (for the Wisconsin Supreme Court in April and the two Turkish elections) and the Supreme Court decisions, both cases where the information would come out at a relatively predictable time, though that of course means that <em>everyone else</em> is also watching and racing you, trying to do the same thing.</p>

<p>In other markets, such as “Will PredictIt Survive?” or “Elon Appoints New Twitter CEO?”, information would come out of nowhere with no warning, and I never had any luck with those. I’m not sure how other people did it, but it presumably involved following the right accounts on Twitter all day. But it doesn’t seem remotely feasible to do that for months on end across many different markets, so it was probably largely a matter of luck.</p>

<p>The <em>easiest</em> way to make a profit is to wait for <em>someone else</em> to find news and spike the market, and then buy into that market as well before it resolves. However, the returns from doing so are relatively small.</p>

<h1 id="3-betting-is-often-terrifying">3. Betting is often terrifying</h1>

<p>Following the news and being the first to bet on it sounds like easy money after the fact, but in the moment, it is terrifying. Sure it might <em>look</em> like the election is effectively over and there’s no way Vallas can win, but you don’t actually <em>know</em> that for sure. Sure it might <em>look</em> like the Supreme Court just banned race in college admissions, but a lot of people disagree and are betting against you, and maybe the Salem Center will agree with their interpretation and resolve against you. Are you really going to lose everything after a year of hard work, just like that?</p>

<p>It doesn’t help that you know that other players are likely watching the news too and trying to race you, so there’s a strong incentive to be bold and act more confident than you actually are. And even when things <em>seem</em> really safe, you can never be <em>completely sure</em> until the market resolves.</p>

<p>Once it resolves of course, you’ll immediately start beating yourself up with the benefit of hindsight, cursing your past self for not buying more/less of that obviously good/bad trade.</p>

<h1 id="4-predicting-when-a-market-will-resolve-is-important-too">4. Predicting <em>when</em> a market will resolve is important too</h1>

<p>This was one of my first major lessons, and one I learned the hard way. On November 16th, I noticed that the “Gay Marriage Bill in 2022?” market had spiked, and assuming that it was about to resolve and I could make a quick buck, I FOMO’d in with my entire balance ($3166) at a market price of 99.0%. As it turns out, the market did resolve YES in the end, and I made a profit of $32. So that was a smart bet, right?</p>

<p>Far from it, in fact. One issue is that the market price dropped into the 90s immediately afterward, and reached as low as 82.4%, so I could have made massively more profit if I’d just waited a bit to invest. But the other issue is the <em>opportunity cost</em> of having your money locked up for long periods of time.</p>

<p>As it turned out, the market didn’t resolve until December 13th, nearly a month later. For a month, I was completely locked out of doing anything on Salem, and just had to watch helplessly and pray that the market would resolve soon. In particular, this meant that I was unable to participate in the Georgia senate runoffs market at all, and thus missed out on the potential profit there.</p>

<p>And yes, before someone complains, it was <em>technically possible</em> to sell my shares early instead of waiting for resolution. However, doing so would have incurred <em>massive</em> losses, so it wasn’t a real possibility. (Another player,
Josiah Neeley, did sell out early at a huge loss, presumably due to not understanding this.)</p>

<p>I actually did already understand the importance of resolution timing, and before investing, I quickly checked Google and saw a news article that the gay marriage bill had passed a critical hurdle in the Senate. I thought it was odd, since that meant there were several more steps before it actually became law, so it seemed like the market might take a while to resolve, but I assumed that everyone else knew what they were doing and suppressed that little voice and FOMO’ed in. Big mistake.</p>

<h3 id="other-examples">Other examples</h3>

<p>Gay Marriage was the most dramatic example, but there were several other cases where I lost out due to failing to predict market resolution time.</p>

<p>On the afternoon of March 30th, the “Will Donald Trump Be Indicted for a Crime by July 2023?” market spiked due to news of the Bragg indictment. I actually happened to check Salem relatively early into the spike and considered buying in myself. However, I worried that the market might not resolve until the indictment was officially announced or something, and that that might take several days to happen.</p>

<p>Ordinarily, several days wouldn’t matter much, but this was on March 30th, and there were three other markets set to resolve on March 31st. If the indictment market resolved immediately, the correct move would be to buy in, but if it took several days to resolve, then that would be a bad idea because it would mean missing out on the profit from the March 31st markets. Therefore, I stayed out, and thus missed a bunch of potential profit when the indictment market did in fact resolve soon afterwards.</p>

<p>The next day, I was caught out <em>again</em> by the “Donald Trump Back on Twitter?” market, which said “This market will settle as YES if an account belonging to former president Donald Trump tweets at least one time between the opening of the market and March 31, 2023.” The market was originally set to close at midnight on March 31st, implying that March 31st was included in the time period of the bet. However, they randomly resolved it at 11:01am on March 31st instead, presumably interpreting the description as requiring Trump to tweet <em>before</em> March 31st. Since I thought that it wouldn’t resolve until later that night, I waited to put my money in until the evening and thus lost out on the potential profit when it unexpectedly resolved early.</p>

<p>Lastly, I also failed to guess when the “Elon Appoints New Twitter CEO?” market would resolve. The market spiked on the afternoon of May 11th, with the news that Elon was appointing a new CEO for Twitter, and I bought into that spike. However, it wasn’t clear to me whether the market would resolve immediately based on the <em>announcement</em> or would only resolve when the new CEO <em>took office</em> which wouldn’t be for another six weeks.</p>

<p>In the latter case, shares in the CEO market weren’t worth 100% because there would be a lot of other markets in the next six weeks that you’d miss out on. Presumably, everyone else took this risk seriously as well, because the market closed at only 92% when it resolved the next morning, rather than jumping up to 97-99% before resolution as would happen when everyone believed it would be resolving imminently. In fact, my final transaction before resolution was actually a small <em>sale</em> at 92%, to try to free up money in case it did get locked up for six weeks. If I’d known that it would be resolving the next morning, I’d have instead gone all in and made more profit.</p>

<h1 id="5-theres-a-risk-that-markets-wont-resolve-when-theyre-supposed-to">5. There’s a risk that markets won’t resolve when they’re supposed to</h1>

<p>There were a bunch of markets that were set to end on February 28th, as well as one market set to end on March 1st. Most of the time, Salem resolved markets relatively quickly, but for unclear reasons, they failed to resolve the end-of-February markets in a timely manner.</p>

<p>Instead, these markets were just stuck in limbo for several days before people finally got their money. This one didn’t really affect me, since I was not actively playing at the time anyway, but I’m sure it annoyed the people who were. It also means that anyone who was planning to reinvest the profits from the Feb 28th markets into the March 1st market before it closed were unable to do so.</p>

<h1 id="6-transaction-fees-are-significant">6. Transaction fees are significant</h1>

<p>When I first joined, I had no idea about the inner mechanics of the markets and only knew “bet on things you think will happen and against things you think won’t happen”. Following the November midterm elections, I was catapulted onto the leaderboard and realized that I now had a real chance of winning and needed to take things more seriously, so I immediately set about researching how the markets actually worked.</p>

<p>The Salem contest was run on a platform called Manifold Markets, and Manifold is open source, so I was able to find the source code that determined how market prices changed in response to bets, and how transaction fees were calculated.</p>

<p>Transaction fees are determined by the following formula:</p>

<p><code class="language-plaintext highlighter-rouge">fee = rate * bet * (1 - final market price)</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">rate</code> is a site-specific setting (which I finally got around to reverse-engineering in early January and found to be <code class="language-plaintext highlighter-rouge">0.1</code>), <code class="language-plaintext highlighter-rouge">bet</code> is the amount you’re betting, and <code class="language-plaintext highlighter-rouge">final market price</code> is what the market price would be after your bet <em>if there were no transaction fees</em>.</p>

<p>For example, suppose the current market price is 0.5 (50%) and you are betting an <em>infinitesimally small amount</em> so that the market price won’t change at all. In this case, the final market price is still 0.5, so the fee is just 10% * (1 - 0.5), or 5% of your bet.</p>

<p>Therefore, you only get 95% of the amount of shares you should have, which means that if you bet YES, you’re effectively paying a price of 1/.95 * 50% = 52.63%. In other words, the amount of YES shares you get at a market price of 50% is the same as the number of shares you would get if the market price were 52.63% and there were no transaction fees. Likewise, if you buy NO, the effective market price is 47.37%. Therefore, at a market price of 50%, there’s an effective bid-ask spread of 5.26%, just from the transaction fees alone.</p>

<blockquote>
  <p><strong>Note:</strong> This is <strong>only</strong> from transaction fees. For any real transaction, your bet would <em>also</em> move the market price, further decreasing the amount of shares you get, which is called <strong>slippage</strong>.</p>
</blockquote>

<p>As an example of how punishing transaction fees can be, there was one time when I accidentally bet $50 that I didn’t intend to and immediately sold the shares back. Despite immediately selling back my bet with no intervening market movements, I only got back $43.75. The transaction fees had just cost me 12.5% of my original bet, just from buying and selling it back.</p>

<h3 id="limit-orders">Limit Orders</h3>

<p>The above all applies to normal <strong>market orders</strong>. You can also place <strong>limit orders</strong>, where you specify a fixed price (sadly only whole percent numbers were allowed) and then if the market price reaches your limit, trades will automatically trade against your limit order at the specified price. The nice thing about limit orders is that there are <em>no transaction fees</em> for the buyer <em>or</em> seller.</p>

<p>One consequence of this is that when the market is at a limit order, trading against it offers a much better deal than the market price would indicate. For example, if you want to buy YES and the current market price is 52.0% with a NO limit at 52%, this is actually a <em>better</em> deal for you then if the current market price were only 50.0% but there were no limit order (which would result in an effective price of at least 52.6%).</p>

<p>This also means that occasionally, the market price getting <em>worse</em> will <em>improve</em> the deal. If the current market price is 51.9% and there is a NO limit order at 52% and you want to buy YES, the effective price you’ll get is whatever the transaction fees are <em>on top of</em> 51.9%, probably around 54%. But once you buy a tiny amount of YES, the market price will hit 52% and trigger the limit order, at which point the marginal price is <em>exactly</em> 52% with no transaction fees.</p>

<h3 id="split-bets">Split bets</h3>

<p>Another little-appreciated consequence of the transaction fee formula is that making a <em>single</em> bet will have very slightly lower transaction fees than splitting the same amount of money into multiple consecutive bets, assuming all else is equal. This is because the transaction fees are calculated based on the <em>final market price</em> (or rather what the final market price would be if there were no transaction fees). Making your bet in one big transaction moves the market more and thus has lower transaction fees <em>for the entire bet</em>.</p>

<p>Overall, I doubt this factor made a big difference, but it encouraged me to try to be bold and make fewer, larger bets. Some players, on the other hand, did the exact opposite. The player 50P in particular would always make their bets in the form of a long string of really tiny consecutive bets.</p>

<p>I didn’t care much if other players inflicted unnecessary transaction fees on themselves, but it was really annoying just due to clogging up the bet history with massive amounts of spam, making it hard to see what was actually going on in a market. Eventually, I got annoyed enough at 50P’s antics that I left a comment explaining how splitting up bets increases transaction fees. They explained that in addition to the normal UI for making bets, where you type in the amount you want to bet, there is apparently also a button in the UI you can click to make a $10 bet, and they were spamming that button instead of using the normal UI. Sadly, the information about transaction fees failed to change their behavior for long.</p>

<p>50P wasn’t the only person to spam the $10 bet button. The most extreme case was Greg Simitian, a new player who joined right before the end of the contest and put their entire starting $1000 on YES on Debt Ceiling (spiking the market price from 7.0-&gt;28.4%) in <em>100 individual bets of $10 each</em>. Just clicking that button 100 times must have been really annoying for them, as well as everyone else. It’s a shame Salem didn’t just disable that button.</p>

<p>Unfortunately, the numbers here are hard to calculate because Malte Schrödl (5th place finisher) had placed several NO limit orders at 13%, 15%, and 20% in case of precisely such an eventuality, and thus some of Greg’s bets were against a limit order and the normal rules don’t apply. However, if we take only Greg’s first 23 bets, before he hit the first limit order, Greg got a total of 2221.97006487 YES shares from his first $230. If he had instead bet $230 in a single bet, he would have gotten 2228.07008541 YES shares, a 0.27% improvement thanks to the lower transaction fees. So it’s not a terribly significant factor, but it is there.</p>

<p>As another example, the night before the Q2 GDP market resolved, I bet $500 on YES and then three hours later (with no intervening market movements), another $500. I got a total of 1127.69167347 shares, but if I had made a single $1000 bet, I would have gotten 1128.70022288 instead. Of course the whole reason I made split bets was because I was originally only willing to bet 500 and only changed my mind hours later. And the advantages to single bets are extremely tiny and swamped by intangible factors such as the chance that someone else will bet on the market in the meantime and move it in your favor or against you. Overall, I think I erred by worrying too much about transaction fees on split bets.</p>

<h3 id="transaction-fee-strategy">Transaction fee strategy</h3>

<p>For better or worse, I tried hard to avoid transaction fees. This mostly meant avoiding trading as much as possible and making decisive large trades when I did bet.</p>

<p>I also used limit orders to sell my bets wherever possible, though this does have downsides. First, you only come out ahead on transaction fees if your limit price is within ~3% of what the market price would have been anyway. But more importantly, you’re completely at the mercy of waiting for other people to trade against your limit order, which may not happen when you want it to. Lastly, there’s the danger that you’ll forget to cancel old, obsolete limit orders. There was one time when I forgot to cancel an old limit order and ended up <em>trading against my own limit order</em>, which was pretty embarrassing.</p>

<p>Relying on limit orders to sell my shares was a double-edged sword. Sometimes noone would cash me out when I really needed the money. And sometimes that was even a good thing. In the week before the Supreme Court decisions, I put limit orders at the market price on all my holdings in an attempt to sell them and free up money to bet on the Supreme Court. I sold some of my shares that way, but not all of them, which turned out to be fortunate, because in retrospect, it was a terrible deal, and the shares I sold would have made way more money if I kept them than I could have made betting on the Supreme Court with the extra money.</p>

<p>Additionally, the fear of transaction fees caused me to generally try to avoid trading too much, which I think is a mistake that many other players made. It was common to see people frequently buying and selling shares back around the same price, even though they were just losing money on transaction fees.</p>

<p>As an example of poor strategy, Johnny (the third place finisher) sold 2000 shares of “Trump Indicted Again?” at 99.3% just 70 minutes before it resolved, incurring a loss of $16.7 for absolutely no reason. If he’d just waited a bit and held to resolution, he would have been 16.7 richer with no effort.</p>

<p>As another example, on the final day of the competition, PPPP (tenth place finisher) sold 219 shares in “Trump the Favorite in Summer 2023?”, which was trading at 93.31% at the time, and bought “Send ATACMS to Ukraine?”, which was trading at 8.25%. Obviously, the latter had a better price, and hence higher return in a vacuum (93.31% is equivalent to 6.69% for NO, and 8.25 &gt; 6.69). However, thanks to transaction fees, this was actually a bad trade. PPPP ended up with 0.462845019 in cash and 217.995331618 ATACMS shares. Since this was just 10 hours before the end of the competition, there was no real risk and all shares were effectively worth $1, which means that PPPP effectively turned their original $219 into $218.458176637 by doing this, even though the price on the second market was <em>better</em> and would have made them more money in the absence of transaction fees.</p>

<p>Thanks to the heavy transaction fees, every bet you make should either</p>
<ul>
  <li>1) be a bet that you plan to hold until resolution</li>
  <li>2) a market where you expect imminent huge swings in the market price and are confident you can sell out at a profit</li>
</ul>

<p>I recently discovered <a href="https://manifold.markets/BionicD0LPH1N/what-informationstrategy-will-be-us#AYb0uvFEXrKqTGuH4rwZ">a comment</a> by Johnny from the beginning of the contest where he talked about maintaining a spreadsheet with his “subjective probabilities” for each market, and then buying the ones with the biggest discrepancy from the market prices. I think this might be a trap though, because unless the discrepancy is large, it encourages you to trade back and forth and lose money on transaction fees.</p>

<p>The other problem with the strategy described in Johnny’s comment is that it completely ignored <em>opportunity costs</em>.</p>

<h1 id="7-opportunity-costs-are-critical">7. Opportunity costs are critical</h1>

<p>Here’s a puzzle. Consider the “Oil at $100/Barrel During Winter?” market, which asks</p>

<blockquote>
  <p>This market will settle YES if oil is priced at at least $100/barrel for the months of November 2022-February 2023. Prices are taken from the following link, averaged over the four months.</p>
</blockquote>

<p>Imagine it is 11:22am on January 26th. The market is currently trading at 11.3%. You already have three out of the four months of oil prices that are going into the final average, and oil prices have been consistently low during the winter, making it effectively impossible for the average to hit $100. If you buy NO shares now, you’ll get an effectively risk-free return of ~10% in a month. Should you do it?</p>

<p>This was the situation facing Henry A Long (20th place finisher) when he bought $800 of NO and then left a comment on the market asking why the price was so high and why everyone else was seemingly sleeping on the market.</p>

<p>The problem is that you also have to consider the <em>opportunity costs</em> of betting. You have a limited amount of money to bet, the $1000 you start with plus however much you managed to gain or lose from earlier bets. Any money you bet on one market is money you can’t bet on another market. So what other markets could Henry have bet on?</p>

<p>At the time, “COVID Peak of over 300,000 by End of Winter?” and “Mask Mandate in Any State by End of Winter?” were trading at 14.3% and 12.6% respectively, and those markets were effectively risk-free as well.</p>

<p>Even better, those markets were set to close at midnight on February 28th, while the oil market wasn’t set to close until midnight on March 1st. This means that you could take any winnings from the Feb 28th markets and immediately plow them back into the oil market for a tiny bit of extra return. It would probably have been down to like 1% by then, but every little bit helps. (Of course, this turned out to be impossible because the Salem Center inexplicably took <em>several days</em> to resolve all of these markets, but noone could have known that at the time.)</p>

<p>What else was there? Also resolving on Feb 28th were “Will Russia Control Bakhmut?” at 34.9% and “China Reaches 100,000 Covid Cases by Winter?” at 46.6%. Those markets still had a lot of uncertainty and risk, but if you had a confident opinion on them, you could have made much more money (assuming you were right) then the risk-free 14.3% on offer, which in turn was better than the 11.3% available in the oil market.</p>

<h3 id="long-termism-considered-harmful">Long-termism considered harmful</h3>

<p>The end result of this is that it takes an <em>absolutely massive</em> mispricing in a long term market to justify actually betting on it, because the profit has to come <em>on top</em> of all the profit you could have made by betting in shorter term markets instead.</p>

<p>Therefore, throughout the contest, I almost exclusively focused on the markets that would be resolving soonest, sometimes betting on the markets that would resolve second-soonest, but not much more. A convenient side effect of this is that it greatly narrows the pool of markets you have to pay attention to and devote mental energy to. At the peak, Salem had over 30 markets open, many of which were useless long term markets that would be impossible to ever profit from, and being able to focus on a small subset of those allowed for applying more careful strategy and analysis.</p>

<p>Notably, Johnny did <em>not</em> do this. Throughout the contest, he had a significant amount of money invested in long-term markets that would only resolve at the very end of the contest. Even worse, a lot of the long-term markets that were available at the start of the contest were massively overpriced the entire time due to the rush of early players who didn’t understand opportunity costs either (for example, “Chinese Military Action against Taiwan?” was already down to 13% all the way back in <em>December</em>, despite not resolving until the very end of the contest.)</p>

<p>To be fair, when you have a large stash of money, the calculus changes somewhat because there are diminishing returns to betting on any one market, so it makes sense to spread things out a bit more, and Johnny was in the lead for most of the contest and had the most money. However, <em>even taking into account</em> his larger bankroll, I suspect that he was massively overweight on the long-term markets, especially since markets like Taiwan offered <em>worse</em> rates than the short term markets <em>even if you completely ignored resolution time</em>.</p>

<h1 id="8-there-are-invisible-opportunity-costs-too">8. There are invisible opportunity costs, too</h1>

<p>Up until January, I assumed that the optimal strategy was to keep your entire bankroll invested at all times. After all, money you have invested will grow over time (assuming you’re right about the outcome), and there were often some effectively risk-free markets to offer a baseline level of “interest rate” as well.</p>

<p>You can clearly see the <em>visible</em> opportunity costs of betting on one market, just by looking at the prices of any comparable markets that resolve at the same time (or earlier). What I didn’t realize until later is that there are <em>invisible</em> opportunity costs to betting as well.</p>

<p>When you bet, your money is effectively locked in until the market resolves. You <em>can</em> sell shares early, but doing so incurs transaction fees, and it takes an especially large profit opportunity to overcome the losses you would take by selling out early to free up money.</p>

<p>What I didn’t appreciate at first is that even if there are no good profit opportunities <em>now</em> (and hence no obvious opportunity costs), a new profit opportunity could appear out of nowhere at any moment. There are several possible causes:</p>

<ul>
  <li>1) New news comes out that greatly shifts a market’s price. Even if you aren’t the first person to discover the news, you can still make an easy profit by piling on top before the market resolves.</li>
  <li>2) Occasionally, people will just make really dumb bets, and you can profit a lot by being the first to trade against them.</li>
  <li>3) Occasionally, the Salem Center will add <em>new</em> markets. This wasn’t common, and I never saw much of a profit opportunity in them, but it’s worth noting for completeness.</li>
</ul>

<p>These opportunity costs are unknown and random and not something you can really put a number on, but they are important. In the second half of the competition, I always kept a lot of money uninvested to be ready for such opportunities, and only invested all my money when a market was about to resolve.</p>

<h1 id="9-predicting-the-actions-of-other-players-is-also-important">9. Predicting the actions of other players is also important</h1>

<p>So you’ve managed to predict the outcomes of the markets <em>and</em> when they will resolve, and you’ve figured out the transaction costs and optimal bet allocation. Are you set?</p>

<p>In addition to all that, you <em>also</em> have to predict the actions of <em>other players</em>, because they can move the market prices around with their own bets. I say this not because this is something I ever managed to do (far from it), but because if you <em>did</em> manage it, it would be incredibly useful. Someone who is sufficiently good at predicting the actions of other players could probably win the contest just from that, without even knowing anything else. But of course, predicting what other players will do is easier said than done.</p>

<p>To illustrate the difficulty, here is a pair of examples that where I made <em>opposite</em> mistakes. In the first case, I overestimated someone’s willingness to sell, and in the second case, I <em>under</em>estimated their willingness to sell.</p>

<h3 id="scenario-a-connor-and-china-gdp">Scenario A: Connor and China GDP</h3>

<p>On January 16th, the “China GDP Growth 4% or More in 2022?” market suddenly tanked (from 61% to 20%), driven by Iraklis Tsatsoulis, who found a news article where China announced GDP growth of 3%. That night, I noticed the drop and sold my YES shares and bought some NO shares (20-&gt;16%).</p>

<p>The following evening (Jan 17, 5:42pm), Connor Pitts (sixth place finisher) sold some of his YES shares, from 11-&gt;7%. I figured that 7% was too low, because the market apparently wouldn’t be resolving until June 30th, and wanted out.</p>

<p>However, I got greedy, and didn’t want to pay the transaction costs from quick-selling at 7%. Just by eyeballing the bet history, I could tell that Connor likely still had a large amount of unsold YES shares that he might want to unload, and I figured that putting down a YES limit at 7% would be a win-win situation. I would be able to sell my NO shares at 7% with no transaction fee, and Connor would be able to sell his remaining YES shares at 7% with no transaction fee. He had <em>already</em> sold some shares at 7%, and a 7% limit would be a strictly better deal for him than what he had already sold at, because it would be a <em>real</em> 7% with no transaction fees on top.</p>

<p>Therefore, I put up a 7% YES limit and then left a comment as well to call Connor’s attention to it. However, for some reason, he never took me up on it, either because he’d already gone to bed or because he had decided that he’d sold enough shares for the time being. Instead, the market price went back <em>up</em> as all the other people who’d bought NO shares during the spike started cashing out. I ended up having to quick-sell at 11% the following evening, and thus got less money than if I had immediately sold at 7%.</p>

<h3 id="scenario-b-johnny-and-the-debt-ceiling">Scenario B: Johnny and the Debt Ceiling</h3>

<p>In the early hours of June 2nd, Johnny suddenly bought massive amounts of NO shares in the “US Debt Limit Raised?” market, from 4% all the way down to 1.9%. Since the market wouldn’t resolve until the end of the contest nearly two months later, this was clearly a mistake. (It seems that Johnny misinterpreted the resolution criteria to imply that it would be resolving imminently.)</p>

<p>By the time I noticed this, Zubby (first place finisher) had bought $30 YES, and Johnny responded with another $1500 of NO. I was happy to see this because by then, Johnny was my only real competition, and this mistake meant that either his money would be locked up until the end of the contest, or he would sell early and take a hit from transaction fees.</p>

<p>However, the important question was whether to try to punish his mistake by buying YES shares myself, like Zubby had. Even though the market was guaranteed to resolve NO in two months, if I bought YES shares and then Johnny sold a lot and pushed up the market price, I could flip my YES shares for a profit. Even more significantly, any profits in this market would count <em>double</em> for me, because Johnny was my only competition, and thus any additional losses inflicted on Johnny were effectively a profit for me and vice versa.</p>

<p>Unfortunately, I greatly underestimated Johnny’s willingness to sell. I guessed that he would <em>maybe</em> sell from 2% up to 3%, and that the market wouldn’t move enough to make a profit worth the effort. If he had been me, who was pathologically afraid of incurring transaction fees, perhaps Johnny would have stubbornly held until the end of the contest. However, Johnny was Johnny, and he ended up selling all the way up to 5%, netting a handsome profit for Zubby. (The debt limit market later peaked all the way up at 10.8%, not counting Greg’s folly, due to <em>other</em> people selling out later.)</p>

<p>Of course, in some circumstances the actions of other players <em>are</em> predictable, but only due to structural factors that make the patterns impossible to exploit, such as the resolution rush.</p>

<h1 id="10-there-is-a-rush-after-market-resolution">10. There is a rush after market resolution</h1>

<p>Whenever a market resolves, especially if multiple markets resolve at the same time, you could safely bet that there would be a surge of new market movements as people reinvested their winnings. In particular, I noticed that Mark (eighth place finisher) kept all his money invested all the time (unlike most other top players) and thus would predictably rush to make new bets whenever a market he was in resolved. It wasn’t just Mark though, there were a lot of low ranked players who would also quickly reinvest their winnings.</p>

<p>Unfortunately, it is difficult to predict <em>which</em> markets these people would bet on and <em>which</em> outcome they would bet on, and thus difficult to actually take advantage of this predictable phenomenon. Another difficulty is that the whole reason this phenomenon happens is due to capital constraints, and those same capital constraints would typically make it impossible to exploit for other people, who would likely have their money locked up in the same markets. The only way to actually take advantage of it is to be the first after resolution. Speaking of which, here’s another anecdote:</p>

<h3 id="the-trump-twitter-misplay">The Trump Twitter Misplay</h3>

<p>On May 31st, there were three different risk-free markets set to close at the end of the month, “Newsom to Run for President by Summer?”, “Will Russia Control Kherson on 5/31/23?”, and “Will Russia Control Kramatorsk on 5/31/23?”.</p>

<p>Near the end of the month, I had invested almost all my remaining money in these markets, to earn a bit of extra return. I only left $200 in cash, and then invested the final $200 on the night of the 31st (for a 2.5% return on Newsom, which was the highest of the three).</p>

<p>Following the end of May, I didn’t have any big plans or ideas for what to do next, but I was planning to put down $500 NO on Trump Twitter, which was at 42.5% at the time. I got greedy and thought that I could earn the extra 2.5% on Newsom <em>and</em> be the first person in on Trump Twitter following the resolution.</p>

<p>The three markets were set to <em>close</em> at midnight, but they don’t <em>resolve</em> automatically. Instead, they have to be manually resolved by someone at Salem, and it is difficult to predict exactly when that will happen, although it usually happens pretty fast (the end of February fiasco notwithstanding).</p>

<p>In this case, Newsom and Kherson resolved at 5:39am and 5:40am respectively, while Kramatorsk didn’t resolve until 7:39am on June <em>2nd</em>. I can’t imagine why that would happen, since whoever at Salem was doing the resolving would presumably want to resolve all three at the same time, but there were similar, but much smaller disparties in many other market resolutions.</p>

<p>I tend to have trouble sleeping and wake up briefly during the night a lot, and figured that I could check my phone for the resolution email whenever I woke up during the night, so that regardless of when it resolved, I’d be likely to see it early. As it turns out, I woke up (among other times) at 4:08am and couldn’t fall asleep again, and only went back to bed again at 5:31, and then woke up again at 5:37 (but took a long time to actually get up). Since the markets resolved at 5:39am, I managed to <em>just</em> miss the resolution during the one time I was asleep, and by the time I was able to buy my Trump Twitter shares, it was already down to 39.2%. Oh well, there was no way to know what would happen in advance, and the amounts involved were pretty trivial. It was still pretty frustrating though.</p>

<p>On the morning of July 27th, I actually <em>did</em> happen to be the first to wake up and see the market resolution (Q2 GDP), but I didn’t do anything because I figured (correctly as it turned out) that bets on the near-risk-free markets were pointless at that point because everything would come down to the Trump Indictment market and nothing else mattered. I did end up putting 4000 down on the near-risk-free markets later that morning anyway, after other people had woken up and bought them down, but it ultimately didn’t matter.</p>

<h1 id="11-ranking-changes-can-be-paradoxical">11. Ranking changes can be paradoxical</h1>

<p>In late January, out of curiosity, I calculated what the rankings would be under all possible outcomes for the upcoming Q4 GDP &gt;=1% and Biden Approval &gt;=42% markets (assuming that no further bets happened before resolution). Strangely, I discovered that while I was currently in 8th place, under all four possible scenarios, I would end up in 9th place, a result I dubbed “the paradox”.</p>

<p>It’s not hard to see why this could happen, but it is completely counter-intuitive, and I would have never thought of it before I happened to encounter it in person. This scenario can happen if two people below you have large <em>opposite</em> positions in a market.</p>

<p>For example, if a market is currently at 50%, and A holds $51 in cash while B holds 100 NO shares and C holds 100 YES shares, then A is in first place at current market prices, but no matter how the market resolves, either B or C will take first place. In this case, either Josiah Neeley or Krum-Dawg Millionaire (13th place finisher) would jump past me depending on the outcome of the Biden Approval market.</p>

<p>On the bright side, the same paradox can also happen in <em>reverse</em> if two people <em>above</em> you hold large anti-correlated positions. In early April, I noticed that David (fourth place finisher) and Mark, the two people just ahead of me in the rankings at the time, had opposite positions in the Chicago Mayor market. David had a huge YES bet, while I had a small YES bet and Mark had a medium NO bet, and thus no matter which way the market went, I would either finally reach 5th place or at least gain a lot of ground towards 5th.</p>

<h1 id="12-you-dont-have-to-outrun-the-bear">12. You don’t have to outrun the bear</h1>

<p>When you’re hidden among the teeming masses and the contest is young, trying to maximize your score is basically the same thing as maximizing your eventual rank. However, something funny happens when you reach the rarified top ranks and the end of the contest approaches. At the top levels, people tend to be farther apart, so you only have one or two people you’re in real competition with at any given time, and the <em>correlation</em> between your portfolios becomes just as important as the <em>expected</em> return.</p>

<p>In my case, the final five months of the competition was a story of increasingly competing with just one person at a time, and in many cases, jumping ahead of them thanks to their losses more than my own gains.</p>

<h3 id="rivals">Rivals</h3>

<p>At the start of March, I was in 7th place, but effectively in 6th place (Ben was just ahead of me in 6th, but he’d been inactive since early December and I knew I could pass him without trying - Ben eventually finished in 7th), and I was desperate to make it into the top 5. Ahead of me, my competition was Connor, David, and Mark in 3rd, 4th, and 5th place respectively. Zubby and Johnny were in 1st and 2nd, but they were so far ahead of me that I knew I had no chance of catching up with them. Meanwhile, 8th and below were fairly far behind me, so I didn’t have much to worry about behind me unless I lost a lot of money.</p>

<p>Therefore, in March and early April, I considered Connor, David, and Mark my “rivals” and cursed whenever they made a profit, as it put 5th place that much further out of my reach. Meanwhile, I didn’t mind at all when Zubby and Johnny rapidly jumped on every profit opportunity, since I had no chance of passing them anyway and it at least meant that Connor, David, and Mark weren’t getting that profit.</p>

<p>On April 4th, the night of the Chicago Mayor election, David self-immolated (due to his massive failed bet on Vallas) so I reached 5th place by default (though I <em>did</em> make a decent profit on the election through my own efforts, too). Furthermore, Connor stopped playing following the election, and once that became clear, I knew I would eventually pass him without much effort. This left Mark in 3rd place as my sole rival.</p>

<p>I even temporarily changed my name on Salem to “I’m coming for you, Mark”. On May 15th, following DeSantis’s candidacy announcement, I finally passed Mark, and thus set my sights on second place, Johnny, although he was far out of reach, and his lead soon got even more impossibly large following the debt ceiling debacle, where I took significant losses and Johnny had huge gains.</p>

<p>I knew it would take multiple miracles in a row to overtake Johnny and didn’t have any real hope, but I kept playing anyway, so that I’d be better positioned just in case the stars aligned.</p>

<p>Fortunately, the stars did align, and at the end of June, following the Supreme Court announcements, I made a huge profit and closed most of the gap, so that I could plausibly overtake Johnny if I just got lucky a few more times. Meanwhile, Mark self-immolated. I was already far ahead of Mark anyway, but it meant that I was even more secure in 3rd place, as that left just the inactive Connor behind me. As long as I bet conservatively enough to leave more cash than Connor in the event of a loss, I was basically guaranteed to at least get third place, so the only question left was whether I would somehow manage to overtake Johnny and get second instead.</p>

<p>For the final month of the contest, I played with a single-minded devotion towards overtaking Johnny, treating his losses as interchangeable with my profits, and vice versa. My strategy primarily revolved around looking at the few places where he had large bets I disagreed with, and betting the other way and hoping that the market would resolve in my favor rather than his (<em>and</em> that he wouldn’t sell his shares first).</p>

<p>In the particular case of the Q2 GDP market, I put a lot of effort into trying to discourage Johnny from selling his NO shares, hoping he would hold them to zero (as he ended up doing). And while I temporarily slipped ahead of him thanks to my win on GDP, what ultimately sealed his fate was his massive losses on the Trump Indictment market, which I had absolutely no control over. (I suspect that Johnny bet so heavily on the indictment market because he was in turn trying to overtake Zubby and reach first place.)</p>

<h1 id="13-always-read-the-fine-print-of-the-resolution-criteria">13. Always read the fine print of the resolution criteria</h1>

<p>Two of the markets on Salem ended up revolving around a very different question than the one suggested by the title of the market. Ironically, I made huge gains in the first one, and took heavy losses in the second.</p>

<h3 id="china-reaches-100000-covid-cases-by-winter">China Reaches 100,000 Covid Cases by Winter?</h3>

<p>The first of these was titled “China Reaches 100,000 Covid Cases by Winter?”. The resolution criteria read as follows:</p>

<blockquote>
  <p>This market resolves as YES if China reports a 7-day rolling average of at least 100,000 covid-19 cases at any point between the opening of the market and February 28, 2023. Source for settling the market will be Our World in Data at the link below.</p>

  <p><a href="https://ourworldindata.org/explorers/coronavirus-data-explorer">https://ourworldindata.org/explorers/coronavirus-data-explorer</a></p>

  <p>Should that source be unavailable, a suitable alternative will be found.</p>
</blockquote>

<p>In early December, China ended its “zero COVID” policies and instead let COVID spread unchecked through the population. However, they <em>also</em> revised their testing criteria, and continued to report very low case numbers, even as COVID ravaged the country.</p>

<p>On December 17th, Salem posted an update to confirm that the market would resolve based on reported COVID numbers, rather than whether China <em>actually</em> had a surge of COVID cases.</p>

<blockquote>
  <p>This market was never meant to estimate the true number of cases in China, but was always to be based on government reports. Thus, any alternative source to Our World in Data will have to rely on official numbers to be used. If at some point China stops reporting data completely, this market will resolve as NO as long as there was never 100,000 cases reported for any 7-day rolling average.</p>
</blockquote>

<p>By early January, the December wave was over and China was still reporting low case numbers, so the market seemed pretty safe. The only risk was that the Salem Center would somehow be persuaded by the brigaders to resolve the market YES, even though by all rights it should be NO. Oh, did I mention the brigading?</p>

<p>Back in November, a player named Andy Martin had been betting heavily YES, hoping that the <em>November</em> wave (before China lifted Zero Covid) would break 100k. As it turns out, Andy Martin was also active on Manifold Markets (the sister site that the Salem contest was forked from) and created a prediction market <em>on Manifold</em> with the same title and with resolution criteria saying that it would resolve to match the resolution of the corresponding market in the Salem contest.</p>

<p>A lot of players on Manifold bet on Andy’s market based on the title, assuming it was an obvious YES, and got furious when it became clear that the resolution of the Salem market (and by extension the Manifold market) would be based on reported case numbers rather than actual cases.</p>

<p>One of these people, Patrick Delaney, went so far as to <em>sign up for the Salem contest for the sole purpose of trying to persuade the Salem Center to resolve the market YES</em> so he would win imaginary money on the <em>Manifold</em> site. He spent the next two months endlessly commenting on the Salem China COVID market, arguing, insulting, wheedling, and throwing out any argument he thought might stick. He was quite persistent at it, and the China COVID market ended with <strong>340</strong> comments, far more than any other market on Salem. (To be fair, many of those came from Iraklis and other legitimate players on Salem as well.)</p>

<p>In mid January, China stopped reporting COVID cases entirely, causing me to get more worried about the market again. One line of argument from the YES side was that this meant that the source was “unavailable” as per the resolution criteria and thus “a suitable alternative” should be used. In my opinion, this was nonsense since the listed source (Our World In Data) was still up and still showing numbers, it just showed zeros for recent days, but there was a chance Salem might be persuaded anyway.</p>

<p>Then at the <em>end</em> of January, the market suddenly got completely upended <em>again</em>. Our World in Data (the source used for resolution) in turn sourced its data from a repository maintained by John Hopkins. On February 1st, <a href="https://github.com/CSSEGISandData/COVID-19/issues/6543">they announced on Github</a> that they would be working to integrate the WHO data (which had vastly higher case counts) into their repository, apparently retroactively.</p>

<p>At that point, I assumed I was certain to lose and turned off all notifications and stopped checking Salem entirely for the month of February. As it turned out, the market continued to swing <em>wildly</em> up and down over the course of February, before ultimately resolving NO. It’s hard to tell exactly what happened, but as far as I can tell, what happened is this:</p>

<ul>
  <li>John Hopkins decides that they are unable to integrate the WHO case data after all because it doesn’t break out Hong Kong and Taiwan from the mainland.</li>
  <li>Our World in Data announces that they’ll stop using John Hopkins and switch to using the WHO data directly, and that this change will be retroactive.</li>
  <li>However, the OWID switch to WHO data is scheduled for March 8th, after the end of the market.</li>
  <li>At the end of February, the <em>graph</em> on the OWID site still showed the John Hopkins numbers, but the <em>spreadsheet download link</em> already showed the WHO data, and it was unclear which would be used for resolution.</li>
</ul>

<p>In any case, this market was an utter disaster, and the outcome ended up being a coin-flip completely divorced from any sort of predictable reality.</p>

<p>Incidentally, Andy Martin ended up resolving the linked Manifold market as “N/A” rather than “NO” as he felt that the NO resolution on Salem was unfair.</p>

<h3 id="us-debt-limit-raised">US Debt Limit Raised?</h3>

<p>The other disaster market was simply titled “US Debt Limit Raised?”. The resolution criteria read</p>

<blockquote>
  <p>This market will settle as YES if Congresses[sic] passes a bill that the president signs that raises the US debt limit by July 31, 2023. If the president vetoes the bill, and his veto is overturned on such a bill, the market will still settle YES.</p>
</blockquote>

<p>On January 26th, Zubby commented, asking “Would a bill suspending the debt limit count? Does minting the coin count?”, to which the Salem Center responded “No”. However, I didn’t appreciate the significance of this comment at the time and unfortunately forgot about it.</p>

<p>Throughout March, April, and May, the market price slowly rose, reaching a peak of 93% on May 28th (which is unfortunately when I bought in). Then overnight, it suddenly tanked.</p>

<p>It turns out my mistake was in naively assuming that the market was <em>asking a meaningful question</em> (as well as relying on the belief implied by the market price that everyone else was assuming the same thing.) Throughout the spring, the one question on everyone’s minds in the US was whether congressional Republicans would reach a deal with Democrats to avert the debt ceiling crisis, and it was natural to assume that that was what the market was trying to measure.</p>

<p>However, this turned out to not be the case. Despite congress reaching a debt ceiling deal in the end, the market resolved <em>NO</em> on a stupid technicality - the deal <em>suspended</em> the debt ceiling rather than <em>raising</em> it. Instead of trying to measure the <em>actually important</em> question that was on everyone’s minds, the market secretly revolved around a stupid question that noone cared about, “which <em>color</em> will the resulting bill be painted?”.</p>

<p>I suppose the best that can be said is that I was evidently in good company misinterpreting the market. <em>Most</em> of the debt ceiling deals over the last decade involved suspending the debt ceiling rather than raising it, so just on the basis of historical data, the YES probability should have been really low. The fact that it got up to 93% implies that everyone else <em>also</em> misinterpreted the market and assumed it was about the actually interesting question, not a stupid gotcha.</p>

<p>In fact, <em>Richard Hanania</em> himself, the <em>founder</em> of the contest, was fooled by this market as well. <a href="https://www.cspicenter.com/p/new-5000-prize-in-the-salem-centercspi">On February 15th, he wrote</a></p>

<blockquote>
  <p>The debt limit standoff is one of the main issues in Washington, with both sides seemingly unwilling to compromise. The market seems optimistic about finding a solution, with 77% thinking that the debt ceiling will be raised by the end of July.</p>
</blockquote>

<p>Obviously, that is not the way one would write if one understood that the market was actually supposed to predict a dumb gotcha rather than “the main issues in Washington”.</p>

<h1 id="14-the-markets-started-highly-inefficient-but-got-a-lot-more-efficient-towards-the-end">14. The markets started highly inefficient, but got a lot more efficient towards the end</h1>

<p>Every once in a while, someone would make a really large dumb bet, and the first person who happened to see it (usually Johnny) could profit enormously by trading against it.</p>

<p>By pure chance, I decided to check Salem while on Christmas vacation, at 6:40am on December 28th. Coincidentally, at 6:08am, Dylan Levi King (a high ranked player at the time) had bought China COVID from 23.0% up to 61.3%. Johnny jumped in at 6:15am, seven minutes later, and bought it back down to 53.9%, but that meant it was still pretty high when I happened to see it half an hour later, and I was still able to make some profit buying it myself.</p>

<p>In early January, I tried to make lightning strike twice by placing limit orders on many markets at way above or below the market price, in hopes of profiting if someone like Dylan Levi King went crazy again. Unfortunately, this proved to mostly be ineffective or counter productive (as you lose money if a market suddenly changes for legitimate reasons), so I stopped doing it.</p>

<p>Instead, I checked Salem several times a day, particularly in the morning and evening, in the hopes of happening to be the first person to see a major market movement, and continued doing the same after I returned in March, though my efforts yielded little.</p>

<p>On March 28th, at 10:22:49, someone named Alec Cenci suddenly tanked “Will Donald Trump Be Indicted for a Crime by July 2023?” from 72.3% down to 28.5%. At 10:26:57, just four minutes later, Zubby bought it back up. Zubby’s reaction was so fast that I thought he might have had a bot, but he said that he just got lucky and happened to be on at the right time.</p>

<p>Throughout March, I noticed that Zubby tended to be the first to react to major market movements, and Johnny always jumped in afterward, and hence got the worse prices after Zubby had already taken most of the profit. I even mentally nicknamed him “Johnny come lately”. However, this pattern reversed in April, with Johnny being all over the markets and Zubby nowhere in sight.</p>

<h3 id="the-bot-wars">The bot wars</h3>

<p>On March 30th, Johnny responded to my question about Zubby’s four minute trade saying that <em>he</em> actually <em>did</em> have a bot to notify him of sudden market movements (given the advantage of his bot, it’s unclear why he was still slower than Zubby in March).</p>

<p>I decided that I needed to create a bot of my own so I wouldn’t be fighting with one hand tied behind my back. However, I procrastinated on it for three weeks and only finished the bot in late April, and my bot didn’t work very well anyway.</p>

<p>I set up a Python script on my desktop to fetch the market data from Salem every 15 seconds, and then email me via the Gmail API whenever a market moved more than 7% in a 15 minute period. Unfortunately, I never found a way to get the Gmail app on my phone to notify me, so it was hard to actually <em>see</em> the emails. In fact, I never managed to get Gmail to even mark the bot emails as <em>important</em>, even when I <em>specifically created a Gmail filter to mark them as important</em>. Additionally, for some bizarre reason, Google forcibly expires app tokens every 7 days, forcing you to manually delete the token and reauthenticate (which involves clicking through the scary warnings in the browser), with no way around this, and occasionally I would forget to regenerate the token, leaving the bot temporarily unable to send emails.</p>

<p>I was originally hoping to have my bot send an SMS message, which I would definitely be able to notice regardless of the time of day or location, but unfortunately, I never managed to find an SMS api that actually worked. Twilio is basically the only game in town, and for some reason, they immediately blocked my account on signup with no explanation. It sounds like nowadays only businesses can use Twilio, but they aren’t nice enough to actually tell you this. I also tried every other SMS api provider I could find (such as Vonage), but none of them worked.</p>

<p>The end result was that while I did have a bot to notify me of market movements, it relied on me happening to be on the computer at the time and happening to notice the new email in Gmail, so it would only occasionally even be possible for me to see the email, and even under ideal circumstances, it would take me minutes to notice it.</p>

<p>On April 19th, someone bought the Russia Donbas market from 15% up to 29%, and it stayed that way for <em>ten hours</em> before Johnny bought it. Once I finally got my bot working, there were one or two cases when I managed small wins like that, and it wasn’t clear to me why. I theorized that Johnny had his bot set to a higher threshold and just wouldn’t notice relatively small market spikes like that.</p>

<h3 id="the-josiah-neeley-incident">The Josiah Neeley incident</h3>

<p>Unfortunately, Johnny was still the fastest and most consistent when it actually mattered.</p>

<p>On April 27th, at 9:21:53, Josiah Neeley, then one of the high-ranked players, went crazy and put all his money on <em>YES</em> on “Newsom to Run for President by Summer?”, spiking it from 7.53% to 67.34%. (Josiah had just lost half his money gambling on the GDP market, and presumably decided that he had no chance playing normally and might as well YOLO it all on an extreme longshot bet. Incidentally, Johnny was <em>also</em> the one to trade against Josiah’s wild GDP bets the previous night, but I didn’t begrudge him that, because the GDP market was legitimately risky, and I would have stayed away out of uncertainty even if I <em>had</em> been the first to see those trades.)</p>

<p>At 9:34:55, thirteen minutes later, Johnny jumped in and bought it back down, making a massive profit, likely the biggest of the whole contest. This was shortly after I had finally got my bot working, and I was absolutely furious when I found out. By all rights, that should have been <em>my</em> windfall. If only I had managed to find a working SMS provider, I could have easily gotten the phone notification and bought the spike in under 13 minutes. It especially stung because for the last month, I’d been the main one participating in the Newsom market. The GDP market, I didn’t mind, but Newsom was <em>my</em> domain.</p>

<h3 id="zubby-strikes-back">Zubby strikes back</h3>

<p>On May 16th, at 12:19:41, a nobody suddenly bought “Biden the Favorite in Summer 2023?” from 85.6% down to 62.9%. At 12:20:05, just <em>24 seconds later</em>, Zubby bought it back up, and then at 12:21:29, Johnny Come Lately stepped in to pick up the dregs, presumably greatly disappointed.</p>

<p>Surprised at the quick reactions, I commented on the market, and they responded:</p>

<blockquote>
  <p>Johnny: Well I have a script that polls for market changes once a minute and happened to be at my computer anyway. Still I frankly felt quite good about how quick I was. Until I looked at the actual seconds via the API: My 107 second reaction time got easily outclassed by zubby’s 24 seconds.</p>
</blockquote>

<blockquote>
  <p>Zubby: A couple months ago I saw J10 aka The Goat clearly had some sort of monitor running and I decided I needed to do the same. I was on a golf course when Josiah Neeley decided to rage quit in the Newsom market, which is why I was extra mad!</p>
</blockquote>

<p>This was doubly unfortunate news because it showed that both a) Zubby had a bot too and b) Zubby and Johnny were fast enough that I wouldn’t be able to profit off any spikes that came up <em>even if the stars aligned and I happened to see the bot email at the right time</em>. Previously, Johnny had typically been taking 7-15 minutes to jump on these things, which was plenty of time if I got lucky with the bot email, but at only one minute, I would have no chance even if I <em>did</em> get the bot email.</p>

<h3 id="a-new-hope">A new hope</h3>

<p>On May 28th, at 15:56:46, Dylan Levi King tanked the Trump Indictment market (48.2%-&gt;24.7%). This time I happened to be on the computer at the time and happened to be the first to see the email, but I quickly checked Google to see if there were any news stories that would justify the drop before I invested. While I was still researching it, Zubby bought it back up at 15:58:52. In retrospect, I should have just speculatively put a small amount in <em>before</em> researching it.</p>

<p>On June 23rd at 21:08:42, a nobody (Guangyu Song) bought up Russia-Ukraine Ceasefire 12.3-&gt;62.5%. Amazingly, this time I somehow managed to beat Johnny to the punch and bought it back down with a speculative $100 NO at 21:11:27 (remembering the Zubby incident) followed by $1000 NO at 21:13:20 once I’d checked the news, and then another $400 NO at 21:22:37 because for some reason, Johnny <em>still</em> hadn’t jumped in.</p>

<p>For some bizarre reason, Johnny didn’t show up until 03:24:55, over <em>six hours</em> later. Presumably, he just didn’t get the bot notification for whatever reason. Previously I’d thought that it was due to his bot threshold being too high, but this jump was big enough to trigger any plausible threshold. Maybe Johnny was just asleep at the time. On the other hand, Johnny had a limit order which triggered in this case, so he got part of the profit without being awake.</p>

<p>Johnny was still <em>massively</em> ahead of me, but this incident did at least reduce the gap a bit and gave me the hope that perhaps I could reap similar windfalls in the future. Sadly, it was never repeated, and for the rest of the contest, Johnny and Zubby were very fast at grabbing these things.</p>

<h3 id="salem-plus">Salem Plus</h3>

<p>In January and March, I checked Salem several times a day, but this was suboptimal because the website takes a long time to load and the UI makes it hard to see relevant changes. In early June, I wrote a very barebones HTML + JS site that I dubbed <a href="https://storyyeller.github.io/salemplus/">Salem Plus</a>.</p>

<p>Salem Plus loads the market data from the main Salem site (using the API), but displays it in a much more convenient view. Specifically, it shows the ten most recent bets for each market in a flat single page view, with the markets sorted top to bottom in order of the most recent bet. This allows you to quickly see all recent activity, something that would require painstakingly clicking through to the bet history for every individual market on the real Salem website. Additionally, Salem Plus displays the exact market prices rather than rounding to the nearest percent like Salem does, and it probably loads faster as well.</p>

<p>This wasn’t the original purpose of Salem Plus. My original plan was to take all the Python scripts I had built and rewrite them in Javascript and embed them in a custom website so I could use them while on vacation when I didn’t have access to my normal computer. However, I never got around to actually doing that. I just wrote a very barebones read-only page to display market data and didn’t bother to do any of the rest.</p>

<p>Even this proof of concept though turned out to be really useful, as I was able to check it periodically to keep abreast of activity in the markets. Initially, I would just check it several times a day, but near the end of the contest, I started checking it much more frequently, refreshing it every 10-40 minutes throughout the day, depending on how bored I was at the time. I’d pretty much given up on my email bot, but figured that if I checked Salem Plus frequently enough, I would still have good odds at seeing any opportunities that came up anyway.</p>

<h3 id="the-final-week">The final week</h3>

<p>On July 24th, Monday of the final week of the competition, all eyes were on the “Third Trump Indictment?” market, the only market left with any real uncertainty. At 14:19:57, PPPP bought it up (54.2-&gt;63.8%) and Johnny and Zubby immediately bought it back down at 14:21:35 and 14:21:41 respectively, less than two minutes later. (I was sitting that market out due to uncertainty and wouldn’t have bet against PPPP even if I had been the fastest.) However, the most impressive part was yet to come.</p>

<p>At 14:53:06, DfromBham (19th place finisher) suddenly bought Trump Indictment up from 54.3% to 70.9%. Somehow, Zubby bought it back down just <em>22 seconds later</em> at 14:53:28. I couldn’t believe it and left a comment to ask Zubby how he managed to do it. He responded “Just running a page monitor and was at my computer.”</p>

<p>Inspired by Zubby’s comment, I modified Salem Plus the following morning to refresh every 15 seconds in the background, and left it open in the corner of my computer all the time, hoping that market movements would catch my eye.</p>

<p>Following the resolution of the Trump Indictment market Thursday afternoon, the competition was effectively over, but I knew there was still a slight chance of someone pulling a Josiah Neeley and feeding Johnny enough for him to overtake me, so I kept an eye on the markets just in case, albeit nowhere near as intensely or consistently as I had been doing earlier in the week.</p>

<p>As it turned out, there were two final mini-spikes the following day. One happened overnight (03:58:52), and Johnny got it (04:01:39, less than two minutes later). The other, larger, spike happened in the afternoon, when Greg Simitian, a new player, put his entire starting $1000 on YES on Debt Ceiling.</p>

<p>Greg did this as 100 individual bets of $10 each, from 14:41:53 to 14:42:42, so it’s hard to know which starting point to measure the reaction time from, but in any case, Zubby got it extremely quickly at 14:43:05. Oddly, Zubby only bought it partway back down, so once I got back to the computer and noticed at 14:46:51 (I’d been eating at the time), I put in a bunch of money myself, figuring that if I didn’t, Johnny would. However, Johnny never bothered with the market, even after <em>commenting</em> on it later on. In fact, his very last bet of the contest (prior to the very end) was at 04:02:55 when he bought the first spike. Presumably he just gave up after that, though he did still go to the trouble of investing his excess cash five minutes before the contest ended.</p>

<h1 id="15-luck-is-important-too">15. Luck is important, too</h1>

<p>When the contest was first announced, many people worried that the winner would just be someone who went all in on an unlikely bet and happened to win big. Fortunately, the contest was long enough that that didn’t happen. All the top players were people who were able to consistently win many bets.</p>

<p>That being said, luck was still important. In my case, there were two points (the November Midterms and China COVID) where I had most of my money on a bet that I didn’t think would actually pay off, and in both cases, I fortunately managed to win anyway. In the second case, I thought it would take a <em>miracle</em> for the market to go my way, and even stopped playing and stayed away from Salem entirely for a month while I waited to find out what happened.</p>

<p>Of course, it’s important not to overstate this. The “miracle” took me from 9th place to 7th place, while I finished the contest in second place, so it clearly wasn’t just a matter of getting lucky twice. But I do think that in order to win the contest, you have to have good strategy and put in hard work <em>and</em> also get very lucky as well.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this part, I covered the main lessons I learned while participating in the Salem prediction market tournament for the last year. In the <a href="/2023/08/28/how-i-came-second-out-of-999-in-the-salem-center-prediction-market-tournament-without-knowing-anything-about-prediction-markets-and-what-i-learned-along-the-way-part-2.html">next part</a>, we’ll go through a detailed <em>chronological</em> account of the tournament, seeing how it unfolded and how my strategy changed over time, and the ups and downs along the way. (Fortunately with a lot more ups than downs!)</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Tokio, FuturesUnordered, and the Thundering Herd Problem</title><link href="/2023/05/15/tokio-futuresunordered-and-the-thundering-herd-problem.html" rel="alternate" type="text/html" title="Tokio, FuturesUnordered, and the Thundering Herd Problem" /><published>2023-05-15T02:08:00+00:00</published><updated>2023-05-15T02:08:00+00:00</updated><id>/2023/05/15/tokio-futuresunordered-and-the-thundering-herd-problem</id><content type="html" xml:base="/2023/05/15/tokio-futuresunordered-and-the-thundering-herd-problem.html"><![CDATA[<p>I work on a team that runs a Rust service using Tokio in production. I’ve been coding Rust for many years, have written or rewritten most of our code, <a href="https://blog.polybdenum.com/2022/07/24/fixing-the-next-thousand-deadlocks-why-buffered-streams-are-broken-and-how-to-make-them-safer.html">have been burned</a> by many of the rough edges of async Rust, and have even written a presentation to introduce async Rust to new people, so I consider myself pretty knowledgeable about the topic. Nevertheless, I ran into a surprising async bug this week. Here is my story:</p>

<h2 id="background">Background</h2>

<p>In the relevant part of the code, we have an <code class="language-plaintext highlighter-rouge">async</code> function, here called <code class="language-plaintext highlighter-rouge">process</code>, which we want to potentially run on multiple items concurrently. This is a very simplified version of our actual code, and all the names have been changed, but here’s an example which demonstrates the basic structure of the problem:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">Request</span> <span class="o">=</span> <span class="nb">u32</span><span class="p">;</span>
<span class="k">struct</span> <span class="n">Response</span><span class="p">;</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">check_cache</span><span class="p">(</span><span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span><span class="k">false</span><span class="p">}</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">prefetch_data</span><span class="p">(</span><span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="p">{}</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">perform_update</span><span class="p">(</span><span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="p">{}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">process</span><span class="p">(</span><span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Response</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} processing {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="k">if</span> <span class="nf">check_cache</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Response</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="nf">prefetch_data</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="nf">perform_update</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="n">Response</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In our actual code, we’re using a manual <code class="language-plaintext highlighter-rouge">FuturesUnordered</code> to run the futures so that we can dynamically add items based on external events, but for the sake of simplicity, we’ll just use <code class="language-plaintext highlighter-rouge">StreamExt.buffer_unordered</code>, (which uses <code class="language-plaintext highlighter-rouge">FuturesUnordered</code> under the hood) with a fixed list of items in our example code to demonstrate the same issue. We can just create a list of items, put it into a stream, and run them concurrently:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[tokio::main]</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nn">stream</span><span class="p">::</span><span class="nf">iter</span><span class="p">((</span><span class="mi">0</span><span class="o">..</span><span class="mi">10</span><span class="p">))</span><span class="nf">.map</span><span class="p">(|</span><span class="n">i</span><span class="p">|</span> <span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
        <span class="nf">process</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="k">.await</span>
    <span class="p">})</span><span class="nf">.buffer_unordered</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This results in something like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>420ns processing 0
13.545µs processing 1
18.035µs processing 2
21.564µs processing 3
25.035µs processing 4
29.47µs processing 5
35.005µs processing 6
39.047µs processing 7
42.92µs processing 8
46.921µs processing 9
</code></pre></div></div>

<p>Thanks to <a href="https://github.com/rust-lang/rust/issues/102211">a longstanding Rust compiler bug</a>, one of our dependencies is incorrectly inferred to be non-<code class="language-plaintext highlighter-rouge">Send</code>, and thus we unfortunately have to run everything in the top level task (using <code class="language-plaintext highlighter-rouge">runtime.block_on</code>) and we can’t actually spawn the futures to run them in parallel. However, running everything within a single task is almost as good, since it still lets us execute different futures while they’re blocked on external calls.</p>

<h2 id="the-change">The change</h2>

<p>In order to future-proof the code (no pun intended), we recently decided to modify it to add support for running on multiple servers, and that meant integrating a distributed locking service. Our distributed locks have an API that looks somewhat like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">DistributedLock</span><span class="p">;</span>
<span class="k">impl</span> <span class="n">DistributedLock</span> <span class="p">{</span>
    <span class="k">async</span> <span class="k">fn</span> <span class="nf">release</span><span class="p">(</span><span class="k">self</span><span class="p">)</span> <span class="p">{}</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">DistributedLockManager</span><span class="p">;</span>
<span class="k">impl</span> <span class="n">DistributedLockManager</span> <span class="p">{</span>
    <span class="k">async</span> <span class="k">fn</span> <span class="nf">try_acquire_distributed_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">DistributedLock</span><span class="p">,</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_millis</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="k">.await</span><span class="p">;</span>
        <span class="nf">Ok</span><span class="p">(</span><span class="n">DistributedLock</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In order to acquire the locks, I wrote a helper method somewhat like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">try_lock</span><span class="p">(</span><span class="n">lock_manager</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RefCell</span><span class="o">&lt;</span><span class="n">DistributedLockManager</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="n">DistributedLock</span><span class="p">,</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} acquiring refcell {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">guard</span> <span class="o">=</span> <span class="n">lock_manager</span><span class="nf">.try_borrow_mut</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} acquired refcell {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">lock</span> <span class="o">=</span> <span class="n">guard</span><span class="nf">.try_acquire_distributed_lock</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="o">?</span><span class="p">;</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} acquired lock {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="n">lock</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">acquire_lock</span><span class="p">(</span><span class="n">lock_manager</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RefCell</span><span class="o">&lt;</span><span class="n">DistributedLockManager</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">DistributedLock</span> <span class="p">{</span>
    <span class="k">loop</span> <span class="p">{</span>
        <span class="k">if</span> <span class="k">let</span> <span class="nf">Ok</span><span class="p">(</span><span class="n">lock</span><span class="p">)</span> <span class="o">=</span> <span class="nf">try_lock</span><span class="p">(</span><span class="n">lock_manager</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span><span class="k">.await</span> <span class="p">{</span>
            <span class="k">return</span> <span class="n">lock</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} Failed to acquire lock {}, sleeping for 10 seconds"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_secs</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="k">.await</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We can then modify <code class="language-plaintext highlighter-rouge">process</code> to acquire the locks before <code class="language-plaintext highlighter-rouge">perform_update</code> like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">process2</span><span class="p">(</span><span class="n">lock_manager</span><span class="p">:</span> <span class="nb">Rc</span><span class="o">&lt;</span><span class="n">RefCell</span><span class="o">&lt;</span><span class="n">DistributedLockManager</span><span class="o">&gt;&gt;</span><span class="p">,</span> <span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Response</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} processing {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="k">if</span> <span class="nf">check_cache</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Response</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="nf">prefetch_data</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">lock</span> <span class="o">=</span> <span class="nf">acquire_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock_manager</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="nf">perform_update</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="n">lock</span><span class="nf">.release</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    <span class="n">Response</span>
<span class="p">}</span>
</code></pre></div></div>

<p>and call it like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[tokio::main]</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">lock_manager</span> <span class="o">=</span> <span class="nn">Rc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">RefCell</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">DistributedLockManager</span><span class="p">));</span>
    <span class="k">let</span> <span class="n">lock_manager</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">lock_manager</span><span class="p">;</span>
    <span class="nn">stream</span><span class="p">::</span><span class="nf">iter</span><span class="p">((</span><span class="mi">0</span><span class="o">..</span><span class="mi">10</span><span class="p">))</span><span class="nf">.map</span><span class="p">(|</span><span class="n">i</span><span class="p">|</span> <span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
        <span class="nf">process2</span><span class="p">(</span><span class="n">lock_manager</span><span class="nf">.clone</span><span class="p">(),</span> <span class="n">i</span><span class="p">)</span><span class="k">.await</span>
    <span class="p">})</span><span class="nf">.buffer_unordered</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="py">.collect</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="the-problem">The problem</h2>

<p>If we fail to acquire the distributed lock (because the other server is currently holding it), we just try again in 10 seconds in a loop until we successfully acquire it. However, that isn’t the only way that <code class="language-plaintext highlighter-rouge">try_lock</code> can fail.</p>

<p>In order to share the <code class="language-plaintext highlighter-rouge">DistributedLockManager</code> between different futures, I passed it around as <code class="language-plaintext highlighter-rouge">Rc&lt;RefCell&lt;DistributedLockManager&gt;&gt;</code>. (Remember, <code class="language-plaintext highlighter-rouge">rustc</code> won’t let us mark the futures as <code class="language-plaintext highlighter-rouge">Send</code> anyway, so we might as well use <code class="language-plaintext highlighter-rouge">Rc</code>s, although this isn’t actually relevant to the problem I encountered - the same thing would have happened with <code class="language-plaintext highlighter-rouge">Arc&lt;Mutex&gt;</code>.) In order to call <code class="language-plaintext highlighter-rouge">try_lock</code> on the <code class="language-plaintext highlighter-rouge">lock_manager</code>, we first call <code class="language-plaintext highlighter-rouge">try_borrow_mut</code> on the <code class="language-plaintext highlighter-rouge">RefCell</code>, and fail if the RefCell is currently locked by another future.</p>

<p>Since we only hold the RefCell guard while calling <code class="language-plaintext highlighter-rouge">DistributedLockManager.try_acquire_distributed_lock()</code> (<em>not</em> while the <code class="language-plaintext highlighter-rouge">DistributedLock</code> itself is locked), and <code class="language-plaintext highlighter-rouge">try_acquire_distributed_lock()</code> is a fast operation, I didn’t expect the service to ever actually run into this condition, or maybe only once in a blue moon, and retrying in 10 seconds in very rare cases didn’t seem like a big deal.</p>

<p>Unfortunately, when my teammate tried manually running the code in order to test it prior to deployment, that isn’t what he saw. He saw it <em>consistently</em> and <em>repeatedly</em> failing to acquire the RefCell. If we run the example code I posted above, the same thing happens:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>438ns processing 0
11.35µs acquiring refcell 0
15.094µs acquired refcell 0
39.697µs processing 1
45.448µs acquiring refcell 1
50.752µs Failed to acquire lock 1, sleeping for 10 seconds
63.077µs processing 2
68.691µs acquiring refcell 2
71.925µs Failed to acquire lock 2, sleeping for 10 seconds
80.604µs processing 3
83.168µs acquiring refcell 3
87.124µs Failed to acquire lock 3, sleeping for 10 seconds
96.29µs processing 4
101.317µs acquiring refcell 4
105.712µs Failed to acquire lock 4, sleeping for 10 seconds
11.191669ms acquired lock 0
11.213052ms processing 5
11.216226ms acquiring refcell 5
11.219453ms acquired refcell 5
22.408349ms acquired lock 5
22.426989ms processing 6
22.430546ms acquiring refcell 6
22.432778ms acquired refcell 6
33.629489ms acquired lock 6
33.648115ms processing 7
33.651487ms acquiring refcell 7
33.653694ms acquired refcell 7
44.797188ms acquired lock 7
44.820335ms processing 8
44.82391ms acquiring refcell 8
44.827705ms acquired refcell 8
56.021801ms acquired lock 8
56.040478ms processing 9
56.043843ms acquiring refcell 9
56.046066ms acquired refcell 9
67.349157ms acquired lock 9
10.001591963s acquiring refcell 1
10.001607538s acquired refcell 1
10.001629928s acquiring refcell 2
10.001637161s Failed to acquire lock 2, sleeping for 10 seconds
10.001647381s acquiring refcell 3
10.001651111s Failed to acquire lock 3, sleeping for 10 seconds
10.001664599s acquiring refcell 4
10.001668651s Failed to acquire lock 4, sleeping for 10 seconds
10.012839752s acquired lock 1
20.003216329s acquiring refcell 2
20.003236367s acquired refcell 2
20.003268547s acquiring refcell 3
20.003278317s Failed to acquire lock 3, sleeping for 10 seconds
20.003299867s acquiring refcell 4
20.003305762s Failed to acquire lock 4, sleeping for 10 seconds
20.014485667s acquired lock 2
30.00398334s acquiring refcell 3
30.004018711s acquired refcell 3
30.004079751s acquiring refcell 4
30.004101231s Failed to acquire lock 4, sleeping for 10 seconds
30.015406338s acquired lock 3
40.004784703s acquiring refcell 4
40.004800233s acquired refcell 4
40.016003298s acquired lock 4
</code></pre></div></div>

<h2 id="what-happened">What happened?</h2>

<p>My reasoning <em>would</em> have been correct <em>if the futures were spawned</em> in separate tasks (yes Clippy, holding a guard across await is a legitimate use-case, even the Tokio docs say so, so please shut up). What I didn’t count on is that the nature of having multiple futures in the same task makes <em>any</em> await, even a fast one, problematic.</p>

<p>Here is our <code class="language-plaintext highlighter-rouge">process2</code> code again:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">fn</span> <span class="nf">process2</span><span class="p">(</span><span class="n">lock_manager</span><span class="p">:</span> <span class="nb">Rc</span><span class="o">&lt;</span><span class="n">RefCell</span><span class="o">&lt;</span><span class="n">DistributedLockManager</span><span class="o">&gt;&gt;</span><span class="p">,</span> <span class="n">req</span><span class="p">:</span> <span class="n">Request</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Response</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} processing {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">req</span><span class="p">);</span>
    <span class="k">if</span> <span class="nf">check_cache</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Response</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="nf">prefetch_data</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">lock</span> <span class="o">=</span> <span class="nf">acquire_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock_manager</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="nf">perform_update</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
    <span class="n">lock</span><span class="nf">.release</span><span class="p">()</span><span class="k">.await</span><span class="p">;</span>
    <span class="n">Response</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Under normal circumstances, we would almost never get to the <code class="language-plaintext highlighter-rouge">acquire_lock</code> step in the first place, because <code class="language-plaintext highlighter-rouge">check_cache</code> will nearly always return true. Additionally, the <code class="language-plaintext highlighter-rouge">check_cache</code> step would block on network calls for a semi-random amount of time, so multiple futures would not reach the main body at the same time. However, while testing the code, my teammate ran with the <code class="language-plaintext highlighter-rouge">check_cache</code> step disabled. Furthermore, the <code class="language-plaintext highlighter-rouge">prefetch_data</code> step caches data on disk (using <em>synchronous</em> file operations due to API limitations) and only <code class="language-plaintext highlighter-rouge">await</code>s if the data is not already present.</p>

<p>Since nothing in the function actually blocked on external operations, this meant that when executing the future, it would <em>immediately</em> go straight to the <code class="language-plaintext highlighter-rouge">acquire_lock</code> step without any intermediate <code class="language-plaintext highlighter-rouge">await</code>s. Then it would lock the <code class="language-plaintext highlighter-rouge">RefCell</code> and call <code class="language-plaintext highlighter-rouge">try_acquire_distributed_lock</code>. Since the distributed locking system <em>wasn’t</em> mocked out, this actually <em>did</em> block. Although the distributed locking operation is fast, it isn’t instant, and that gave <code class="language-plaintext highlighter-rouge">FuturesUnordered</code> the opportunity to try polling the <em>other</em> futures it was managing <em>while the RefCell was still locked</em>.</p>

<p>When the <em>second</em> future is polled, it again immediately goes to the <code class="language-plaintext highlighter-rouge">acquire_lock</code> step, but this time, it fails to lock the <code class="language-plaintext highlighter-rouge">RefCell</code> because the <code class="language-plaintext highlighter-rouge">RefCell</code> is still being held by the first future, so it sleeps for 10 seconds before trying again. This then happens to <em>every</em> other future in the <code class="language-plaintext highlighter-rouge">FuturesUnordered</code> pool as well. No matter how many futures are in the pool only the first one will actually run successfully. Even worse, the failed futures all sleep for exactly 10 seconds, so when they wake up, <em>the same thing happens again</em>.</p>

<p>Here is the output from our example program again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>438ns processing 0
11.35µs acquiring refcell 0
15.094µs acquired refcell 0
39.697µs processing 1
45.448µs acquiring refcell 1
50.752µs Failed to acquire lock 1, sleeping for 10 seconds
63.077µs processing 2
68.691µs acquiring refcell 2
71.925µs Failed to acquire lock 2, sleeping for 10 seconds
80.604µs processing 3
83.168µs acquiring refcell 3
87.124µs Failed to acquire lock 3, sleeping for 10 seconds
96.29µs processing 4
101.317µs acquiring refcell 4
105.712µs Failed to acquire lock 4, sleeping for 10 seconds
11.191669ms acquired lock 0
11.213052ms processing 5
11.216226ms acquiring refcell 5
11.219453ms acquired refcell 5
22.408349ms acquired lock 5
22.426989ms processing 6
22.430546ms acquiring refcell 6
22.432778ms acquired refcell 6
33.629489ms acquired lock 6
33.648115ms processing 7
33.651487ms acquiring refcell 7
33.653694ms acquired refcell 7
44.797188ms acquired lock 7
44.820335ms processing 8
44.82391ms acquiring refcell 8
44.827705ms acquired refcell 8
56.021801ms acquired lock 8
56.040478ms processing 9
56.043843ms acquiring refcell 9
56.046066ms acquired refcell 9
67.349157ms acquired lock 9
10.001591963s acquiring refcell 1
10.001607538s acquired refcell 1
10.001629928s acquiring refcell 2
10.001637161s Failed to acquire lock 2, sleeping for 10 seconds
10.001647381s acquiring refcell 3
10.001651111s Failed to acquire lock 3, sleeping for 10 seconds
10.001664599s acquiring refcell 4
10.001668651s Failed to acquire lock 4, sleeping for 10 seconds
10.012839752s acquired lock 1
20.003216329s acquiring refcell 2
20.003236367s acquired refcell 2
20.003268547s acquiring refcell 3
20.003278317s Failed to acquire lock 3, sleeping for 10 seconds
20.003299867s acquiring refcell 4
20.003305762s Failed to acquire lock 4, sleeping for 10 seconds
20.014485667s acquired lock 2
30.00398334s acquiring refcell 3
30.004018711s acquired refcell 3
30.004079751s acquiring refcell 4
30.004101231s Failed to acquire lock 4, sleeping for 10 seconds
30.015406338s acquired lock 3
40.004784703s acquiring refcell 4
40.004800233s acquired refcell 4
40.016003298s acquired lock 4
</code></pre></div></div>

<p>Since we called <code class="language-plaintext highlighter-rouge">buffered_unordered(5)</code>, there are five futures in the <code class="language-plaintext highlighter-rouge">FuturesUnordered</code> pool. Notice that the first future (<code class="language-plaintext highlighter-rouge">0</code>) successfully runs, but the other four <code class="language-plaintext highlighter-rouge">1-4</code> all fail to acquire the lock and start sleeping. Then 10 seconds later, futures <code class="language-plaintext highlighter-rouge">1-4</code> wake up, future <code class="language-plaintext highlighter-rouge">1</code> successfully acquires the lock, and <code class="language-plaintext highlighter-rouge">2-4</code> all fail and start sleeping again. Then the next time, future <code class="language-plaintext highlighter-rouge">2</code> succeeds while <code class="language-plaintext highlighter-rouge">3</code> and <code class="language-plaintext highlighter-rouge">4</code> fail again, etc. It takes a total of five iterations before all the futures manage to run successfully.</p>

<p>In this toy example, it still doesn’t take that long to complete, and it is obvious from the logs that the number of failures is decreasing after each iteration. However, in our actual test code, we were running with <em>32</em> futures in the pool, and the sleep time increases after each failure, meaning that it would have taken effectively forever for everything to get unstuck.</p>

<h2 id="the-solution">The solution</h2>

<p>So what’s the solution? One obvious tactic is to <em>randomize</em> the amount of time each future sleeps. This is useful in some cases, and would have prevented the <em>repeated</em> failures, but it doesn’t stop all the futures from failing the <em>first</em> time.</p>

<p>Additionally, <strong>this problem is not specific to RefCell</strong>. We were using <code class="language-plaintext highlighter-rouge">Rc&lt;RefCell&gt;</code> because the compiler thought the code was not-<code class="language-plaintext highlighter-rouge">Send</code> anyway, so there was no reason not to. However, <em>the exact same thing</em> would have happened using <code class="language-plaintext highlighter-rouge">std::sync::Mutex</code>. Or rather, the same thing would have happened if you use <code class="language-plaintext highlighter-rouge">Mutex.try_lock</code>. If you use regular <code class="language-plaintext highlighter-rouge">Mutex.lock</code>, then instead of the pointless thrashing we got, you would instead get an outright <strong>deadlock</strong>.</p>

<p>The correct solution is to use <a href="https://docs.rs/tokio/latest/tokio/sync/struct.Mutex.html">Tokio’s Mutex type</a>, which has an <em>async</em> <code class="language-plaintext highlighter-rouge">lock()</code> method designed specifically for situations like this. Fortunately, it’s an easy fix, but the fact that this could happen at all was an unpleasant surprise.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Unlike most languages with <code class="language-plaintext highlighter-rouge">async</code>, Rust does not automatically spawn futures into separate tasks. Spawning everything vastly reduces the potential for bugs, but it comes at the cost of performance and flexibility, so Rust doesn’t do it by default. In our case, our code wouldn’t have even been possible at all without the ability to run non-spawned futures, since rustc incorrectly thinks the code is not <code class="language-plaintext highlighter-rouge">Send</code>.</p>

<p>While this ability is invaluable, <a href="https://blog.polybdenum.com/2022/07/24/fixing-the-next-thousand-deadlocks-why-buffered-streams-are-broken-and-how-to-make-them-safer.html">it is also <em>extremely</em> error-prone</a>. Even when you think you’re being careful, you’re not being careful enough. Fortunately, in this case, the bug was ultimately harmless and easily fixed, but it was still a great lesson in how unintuitive async Rust can be. Hopefully now that you’ve read this, you’ll be able to prevent such issues <em>before</em> you have to learn this lesson the hard way.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I work on a team that runs a Rust service using Tokio in production. I’ve been coding Rust for many years, have written or rewritten most of our code, have been burned by many of the rough edges of async Rust, and have even written a presentation to introduce async Rust to new people, so I consider myself pretty knowledgeable about the topic. Nevertheless, I ran into a surprising async bug this week. Here is my story:]]></summary></entry><entry><title type="html">Fixing the Next 10,000 Aliasing Bugs</title><link href="/2023/03/05/fixing-the-next-10-000-aliasing-bugs.html" rel="alternate" type="text/html" title="Fixing the Next 10,000 Aliasing Bugs" /><published>2023-03-05T22:42:00+00:00</published><updated>2023-03-05T22:42:00+00:00</updated><id>/2023/03/05/fixing-the-next-10-000-aliasing-bugs</id><content type="html" xml:base="/2023/03/05/fixing-the-next-10-000-aliasing-bugs.html"><![CDATA[<p>Why do software bugs happen? There are many possible causes of bugs, but if we look at examples, we can hopefully see patterns in the bugs that arise and design our programming languages to rule out entire classes of bugs.</p>

<h2 id="1-my-first-arraylist">1) My first ArrayList</h2>

<p>Suppose you’re back in freshman CS, studying data structures and algorithms, and you’re asked to implement an array-backed list in Java. You might write something like the following:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyList</span><span class="o">&lt;</span><span class="no">E</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="no">E</span><span class="o">[]</span> <span class="n">arr</span><span class="o">;</span>
    <span class="kd">private</span> <span class="kt">int</span> <span class="n">length</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">MyList</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="o">(</span><span class="no">E</span><span class="o">[])</span> <span class="k">new</span> <span class="nc">Object</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>
        <span class="n">length</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">ensureCapacity</span><span class="o">(</span><span class="kt">int</span> <span class="n">minCapacity</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">minCapacity</span> <span class="o">&gt;</span> <span class="n">arr</span><span class="o">.</span><span class="na">length</span><span class="o">)</span> <span class="o">{</span>
            <span class="kt">int</span> <span class="n">new_capacity</span> <span class="o">=</span> <span class="nc">Math</span><span class="o">.</span><span class="na">max</span><span class="o">(</span><span class="n">minCapacity</span><span class="o">,</span> <span class="n">arr</span><span class="o">.</span><span class="na">length</span> <span class="o">*</span> <span class="mi">2</span><span class="o">);</span>
            <span class="no">E</span><span class="o">[]</span> <span class="n">new_arr</span> <span class="o">=</span> <span class="o">(</span><span class="no">E</span><span class="o">[])</span> <span class="k">new</span> <span class="nc">Object</span><span class="o">[</span><span class="n">new_capacity</span><span class="o">];</span>
            <span class="nc">System</span><span class="o">.</span><span class="na">arraycopy</span><span class="o">(</span><span class="n">arr</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">new_arr</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">length</span><span class="o">);</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">new_arr</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">add</span><span class="o">(</span><span class="no">E</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">ensureCapacity</span><span class="o">(</span><span class="n">length</span> <span class="o">+</span> <span class="mi">1</span><span class="o">);</span>
        <span class="n">arr</span><span class="o">[</span><span class="n">length</span><span class="o">++]</span> <span class="o">=</span> <span class="n">e</span><span class="o">;</span>
        <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">addAll</span><span class="o">(</span><span class="nc">MyList</span><span class="o">&lt;?</span> <span class="kd">extends</span> <span class="no">E</span><span class="o">&gt;</span> <span class="n">c</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">ensureCapacity</span><span class="o">(</span><span class="n">length</span> <span class="o">+</span> <span class="n">c</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">c</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="n">arr</span><span class="o">[</span><span class="n">length</span><span class="o">++]</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="na">arr</span><span class="o">[</span><span class="n">i</span><span class="o">];</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>This code is <em>mostly</em> correct, but has a subtle bug. The <code class="language-plaintext highlighter-rouge">addAll</code> method is intended to append all the elements of one list to another list. However, what if we pass a second pointer to the <em>same</em> list to <code class="language-plaintext highlighter-rouge">addAll</code>?</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">...</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">MyList</span> <span class="n">s</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">MyList</span><span class="o">&lt;</span><span class="nc">Integer</span><span class="o">&gt;();</span>
    <span class="n">s</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="mi">42</span><span class="o">);</span>
    <span class="n">s</span><span class="o">.</span><span class="na">addAll</span><span class="o">(</span><span class="n">s</span><span class="o">);</span> <span class="c1">// boom!</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2
    at MyList.addAll(MyList.java:28)
    at MyList.main(MyList.java:37)
</code></pre></div></div>

<p>Let’s look more closely at the implementation of <code class="language-plaintext highlighter-rouge">addAll</code>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">addAll</span><span class="o">(</span><span class="nc">MyList</span><span class="o">&lt;?</span> <span class="kd">extends</span> <span class="no">E</span><span class="o">&gt;</span> <span class="n">c</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">ensureCapacity</span><span class="o">(</span><span class="n">length</span> <span class="o">+</span> <span class="n">c</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">c</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
        <span class="n">arr</span><span class="o">[</span><span class="n">length</span><span class="o">++]</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="na">arr</span><span class="o">[</span><span class="n">i</span><span class="o">];</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>We first ensure that <code class="language-plaintext highlighter-rouge">this</code> has sufficient capacity to append the elements from <code class="language-plaintext highlighter-rouge">c</code> by calling <code class="language-plaintext highlighter-rouge">ensureCapacity(length + c.length)</code>, and then append those elements one by one. The problem with this is that the code has an implicit <em>invariant</em> - that <code class="language-plaintext highlighter-rouge">c.length</code> does not change while we are appending the elements.</p>

<p>If <code class="language-plaintext highlighter-rouge">c.length</code> somehow increases while <code class="language-plaintext highlighter-rouge">addAll</code> is executing, then we may no longer have sufficient capacity to hold all the new elements despite reserving <code class="language-plaintext highlighter-rouge">c.length</code> worth of extra capacity at the beginning of the method. Since <code class="language-plaintext highlighter-rouge">addAll</code> itself does not change <code class="language-plaintext highlighter-rouge">c.length</code>, it might seem like it is impossible for this to happen (barring multi-threaded race conditions).</p>

<p>However, if <code class="language-plaintext highlighter-rouge">c</code> points to the <em>same</em> object as <code class="language-plaintext highlighter-rouge">this</code>, then every time we run <code class="language-plaintext highlighter-rouge">length++</code> in the middle of the loop, <code class="language-plaintext highlighter-rouge">c.length</code> <em>also</em> increases because <code class="language-plaintext highlighter-rouge">length</code> and <code class="language-plaintext highlighter-rouge">c.length</code> point to the same field. This means that the <code class="language-plaintext highlighter-rouge">for</code> loop runs forever, repeatedly copying <code class="language-plaintext highlighter-rouge">c</code> onto the end of the list until we reach the edge of the backing array and crash with an <code class="language-plaintext highlighter-rouge">ArrayIndexOutOfBoundsException</code>.</p>

<h2 id="2-the-dao">2) The DAO</h2>

<p>Now let’s look at a famous real world bug. <em>The DAO</em> was a “smart contract” published to the Ethereum blockchain in 2016. The idea behind the DAO was to create a machine-operated investment fund that anyone could deposit and withdraw money from, with the operations governed purely by smart contract code running on the computers of “miners” on the Ethereum network.</p>

<p>Anyone could deposit money by calling a function in the smart contract, and they could later withdraw their money by calling another function*. The smart contract would internally keep track of how much each user is owed, and prevent users from withdrawing more money than they originally deposited, so that one person couldn’t just steal everyone else’s money.</p>

<blockquote>
  <p>* Technically speaking, you couldn’t withdraw money from the DAO directly. Instead, you had to <em>split</em> the DAO into two sub-contracts, one containing your money and one containing everyone else’s. Then you could take the money out of the new contract you created. However, the overall story is the same.</p>
</blockquote>

<p>Unfortunately, one enterprising user noticed a bug in the contract that allowed them to bypass this check and withdraw “their money” multiple times without changing the contract’s internal balance, and thus they were able to drain all the money from the contract that everyone else had deposited (around $150 million). What went wrong?</p>

<p>Here is the relevant code from the DAO smart contract with comments added:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function splitDAO(
  uint _proposalID,
  address _newCurator
) noEther onlyTokenholders returns (bool _success) {

  ...
  // XXXXX Move ether and assign new Tokens.  Notice how this is done first!
  uint fundsToBeMoved =
      (balances[msg.sender] * p.splitData[0].splitBalance) /
      p.splitData[0].totalSupply;
  if (p.splitData[0].newDAO.createTokenProxy.value(fundsToBeMoved)(msg.sender) == false) // XXXXX This is the line the attacker wants to run more than once
      throw;

  ...
  // Burn DAO Tokens
  Transfer(msg.sender, 0, balances[msg.sender]);
  withdrawRewardFor(msg.sender); // be nice, and get his rewards
  // XXXXX Notice the preceding line is critically before the next few
  totalSupply -= balances[msg.sender]; // XXXXX AND THIS IS DONE LAST
  balances[msg.sender] = 0; // XXXXX AND THIS IS DONE LAST TOO
  paidOut[msg.sender] = 0;
  return true;
}
</code></pre></div></div>
<p><a href="https://hackingdistributed.com/2016/06/18/analysis-of-the-dao-exploit/">source</a></p>

<p>Don’t worry about the details of the code. The important part is that this function sends money to the user <em>before</em> decreasing their internal balance. Just like our <code class="language-plaintext highlighter-rouge">MyList</code> example, this code has an implicit <em>invariant</em>.</p>

<p>The invariant is that every user’s balance matches up with the correct amount of money they are owed. When a user deposits money, two changes are required: you have to add the money to the contract <em>and</em> increase the user’s internal balance variable. And likewise when they withdraw money, you have to send them the money <em>and</em> decrease the user’s internal balance variable.</p>

<p>Since multiple steps are required, this means that the invariant is <em>temporarily</em> violated <em>while the function is running</em>. Once both steps are complete and the function returns, the invariant is restored. However, if there is some way to access the smart contract while the withdrawal function is still running, <em>in between</em> when it sends money to the user and when the internal balance variable is updated, the internal balance value will be incorrect and the user can withdraw they money a <em>second</em> time (and then a third and a fourth, until all the money is gone).</p>

<p>In the <code class="language-plaintext highlighter-rouge">MyList</code> example, the temporarily violated invariant was broken by having two <em>aliased</em> pointers pointing to the same object. In the DAO case, the aliasing involved is more subtle.</p>

<p>As it turns out, Solidity (the language that Ethereum smart contracts were written in) allows you to define a fallback function when money is sent to a contract, and this function can execute arbitrary code. Therefore, the attacker just created a smart contract with a fallback function that attempts to withdraw money from the DAO again, and then asked the DAO to withdraw money into their smart contract. When the DAO sent money to the attacker, this triggered the fallback function, which called the DAO withdraw function again <em>while the original withdraw function was still running and the balance value was not yet updated</em> allowing them to endlessly withdraw money.</p>

<p>Here, the fatal aliasing wasn’t due to multiple variables pointing to the same object, but rather copies of the same variable in multiple stack frames, as the same function was called <em>reentrantly</em>.</p>

<h2 id="3-uber">3) Uber</h2>

<p>Last year, Uber published <a href="https://www.uber.com/blog/data-race-patterns-in-go/">a blog post</a> detailing the most common types of bugs they’ve seen in their production Go code. The most common bug pattern they saw was concurrent slice access, as in the following example.</p>

<p><img src="https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2022/08/Figure2.png" alt="Uber Go slice race example" /></p>

<p>In Go, slices are basically like an un-encapsulated version of our <code class="language-plaintext highlighter-rouge">MyList</code> class in the first example. They consist of a <code class="language-plaintext highlighter-rouge">(data pointer, length, capacity)</code> tuple. When you assign or pass around a slice value, those fields are all copied <em>by value</em>. The length and capacity are copied by value, and the data pointer is also copied by value, which is equivalent to passing the data array by reference. This makes it easy to end up with multiple slice values that share the same data array but have inconsistent length and capacity values.</p>

<p>In Uber’s example, the programmer realized that they needed something to protect against race conditions and added a mutex to the <code class="language-plaintext highlighter-rouge">safeAppend</code> function. However, this merely prevents multiple threads from running <code class="language-plaintext highlighter-rouge">safeAppend</code> simultaneously, and thus writing to <code class="language-plaintext highlighter-rouge">myResults</code> simultaneously. The <em>read</em> of <code class="language-plaintext highlighter-rouge">myResults</code> on line 14 is not protected by the mutex at all.</p>

<p>This means that the read of <code class="language-plaintext highlighter-rouge">myResults</code> (which is passed to <code class="language-plaintext highlighter-rouge">results</code> on line 11) may happen while <code class="language-plaintext highlighter-rouge">myResults</code> is simultaneously being written to on line 6. That means that the read may see garbage data, such as if <code class="language-plaintext highlighter-rouge">myResult</code>’s capacity field is updated before the data pointer field, and thus <code class="language-plaintext highlighter-rouge">results</code> copies a capacity value that does not match its data pointer. Uber’s example does not show <code class="language-plaintext highlighter-rouge">results</code> being used anywhere, but if it was used, this might result in out-of-bounds memory access, and thus arbitrary code execution and critical security vulnerabilities.</p>

<p>The Go runtime has an invariant that the three fields of a slice value are consistent, and this invariant is violated via concurrent access to multiple references to <code class="language-plaintext highlighter-rouge">myResults</code>, specifically a mutable access to <code class="language-plaintext highlighter-rouge">myResults</code> in one of the spawned go routines concurrently with a read access to <code class="language-plaintext highlighter-rouge">myResults</code> from the main thread.</p>

<p>However, even if the <em>Go runtime’s</em> invariant was protected by putting a mutex around the read of <code class="language-plaintext highlighter-rouge">myResults</code> on line 14, this code likely still violates <em>logical</em> invariants. Namely, the programmer presumably assumes that the <code class="language-plaintext highlighter-rouge">results</code> values will hold a consistent state that matches <code class="language-plaintext highlighter-rouge">myResults</code>. However, since <code class="language-plaintext highlighter-rouge">results</code> is just <em>copied</em> from <code class="language-plaintext highlighter-rouge">myResults</code> at an arbitrary point, they will likely end up with inconsistent data. If the goroutine then attempts to access <code class="language-plaintext highlighter-rouge">results</code>, this could lead to the result values being overwritten, or failing to see results values that were previously appended.</p>

<h2 id="invariants-and-aliasing">Invariants and aliasing</h2>

<p>What do all three of these bugs have in common? In every case, an <em>invariant</em> was violated thanks to multiple <em>aliased</em> references to the same value.</p>

<p>Invariants are essential to large scale programming, because it is impossible to hold the entire state of a system in your head at once. Invariants allow you to focus only on the parts of the code responsible for upholding that invariant, and to just assume it holds elsewhere, thus reducing the combinatorial explosion of the state space and allowing the development of software larger than trivial toy examples.</p>

<p>However, code inevitably needs to temporarily violate an invariant while performing updates. The problem comes when there are multiple references to the relevant data, and another reference observes this temporarily violated invariant.</p>

<h2 id="preventing-aliasing-bugs">Preventing aliasing bugs</h2>

<p>Now that we’ve recognized the problem, the next question is how to prevent these bugs.</p>

<p>As it turns out, we’ve been here before. The null pointer has been described as “the billion dollar mistake” due to the sheer number of bugs that resulted from null pointers. For decades, programmers just shrugged and accepted <code class="language-plaintext highlighter-rouge">NullPointerException</code>s (or seg faults or <code class="language-plaintext highlighter-rouge">undefined is not a function</code>s, depending on your poison of choice) as a fact of life. You just have to try harder to make sure you don’t slip up, right?</p>

<p>However, more recently, programmers realized that things didn’t have to be this way, and a new generation of programming languages came out where nullability is encoded in the type system. Instead of <em>every</em> value possibly being null, only the values explicitly so marked by the programmer might be null. For the remainder, the compiler would statically verify that they are never null, vastly reducing the surface of potential null pointer bugs. Humans will always slip up from time to time, which is why it is important to develop systems that will catch and prevent these mistakes.</p>

<p>The time has come to do the same for aliasing bugs, to banish them at the programming language level once and for all.</p>

<h2 id="alias-typing">Alias typing</h2>

<p>What might such a language look like?</p>

<p>In the case of null pointers, every reference in a traditional language is implicitly nullable, while in a modern language, you can mark references as nullable or non-nullable, and the latter are statically guaranteed to be non-null. Likewise, in a traditional language, every reference is implicitly aliasable. Therefore, by analogy, in our language, all references will be marked as <em>shared</em> or <em>exclusive</em> and an exclusive reference is statically guaranteed to be non-aliased.</p>

<p>For the sake of example, I’ll write these as <code class="language-plaintext highlighter-rouge">shr</code> and <code class="language-plaintext highlighter-rouge">xcl</code> respectively, e.g. <code class="language-plaintext highlighter-rouge">xcl List</code> or <code class="language-plaintext highlighter-rouge">shr Map</code>, but you’ll probably want to use different syntax in your language. The point of this post is to illustrate how type checking can be used to rule out most aliasing bugs, not to dictate surface-level syntax.</p>

<p>What rules do these types need? First off, when a new object is created, the resulting reference is guaranteed unique, so all objects start out <code class="language-plaintext highlighter-rouge">xcl</code>. Furthermore, you can always implicitly convert an exclusive reference to a shared reference, but not the reverse, much like how a non-nullable reference can be implicitly converted to a nullable reference, but not the reverse.</p>

<h3 id="non-copyable-types">Non-copyable types</h3>

<p>The last rule we need is a bit different: <em>exclusive references can’t be copied</em>. (You can of course convert an exclusive reference to a shared reference and then copy it as much as you want.) This means that when you use an exclusive reference, it is <em>moved</em> rather than <em>copied</em>. The compiler needs to ensure that the old variable is no longer accessed. E.g.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>let foo: xcl Foo = new Foo;
let bar = foo; // foo is moved to bar
foo; // compile error - foo can't be accessed any more
</code></pre></div></div>

<h2 id="permissions-and-invariant-removal">Permissions and invariant removal</h2>

<p>In the case of nullable pointers, the input type required is obvious. If a piece of code accesses a reference without checking it for null, then it needs to take in a non-nullable reference. If it does check for null explicitly, then it is safe to take in a nullable reference instead. What is the equivalent for alias typing? When do you actually need an exclusive reference, and when can you get away with using shared references?</p>

<p>The answer is that an exclusive reference is required to <em>remove invariants</em>. If you want to violate an invariant, even temporarily, you need to ensure that no other reference can possibly observe the violated invariant, and thus you need an exclusive reference. If your code does not require removing any invariants from a value, you can safely use shared references.</p>

<p>For example, imagine that we have an <code class="language-plaintext highlighter-rouge">UInt</code> type for (mutable) unsigned integer objects and a <code class="language-plaintext highlighter-rouge">NonZero</code> type that represents <code class="language-plaintext highlighter-rouge">UInt</code>s with the additional invariant of holding a nonzero value. We might write a function that takes in a nonzero int and temporarily violates the invariant like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment(x: xcl NonZero) -&gt; xcl NonZero {
    let x = x as UInt; // remove invariant
    *x += 1;
    // check for overflow and ensure value is nonzero
    if *x == 0 {
        *x = 0xFFFFFFFF; // saturate at max value
    }
    // add the invariant back
    return x as NonZero;
}
</code></pre></div></div>

<p>Personally, I like to think of <code class="language-plaintext highlighter-rouge">xcl</code> and <code class="language-plaintext highlighter-rouge">shr</code> as <em>permissions</em> for the associated references. However, these aren’t quite the same as permissions like “can read” or “can write” that you’re probably used to thinking of as “permissions”. Rather, <code class="language-plaintext highlighter-rouge">xcl</code> is <em>the permission to assume that noone else is accessing this value</em>, which in turn implies the permission to remove invariants.</p>

<p>You can of course create an arbitrarily fine-grained permission system if you want to. For instance, you might have one permission type for pointers where only you can write to the pointer but other copies may exist that can read the value. But the two permission <code class="language-plaintext highlighter-rouge">xcl/shr</code> system illustrates all the fundamental design considerations required, so I’ll stick with it for simplicity.</p>

<h2 id="time-limited-permissions">Time-limited permissions</h2>

<p>The above system is straightforward to implement, but it isn’t very useful. The problem is that you can only ever use an exclusive reference once, which makes it impossible to do anything interesting. You can partially work around this by always returning the new value and assigning it back at the callsite, but this quickly becomes cumbersome.</p>

<p>Suppose for example, that we want to call our <code class="language-plaintext highlighter-rouge">increment</code> function twice. We would have to do something like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_twice(x: xcl NonZero) -&gt; xcl NonZero {
    let x = increment(x);
    let x = increment(x);
    return x;
}
</code></pre></div></div>

<p>But what if we want to add loops or conditionals? What if we’re operating on a bunch of different values? What if we are mapping over a list of values? The “return value and reassign at callsite” style is very limited, in addition to being verbose. It would be a lot more convenient if we could do the operations by reference instead.</p>

<p>We would like to be able to do something like this.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment(x: xcl NonZero) {
    // ...
}

fn increment_twice(x: xcl NonZero) {
    increment(x);
    increment(x); // ??? 
}
</code></pre></div></div>

<p>However, the <code class="language-plaintext highlighter-rouge">increment_twice</code> function doesn’t work because <code class="language-plaintext highlighter-rouge">x</code> was already moved on the first call to <code class="language-plaintext highlighter-rouge">increment</code>. Intuitively, this code <em>should</em> work though. After all, <code class="language-plaintext highlighter-rouge">increment</code> only needs <em>temporary</em> exclusive access to <code class="language-plaintext highlighter-rouge">x</code>. Once the call to <code class="language-plaintext highlighter-rouge">increment</code> completes, it doesn’t hold on to any references to <code class="language-plaintext highlighter-rouge">x</code>, so we should be able to treat <code class="language-plaintext highlighter-rouge">x</code> as exclusive again in the parent <code class="language-plaintext highlighter-rouge">increment_twice</code> function, and thus be able to call <code class="language-plaintext highlighter-rouge">increment</code> a second time.</p>

<p>The solution is <em>time-limited permissions</em>. Instead of granting <code class="language-plaintext highlighter-rouge">increment</code> <em>permanent</em> exclusive access to <code class="language-plaintext highlighter-rouge">x</code>, we only grant it temporary exclusive access to <code class="language-plaintext highlighter-rouge">x</code> for the duration of the call, and thus can call it again after the first call completes.</p>

<h2 id="permission-grants">Permission grants</h2>

<p>So how do we implement this? And in particular, how can we do the type checking without costly inter-procedural code analysis? How can we represent all the information required to check time-limited permissions in just the type annotations?</p>

<p>In addition to a permission (<code class="language-plaintext highlighter-rouge">xcl</code> or <code class="language-plaintext highlighter-rouge">shr</code>), each reference type optionally has a <em>grant</em> parameter, which tracks temporary permission grants and when they can be revoked. In the example syntax, I will write grants using a leading apostrophe, i.e. <code class="language-plaintext highlighter-rouge">'a xcl Foo</code>. <strong>Note that these exist purely at compile time</strong>. The permission types are merely for static type checking to prevent bugs. At runtime, everything is compiled down to ordinary pointers, and there is no runtime overhead.</p>

<p>Additionally, I’ll introduce the <code class="language-plaintext highlighter-rouge">'call</code> keyword to represent the duration of the current function call. Therefore, we can write <code class="language-plaintext highlighter-rouge">increment</code> as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment(x: 'call xcl NonZero) {
    // ...
}
</code></pre></div></div>

<p>Note that grant parameters will always be generic, because every instance of every call will have a different grant. So <code class="language-plaintext highlighter-rouge">'call</code> here is really shorthand for “any <code class="language-plaintext highlighter-rouge">'a</code> such that <code class="language-plaintext highlighter-rouge">'a</code> lasts at least as long as <code class="language-plaintext highlighter-rouge">'call</code>”. For the sake of example syntax, we’ll write this as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment&lt;'a: 'call&gt;(x: 'a xcl NonZero) {
    // ...
}
</code></pre></div></div>

<p>This explicit syntax allows us to also express <em>dependencies</em> between arguments and return values. For example, suppose we modify <code class="language-plaintext highlighter-rouge">increment</code> to return the input again, like before. We could write this type signature as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment&lt;'a: 'call&gt;(x: 'a xcl NonZero) -&gt; 'a xcl NonZero {
    // ...
    return x as NonZero;
}
</code></pre></div></div>

<p>Since the argument and return value have the same grant parameter, the compiler can know that the return value depends on the input without looking at the body of the function.</p>

<p>Now let’s get back to <code class="language-plaintext highlighter-rouge">increment_twice</code> and make it a bit more interesting, by storing the return value and adding some extra <code class="language-plaintext highlighter-rouge">increment</code> calls, attempting to increment four times in total, but using a stale reference for the last call which should result in a compile error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    let y = increment(x);
    increment(y); // ok
    increment(x); // also ok
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<h2 id="permission-splitting">Permission splitting</h2>

<p>To typecheck this code, we’ll need to introduce the notion of <em>splitting</em> permissions, which is the most counter-intuitive part of alias checking.</p>

<p>We already got a taste of this with the initial version of non-copyable types above:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>let a: xcl Foo = new Foo;
let b = a; 
// b has type xcl Foo, a has type undefined
</code></pre></div></div>

<p>Essentially, <code class="language-plaintext highlighter-rouge">a</code> has a certain amount of permissions to access its content. In the simple case with non-copyable types, we transfer the <em>entire</em> permission to the new value whenever we read a variable. This means that the original variable <code class="language-plaintext highlighter-rouge">a</code> no longer has <em>any</em> permissions and thus can’t be accessed.</p>

<p>However, instead of transfering <code class="language-plaintext highlighter-rouge">a</code>’s permissions permanently when read, we can instead only transfer <em>part</em> of the permissions, specifically, the part that allows access before a given point in time. Then <code class="language-plaintext highlighter-rouge">b</code> can only be accessed <em>before</em> that time and <code class="language-plaintext highlighter-rouge">a</code> can only be accessed <em>after</em> that point in time, and thus there is no conflict in them <em>both</em> having a (time-limited) <em>exclusive</em> permission attached.</p>

<p>More specifically, when we read <code class="language-plaintext highlighter-rouge">a</code>, we’ll give the read value (<code class="language-plaintext highlighter-rouge">b</code>) the type <code class="language-plaintext highlighter-rouge">'0 xcl Foo</code>, where <code class="language-plaintext highlighter-rouge">'0</code> is a freshly generated grant variable, representing that <code class="language-plaintext highlighter-rouge">b</code> can be accessed until the grant <code class="language-plaintext highlighter-rouge">'0</code> is revoked. Meanwhile, <code class="language-plaintext highlighter-rouge">a</code> will have the type “can be accessed as <code class="language-plaintext highlighter-rouge">xcl Foo</code> by first revoking the <code class="language-plaintext highlighter-rouge">'0</code> grant”. We’ll write <code class="language-plaintext highlighter-rouge">'n -* T</code> to represent the type “can revoke <code class="language-plaintext highlighter-rouge">'n</code> to access as <code class="language-plaintext highlighter-rouge">T</code>”, so <code class="language-plaintext highlighter-rouge">a</code> has the type <code class="language-plaintext highlighter-rouge">'0 -* xcl Foo</code>. Note that <code class="language-plaintext highlighter-rouge">-*</code> is just example syntax for the sake of discussion. In practice, these types will only be used for internal bookkeeping by the compiler and never be exposed to the user, so it doesn’t matter if the syntax is ungainly.</p>

<h3 id="type-checking-example">Type-checking example</h3>

<p>With that machinery out of the way, we can see an example of how our fancy <code class="language-plaintext highlighter-rouge">increment_twice</code> function will be typechecked. Recall that the code is as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    let y = increment(x);
    increment(y); // ok
    increment(x); // also ok
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<p>We start with all variables (i.e. just <code class="language-plaintext highlighter-rouge">x</code>) having the types from the function signature:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    // types: x: 'b xcl NonZero
    let y = increment(x);
    increment(y); // ok
    increment(x); // also ok
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<p>Now we get to the <code class="language-plaintext highlighter-rouge">x</code> in the first <code class="language-plaintext highlighter-rouge">increment(x)</code>. We generate a fresh grant variable, <code class="language-plaintext highlighter-rouge">'0</code>, and assign the type <code class="language-plaintext highlighter-rouge">'0 xcl NonZero</code> to <em>the temporary value read from <code class="language-plaintext highlighter-rouge">x</code></em>. Meanwhile, the <em>local variable</em> x has its type changed to <code class="language-plaintext highlighter-rouge">'0 -* 'b xcl NonZero</code>. This means that it currently has no permissions, but will regain the <code class="language-plaintext highlighter-rouge">'b xcl NonZero</code> permission by revoking the <code class="language-plaintext highlighter-rouge">'0</code> grant.</p>

<p>Next, we match the argument value against the type signature of <code class="language-plaintext highlighter-rouge">increment</code>, and thus <code class="language-plaintext highlighter-rouge">'a</code> matches with <code class="language-plaintext highlighter-rouge">'0</code>. Thus we know that the return value has the same grant, so <code class="language-plaintext highlighter-rouge">y</code> gets the type <code class="language-plaintext highlighter-rouge">'0 xcl NonZero</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    let y = increment(x);
    // types: x: '0 -* 'b xcl NonZero, y: '0 xcl NonZero
    increment(y); // ok
    increment(x); // also ok
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<p>Next we do the same thing with the <code class="language-plaintext highlighter-rouge">increment(y)</code> line, generating a <code class="language-plaintext highlighter-rouge">'1</code> sub-grant variable. This doesn’t matter because we aren’t storing the return value this time, and thus can revoke the grant any time we want, but I’m listing it explicitly for the sake of clarity.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    let y = increment(x);
    increment(y); // ok
    // types: x: '0 -* 'b xcl NonZero, y: '1 -* '0 xcl NonZero
    increment(x); // also ok
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<p>The interesting part happens when we get to the second <code class="language-plaintext highlighter-rouge">increment(x)</code> call. <code class="language-plaintext highlighter-rouge">increment</code> requires an argument of type <code class="language-plaintext highlighter-rouge">'a xcl NonZero</code> for some <code class="language-plaintext highlighter-rouge">'a</code>, but our <code class="language-plaintext highlighter-rouge">x</code> variable currently has the type <code class="language-plaintext highlighter-rouge">'0 -* 'b xcl NonZero</code>. Therefore we revoke the <code class="language-plaintext highlighter-rouge">'0</code> grant, which changes the type back to <code class="language-plaintext highlighter-rouge">'b xcl NonZero'</code>. Since <code class="language-plaintext highlighter-rouge">'1</code> depends on <code class="language-plaintext highlighter-rouge">'0</code>, it gets revoked as well. <code class="language-plaintext highlighter-rouge">y</code> is no longer accessible at all.</p>

<p>After changing the type of <code class="language-plaintext highlighter-rouge">x</code> back to <code class="language-plaintext highlighter-rouge">'b xcl NonZero'</code>, we can then split it like before, resulting in a new local grant variable, so we generate a temporary value with type <code class="language-plaintext highlighter-rouge">'2 xcl NonZero</code> to pass to <code class="language-plaintext highlighter-rouge">increment</code> and change the type of the <code class="language-plaintext highlighter-rouge">x</code> variable to <code class="language-plaintext highlighter-rouge">'2 -* 'b xcl NonZero</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fn increment_four_times&lt;'b: 'call&gt;(x: 'b xcl NonZero)  {
    let y = increment(x);
    increment(y); // ok
    increment(x); // also ok
    // types: x: '2 -* 'b xcl NonZero, y: undefined
    increment(y); // compile error - y's permission grant has been revoked by this point
}
</code></pre></div></div>

<p>Lastly, we get to the final line, where we try to read from <code class="language-plaintext highlighter-rouge">y</code> again. However, by this point, <code class="language-plaintext highlighter-rouge">y</code>’s grant has been revoked, and thus it can’t be accessed anymore, so we return a compile error.</p>

<h3 id="first-class---types">First class <code class="language-plaintext highlighter-rouge">-*</code> types</h3>

<p>Note that in this design, the only time we ever use <code class="language-plaintext highlighter-rouge">-*</code> types is for local variables <em>during type checking</em>. Whenever a local variable is <em>read</em>, we revoke grants in front of the <code class="language-plaintext highlighter-rouge">-*</code> if applicable and then re-split off as a normal type. Therefore, the user will never see or deal with <code class="language-plaintext highlighter-rouge">-*</code> types, they’re just a mechanism to describe the internals of type checking.</p>

<p>Furthermore, all grant variables are local to the function being typechecked, and only fresh grants defined in the same function (<code class="language-plaintext highlighter-rouge">'0</code>, <code class="language-plaintext highlighter-rouge">'1</code>, etc. as opposed to <code class="language-plaintext highlighter-rouge">'b</code>) can appear in front of the <code class="language-plaintext highlighter-rouge">-*</code>. This ensures that we can <em>statically</em> revoke the grants during typechecking, and therefore can erase them during compilation, and there is no runtime overhead.</p>

<p>This system should be good enough for ordinary code, but there are rare cases where you might want to give the users more control over typechecking, and allow them to define custom <code class="language-plaintext highlighter-rouge">-*</code> types and pass them around. For example, they are useful for representing mutex guards and coroutines. However, these uses should be rare and will usually be hidden inside a standard library, so the complexity there shouldn’t be an issue in practice.</p>

<h3 id="type-inference">Type inference</h3>

<p>Obviously this makes types more verbose, but judicious use of type inference or type defaulting can greatly reduce the burden of explicit permission types. I think that it still makes sense to require explicit <code class="language-plaintext highlighter-rouge">xcl/shr</code> in function signatures, since those are useful for documentation purposes and not much different from the <code class="language-plaintext highlighter-rouge">const T</code> annotations that you already see in existing languages.</p>

<p>However, the grant variables are a bit ugly and a pain to manage. Therefore, type inference should be used to remove the need to explicitly write them as much as possible. As far as I know, there is no decidable way to <em>fully</em> infer them, and you probably don’t want to do that anyway for efficiency and error-message quality reasons. However, you can still infer them in simple cases, i.e. private non-recursive functions.</p>

<h1 id="the-elephant-crab">The elephant crab</h1>

<div align="center">
    <img src="/img/20230305_crab.png" alt="giant crab" />
    <p></p>
</div>

<p>And now for the elephant crab in the room: the system I’ve described is similar to that of the existing programming language <a href="https://www.rust-lang.org/">Rust</a> and its “borrow checker”.</p>

<p>People often think that Rust is hard to learn due to its borrow checker and think “well, maybe you need a borrow checker if you want to write C++ correctly, but why do we need it for a Java/Python/Javascript competitor?” Why can’t we just use a GC and throw off the dread borrow checker?</p>

<p>This logic however, is precisely backwards. It is true that Rust is designed to replace C++, and that Rust has a borrow checker, and that the borrow checker is necessary in order to safely perform the kind of memory management people are used to in C++. However, that doesn’t mean that the borrow checker is only useful or necessary when doing C++, or that it isn’t useful in a GC’ed language. Memory management is the <em>least</em> interesting application of borrow checking.</p>

<p>One of the goals of writing this post is to show how the logic of preventing common bugs inexorably leads to something that is at least vaguely similar to Rust’s borrow checker (of course it doesn’t have to be identical - there’s still lots of room for improvement over Rust here!). In fact, <em>two of the three languages from the bug examples section have garbage collectors</em>. Far from removing the need for a borrow checker, GC merely removes some of the <em>hassle</em> of using a borrow checker.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this post, we saw a very common class of bugs, those caused by <em>aliasing</em>, and how to statically prevent these bugs via typechecking. Although alias types are a bit more exotic than traditional type systems (in particular, types are only <em>temporarily</em> valid), they aren’t that hard to get used to and are important for preventing bugs.</p>

<p>Null checking was once unusual as well, but now, in this age of Kotlin and strictNullChecks TypeScript, nobody will take a language without null checking seriously. I think that someday, the same will be true of alias checking as well.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Why do software bugs happen? There are many possible causes of bugs, but if we look at examples, we can hopefully see patterns in the bugs that arise and design our programming languages to rule out entire classes of bugs.]]></summary></entry><entry><title type="html">Fixing the Next Thousand Deadlocks: Why Buffered Streams Are Broken and How To Make Them Safer</title><link href="/2022/07/24/fixing-the-next-thousand-deadlocks-why-buffered-streams-are-broken-and-how-to-make-them-safer.html" rel="alternate" type="text/html" title="Fixing the Next Thousand Deadlocks: Why Buffered Streams Are Broken and How To Make Them Safer" /><published>2022-07-24T23:52:00+00:00</published><updated>2022-07-24T23:52:00+00:00</updated><id>/2022/07/24/fixing-the-next-thousand-deadlocks-why-buffered-streams-are-broken-and-how-to-make-them-safer</id><content type="html" xml:base="/2022/07/24/fixing-the-next-thousand-deadlocks-why-buffered-streams-are-broken-and-how-to-make-them-safer.html"><![CDATA[<p>I am fortunate enough to work on a production Rust service (a real one, not cryptocurrency nonsense). Rust virtually eliminates the kinds of stupid bugs and gotchas that are endemic in other languages, making it much easier to develop and maintain our project. Unfortunately, Rust is substantially less capable when it comes to preventing the common issues involved in async programming. In fact, async programming is substantially <em>harder</em> to get right in Rust than in something like Javascript, due to the decision to make task spawning explicit for performance reasons.</p>

<p>Last month, our service was brought down for days by a nasty deadlock bug, and this isn’t the first deadlock we’ve seen - it’s at least the fourth. And just last week, we saw yet another deadlock-induced outage. Fortunately, four of the five deadlocks (including the most recent two) have the same root cause - <strong><code class="language-plaintext highlighter-rouge">futures::stream::Buffered</code> is inherently prone to deadlocks</strong>. In this post, I will explain the issue and explore ways to prevent this from happening again. The transition won’t be easy, but I think it will pay off for the ecosystem in the long run.</p>

<h2 id="why-do-these-deadlocks-keep-happening">Why do these deadlocks keep happening?</h2>

<p>Here is a recipe for deadlock:</p>

<ol>
  <li>Have two futures, A and B, where A cannot make progress until B does. The exact reason for the dependence here doesn’t matter - perhaps B is holding a shared semaphore, or they’re sending to each other over a shared channel.</li>
  <li>Poll A and never poll B.</li>
</ol>

<p>Part 1 is nearly impossible to avoid. No matter how careful you are, any sufficiently complex codebase will end up having unforseen dependencies between futures sooner or later. Part 2 on the other hand, is an issue unique to Rust. In a high level language like Javascript, futures are spawned automatically, meaning that they will execute even if you don’t poll them. This means that you’ll never get into the situation where your code is blocked on a future that isn’t running due to not being polled.</p>

<p>Of course, Rust does this for a good reason. It is part of the “only pay for what you use” zero-cost abstraction philosophy and is also required in order to avoid enshrining a particular async executor design into the language. However, it does mean that async code in Rust does not follow the intuitive mental model where futures just execute in the background. Therefore, we need to carefully design APIs in order to avoid the resulting bugs.</p>

<p>Fortunately, this is already mostly the case in Rust. Most async-related APIs already poll all their constituent futures when polled, which means that you can just program like you normally would and ignore the fact that the futures aren’t <em>actually</em> scheduled independently in the executor. There is one very common exception however, and that is <code class="language-plaintext highlighter-rouge">stream::Buffered</code> (and its cousins <code class="language-plaintext highlighter-rouge">stream::BufferUnordered</code>, <code class="language-plaintext highlighter-rouge">stream::TryBuffered</code>, and <code class="language-plaintext highlighter-rouge">stream::TryBufferUnordered</code> - I’m treating all four as a single API for the purpose of this post, since the issues involved are the same).</p>

<p><strong>Update</strong>: At first, I thought the issue was just <code class="language-plaintext highlighter-rouge">Buffered</code>, but in the process of writing up this post, I realized that <code class="language-plaintext highlighter-rouge">stream::Zip</code> can potentially suffer from similar issues, and there are likely other similarly afflicted APIs. <code class="language-plaintext highlighter-rouge">Buffered</code> and its ilk seem to be the most common source of problems in practice, but any comprehensive solution would have to audit the other APIs and make similar changes where applicable.</p>

<h2 id="how-do-buffered-streams-currently-work">How do buffered streams currently work?</h2>

<p>Here is a psuedocode version of <a href="https://github.com/rust-lang/futures-rs/blob/183f8c61371d4c3891683ca51c72e579891bfa79/futures-util/src/stream/stream/buffered.rs">the Buffered implementation</a>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Buffered</span> <span class="p">{</span>
  <span class="n">wrapped_stream</span><span class="p">:</span> <span class="k">impl</span> <span class="n">Stream</span><span class="p">,</span>
  <span class="n">in_progress_queue</span><span class="p">:</span> <span class="n">FuturesOrdered</span><span class="p">,</span>
  <span class="n">max_buffer_size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>
<span class="k">impl</span> <span class="n">Buffered</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">poll_next</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Poll</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">Item</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">while</span> <span class="k">self</span><span class="py">.in_progress_queue</span><span class="nf">.len</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">max_buffer_size</span> <span class="p">{</span>
      <span class="k">if</span> <span class="k">let</span> <span class="nf">Ready</span><span class="p">(</span><span class="nf">Some</span><span class="p">(</span><span class="n">fut</span><span class="p">))</span> <span class="o">=</span> <span class="k">self</span><span class="py">.wrapped_stream</span><span class="nf">.poll_next</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">self</span><span class="py">.in_progress_queue</span><span class="nf">.push</span><span class="p">(</span><span class="n">fut</span><span class="p">);</span>
      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">match</span> <span class="k">self</span><span class="py">.in_progress_queue</span><span class="nf">.poll_next</span><span class="p">()</span> <span class="p">{</span>
      <span class="n">Pending</span> <span class="k">=&gt;</span> <span class="n">Pending</span><span class="p">,</span>
      <span class="nf">Ready</span><span class="p">(</span><span class="nf">Some</span><span class="p">(</span><span class="n">val</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="nf">Ready</span><span class="p">(</span><span class="nf">Some</span><span class="p">(</span><span class="n">val</span><span class="p">)),</span>
      <span class="nf">Ready</span><span class="p">(</span><span class="nb">None</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
        <span class="c1">// if we get here, in_progress_queue is empty. check if wrapped_stream has anything left</span>
        <span class="k">if</span> <span class="k">self</span><span class="py">.wrapped_stream</span><span class="nf">.is_done</span><span class="p">()</span> <span class="p">{</span>
          <span class="nf">Ready</span><span class="p">(</span><span class="nb">None</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
          <span class="n">Pending</span> 
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Basically, <code class="language-plaintext highlighter-rouge">Buffered</code> is a stream implementation that wraps another stream (here called <code class="language-plaintext highlighter-rouge">wrapped_stream</code>) and buffers up to <code class="language-plaintext highlighter-rouge">max_buffer_size</code> futures into a queue where they are executed concurrently.</p>

<p>When <code class="language-plaintext highlighter-rouge">Buffered</code> is polled, it first checks whether the <code class="language-plaintext highlighter-rouge">in_progress_queue</code> is less than <code class="language-plaintext highlighter-rouge">max_buffer_size</code> and takes new futures from the wrapped stream and adds them into the progress queue as long as a) <code class="language-plaintext highlighter-rouge">in_progress_queue</code> is less than the maximum size and b) the wrapped stream has futures ready to be added.</p>

<p>Once <code class="language-plaintext highlighter-rouge">in_progress_queue</code> is at its maximum size (or <code class="language-plaintext highlighter-rouge">wrapped_stream</code> has no new items ready), it just polls <code class="language-plaintext highlighter-rouge">in_progress_queue</code> and returns the next item from the queue if it is ready.</p>

<p>At first glance, this seems like a reasonable implementation. However, it has a crucial flaw: <strong>as long as <code class="language-plaintext highlighter-rouge">in_progress_queue</code> is full, <code class="language-plaintext highlighter-rouge">wrapped_stream</code> will never be polled</strong>. This means that if you have futures <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code> from the previous section where <code class="language-plaintext highlighter-rouge">A</code> depends on <code class="language-plaintext highlighter-rouge">B</code> and <code class="language-plaintext highlighter-rouge">A</code> is in <code class="language-plaintext highlighter-rouge">in_progress_queue</code> while <code class="language-plaintext highlighter-rouge">B</code> is contained within <code class="language-plaintext highlighter-rouge">wrapped_stream</code>, the stream will immediately deadlock.</p>

<p>Now that we know the problem, how do we fix it?</p>

<h2 id="just-be-careful">JuSt Be CaReFuL</h2>

<p>If there’s one lesson from decades of software engineering, it is the failure of “just be careful” as a strategy. C/C++ programmers still experience memory corruption constantly, no matter how careful they are. Java programmers still frequently see <code class="language-plaintext highlighter-rouge">NullPointerException</code>s, no matter how careful they are. And so on. One of the reasons that Rust is so successful is that it adds automated checks to prevent many common mistakes.</p>

<p>As shown by the fact that we keep seeing new deadlock bugs, despite our best efforts to avoid them, “just be careful” is not a strategy that can avoid this kind of bug in nontrivial codebases. We need some way to statically eliminate the issue.</p>

<h2 id="making-the-world-safe-for-unspawned-futures">Making the world safe for unspawned futures</h2>

<p>Before we get into the details of the proposal, I want to be clear about what is and isn’t the goal here. <strong>The goal of this proposal is to eliminate deadlocks that arise from the unspawned nature of Rust futures</strong> - i.e. where the equivalent code would not deadlock if all futures were magically spawned.</p>

<p>Eliminating <em>all</em> deadlocks is out of scope for this proposal. After all, there’s nothing stopping programmers from say, acquiring two locks in an inconsistent order, or re-entrantly trying to acquire a lock, etc. You don’t even need futures to cause a deadlock, let alone buffered streams. Preventing <em>all</em> deadlocks would require a language that is extremely limited in what it can do or that requires programmers to write Coq-like proofs all the time, and that does not seem to be practical for the foreseeable future.</p>

<p>Additionally, <em>real-time guarantees</em> are also out of scope. <a href="https://github.com/rust-lang/futures-rs/issues/2387">Deadlocks aren’t the only thing that can go wrong in asynchronous code</a>. If you have a future that holds on to a database connection, and then it takes a long time before the future is polled again, the connection will time out, leading to an error. Unfortunately, there is no way to completely avoid this. After all, no matter how the libraries are designed, you can always write an async function that just takes a long time between awaits, thus causing other pending futures to time out. For that matter, you can’t even make real-time gauarantees for single thread synchronous code, because it can always be preempted by the OS for arbitrary long. There’s no 100% solution here, but running database code inside <code class="language-plaintext highlighter-rouge">spawn_blocking()</code> with a seperate executor would probably avoid most of the timeout issues here.</p>

<p>That being said, I think even this limited goal would be extraordinarily beneficial to the Rust ecosystem. Designing async libraries so that programmers don’t have to think about the implementation details of the executor and can just use a simplified mental model based on higher level languages would make the language more approachable and relieve a great mental burden while writing async Rust. And empirically, this particular issue with buffered streams is the cause of the vast majority of outages in our experience.</p>

<h2 id="towards-a-better-futuresstreambuffered">Towards a better future(s::stream::Buffered)</h2>

<p>Unfortunately, there is no quick fix that can be slapped on without breaking backwards compatibility. Instead, my proposal is to replace the existing API with several new APIs that statically protect against deadlocks. This will involve a significant deprecation period and effort by users to migrate to the new APIs, but as they say, the journey of a thousand miles begins with a single step, and it will pay off in the long run.</p>

<p>In order to fix <code class="language-plaintext highlighter-rouge">Buffered</code>, we need to rule out the situation where you have two futures and only one of them is being polled. There are two main ways to do this, each with its pros and cons that make sense in certain situations and not others. Therefore, I propose adding both.</p>

<h2 id="every-day-im-pollin">Every day I’m pollin’</h2>

<p>The first approach is rarely useful, but it is a lot simpler, so I’ll cover it first. If the problem is that we might have futures hidden within <code class="language-plaintext highlighter-rouge">wrapped_stream</code> while we’re not polling it, why not just <em>always poll <code class="language-plaintext highlighter-rouge">wrapped_stream</code>?</em></p>

<p>More specifically, we don’t <em>always</em> have to poll it. We just have to ensure that we poll <code class="language-plaintext highlighter-rouge">wrapped_stream</code> whenever <code class="language-plaintext highlighter-rouge">in_progress_queue</code> returns <code class="language-plaintext highlighter-rouge">Pending</code>, even if it is already at our <code class="language-plaintext highlighter-rouge">max_buffer_size</code>.</p>

<p>This approach has the advantage that it is incredibly simple to implement. It could be added to the <code class="language-plaintext highlighter-rouge">futures</code> library with just a couple lines of code without even changing any of the APIs. Unfortunately, it is only rarely the appropriate solution for users. In the common case where <code class="language-plaintext highlighter-rouge">wrapped_stream</code> is actually synchronous where <code class="language-plaintext highlighter-rouge">poll_next</code> never blocks (for example, if it came from a <code class="language-plaintext highlighter-rouge">stream::iter(...).map(...)</code> construction), this solution devolves into just an unbounded queue that eagerly evaluates the underlying stream. And that can cause problems such as running out of memory.</p>

<h2 id="if-you-buffered-it-then-you-should-have-put-a-spawn-on-it">If you buffered it, then you should have put a spawn() on it</h2>

<p>If we can’t just poll <code class="language-plaintext highlighter-rouge">wrapped_stream</code> all the time, the other way to eliminate the problem is to <em>change the type signature of <code class="language-plaintext highlighter-rouge">Buffered</code></em> to prevent the wrapped stream from containing (non-ignorable) futures in the first place, so it doesn’t matter if it never gets polled.</p>

<p>Luckily, we don’t have to prevent the stream from containing <em>all</em> futures. Some futures are ok to ignore, because they’ll execute in the background even if not polled. In the case of <code class="language-plaintext highlighter-rouge">tokio</code>, this is done via the <code class="language-plaintext highlighter-rouge">task::spawn</code> call, which returns a <code class="language-plaintext highlighter-rouge">JoinHandle</code>. So if you have a <code class="language-plaintext highlighter-rouge">JoinHandle</code>, you know that it is safe to not poll it. Therefore, we just need to change the type signature of <code class="language-plaintext highlighter-rouge">Buffered</code> somehow to rule out streams which contain futures <em>that aren’t <code class="language-plaintext highlighter-rouge">JoinHandle</code>s</em>.</p>

<p>Unfortunately, the <code class="language-plaintext highlighter-rouge">futures</code> library needs to be executor agnostic and every executor has slightly different ways of doing things. So the first step is to introduce a marker trait, which we’ll call <code class="language-plaintext highlighter-rouge">SpawnedFuture</code> for the sake of argument, and then wait for all the executor libraries to implement that trait for their <code class="language-plaintext highlighter-rouge">JoinHandle</code> equivalents.</p>

<p>With that out of the way, how do we actually fix the type signatures? In order to do this, we’ll first have to be clear on what it means for a stream to “contain” a non-ignorable future in the first place.</p>

<h2 id="know-your-enemy-item-vs-poll_next">Know your enemy: Item vs poll_next</h2>

<p>Typically, if asked what a stream contains, you would think of the <em>values</em> the stream yields, i.e. <code class="language-plaintext highlighter-rouge">Stream::Item</code>. However, this is not what we are concerned about here, or at least not the only thing.</p>

<p>First off, a stream will typically not actually <em>contain</em> the values it yields. Normally the values are produced on the fly when the stream is polled! There are some cases where the stream could be considered to contain futures that it yields. For example, if you have a <code class="language-plaintext highlighter-rouge">Vec</code> of existing futures and you call <code class="language-plaintext highlighter-rouge">stream::iter</code> on it, the resulting stream will yield futures that <em>already</em> exist <em>before</em> <code class="language-plaintext highlighter-rouge">poll_next</code> is called.</p>

<p>On the other hand, a more typical situation is that you call <code class="language-plaintext highlighter-rouge">stream::iter(vals).map(|v| async move {whatever})</code>, where <code class="language-plaintext highlighter-rouge">vals</code> is some iterator of plain non-future data, and the <code class="language-plaintext highlighter-rouge">map</code> callback constructs futures on the fly. In this case, there are no concerns with deadlocks because the futures don’t exist until the stream is polled, and hence there is no way to be blocked on them. (Or if you do somehow get blocked on a non-existent future, your code would deadlock even in the JS everything-auto-spawned world as well, and is thus out of scope of this proposal as described previously.)</p>

<p>The other issue is that a stream may contain futures that are <em>not</em> part of the items it yields! In a simple case like <code class="language-plaintext highlighter-rouge">stream::iter</code>, the <code class="language-plaintext highlighter-rouge">poll_next</code> method will just always complete and return a value immediately. However, <code class="language-plaintext highlighter-rouge">poll_next</code> is asynchronous, and hence can depend on futures under the hood. You could have a stream where <code class="language-plaintext highlighter-rouge">Item=u8</code> or something perfectly innocous like that, and yet it still contains futures. The most obvious example of this is <code class="language-plaintext highlighter-rouge">Buffered</code> itself, but it could also happen if you have a custom <code class="language-plaintext highlighter-rouge">Stream</code> implementation (which is what led to last month’s deadlock in our case).</p>

<p>Therefore, there are two different axis we have to worry about:</p>
<ol>
  <li>Does the stream contain unspawned futures internally (such as to implement <code class="language-plaintext highlighter-rouge">poll_next</code>)?</li>
  <li>Does it <em>yield</em> unspawned futures that pre-date the call to <code class="language-plaintext highlighter-rouge">poll_next</code>?</li>
</ol>

<h2 id="let-the-right-stream-in">Let the right stream in</h2>

<p>So how do we statically determine whether a stream is safe to buffer or not? Unfortunately, there’s no really good solution, as far as I know (suggestions are welcome). However, here is <em>a</em> possibility, which works at the cost of being overly conservative and ruling out some common code patterns.
async {</p>
<ul>
  <li>Introduce a marker trait, perhaps called <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code> for streams <em>whose <code class="language-plaintext highlighter-rouge">poll_next</code> implementation</em> does not depend on any non-spawned futures. Note that this trait places no requirements on the <em>items</em> yielded by the stream, even when those items are futures.</li>
  <li><code class="language-plaintext highlighter-rouge">Iter</code> can implement <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code> unconditionally. Most other stream combinators (such as <code class="language-plaintext highlighter-rouge">Fuse</code>) will implement it if the underlying stream does.</li>
  <li>Change <code class="language-plaintext highlighter-rouge">Buffered</code> to require that the wrapped stream implement <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code> <em>and</em> that its <code class="language-plaintext highlighter-rouge">Item</code> type implement <code class="language-plaintext highlighter-rouge">SpawnedFuture</code> as well.</li>
  <li><code class="language-plaintext highlighter-rouge">Buffered</code> can also implement <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code> unconditionally, but only because we’re changing it to always be safe. The <em>current</em> version of <code class="language-plaintext highlighter-rouge">Buffered</code> would <em>not</em> be able to implement <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code>!</li>
  <li>Change <code class="language-plaintext highlighter-rouge">Zip</code> to require that the underlying streams implement <code class="language-plaintext highlighter-rouge">SpawnedPollStream</code> as well. (No restrictions on <code class="language-plaintext highlighter-rouge">Item</code> are necessary in this case.)</li>
</ul>

<h2 id="you-only-buffer-once">You only buffer once</h2>

<p>The above scheme prevents deadlocks, but it is also highly conservative. In particular, it requires <em>any</em> futures that end up in a stream which is eventually buffered (or zipped) to be spawned. However, as mentioned previously, this is not actually necessary in the common case where 1) the futures are created on the fly and 2) the stream is only buffered/zipped/etc. once.</p>

<p>If you have something like <code class="language-plaintext highlighter-rouge">stream::iter(non_async_thing).map(|v| async {whatever}).buffered(42)</code>, that is perfectly safe as long as <code class="language-plaintext highlighter-rouge">whatever</code> is not sneaking in any pre-existing futures under the hood and as long as the stream is not buffered <em>a second time</em>. This is how streams are most commonly used in practice, so it would be nice if we could support it without modification somehow.</p>

<p>Unfortunately, supporting this case seems to be impossible. The problem is that <code class="language-plaintext highlighter-rouge">Map</code> only sees a <code class="language-plaintext highlighter-rouge">FnMut(T) -&gt; impl Future</code>. There’s no way to distinguish from the types alone between something safe like an ordinary inline <code class="language-plaintext highlighter-rouge">async</code> block and an evil function which is sneaking in futures from elsewhere.</p>

<p>In fact, it can’t even be determined <em>syntactically</em> either. Even if you see innocuous looking code like <code class="language-plaintext highlighter-rouge">.map(|v| async move {foo(v).await})</code>, there’s no way to know without checking the implementation of <code class="language-plaintext highlighter-rouge">foo</code> whether <code class="language-plaintext highlighter-rouge">foo</code> itself is smuggling in futures. Therefore, this problem seems intractable, although I am open to suggestions.</p>

<p>One possibility is to have an escape hatch where programmers can manually assert that their functions are well-behaved async blocks (on the pain of possible deadlocks if they get it wrong). For example, we could have some wrapper type, say <code class="language-plaintext highlighter-rouge">NewlyCreatedFuture&lt;F: Future&gt;(F)</code> where users are expected to (but not enforced to) only wrap around futures which were created on the fly. Then we could have <code class="language-plaintext highlighter-rouge">Buffered</code> accept streams where <code class="language-plaintext highlighter-rouge">Item = NewlyCreatedFuture</code> as well, but have the resulting buffered stream <code class="language-plaintext highlighter-rouge">!SpawnedPollStream</code> to prevent it from being buffered a second time. Under this system, most code can be used unmodified by just adding a <code class="language-plaintext highlighter-rouge">.map(NewlyCreatedFuture)</code> before the <code class="language-plaintext highlighter-rouge">.buffered()</code> for cases where programmers are confident that their functions are not vulnerable to deadlocks.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Making these changes won’t be easy, but that doesn’t mean they shouldn’t be done. Before Rust came along, achieving both memory safety and C++ levels of performance in a practical, easy-to-use language seemed impossible. And this change doesn’t even require a new language! It’s just a matter of redesigning a commonly used library to be less error-prone. Hopefully someday, deadlocks too will be an almost-unheard of class of bug. Even if this proposal isn’t suitable for implementation as is, I hope this starts a conversation so we can find better ways to address the problem.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I am fortunate enough to work on a production Rust service (a real one, not cryptocurrency nonsense). Rust virtually eliminates the kinds of stupid bugs and gotchas that are endemic in other languages, making it much easier to develop and maintain our project. Unfortunately, Rust is substantially less capable when it comes to preventing the common issues involved in async programming. In fact, async programming is substantially harder to get right in Rust than in something like Javascript, due to the decision to make task spawning explicit for performance reasons.]]></summary></entry><entry><title type="html">An Unfortunate Experience with Rust</title><link href="/2022/06/25/an-unfortunate-experience-with-rust.html" rel="alternate" type="text/html" title="An Unfortunate Experience with Rust" /><published>2022-06-25T21:18:00+00:00</published><updated>2022-06-25T21:18:00+00:00</updated><id>/2022/06/25/an-unfortunate-experience-with-rust</id><content type="html" xml:base="/2022/06/25/an-unfortunate-experience-with-rust.html"><![CDATA[<style>
/*pre {white-space: pre-wrap};*/
span.bold {font-weight: bold;}
span.red {color: red;}
span.green {color: green;}
span.blue {color: blue;}
span.cyan {color: cyan;}
</style>

<p>I consider myself to be pretty experienced in Rust. I’ve been using Rust in personal projects since late 2016 and professionally since early 2021. I’ve prepared internal presentations to teach coworkers about borrow checking and about async programming. However, even I still occasionally run into issues fighting the Rust compiler, and the following is a series of particularly unfortunate issues I ran into at work this week.</p>

<h3 id="background">Background</h3>

<blockquote>
  <p><strong>Note:</strong> The following code examples are simplified in order to demonstrate the essence of the problem. Obviously, our actual code is a lot more complicated.</p>
</blockquote>

<p>We have an async trait <code class="language-plaintext highlighter-rouge">Foo</code> with a method <code class="language-plaintext highlighter-rouge">update_all</code> to process a list of items, which then calls the per-implementation <code class="language-plaintext highlighter-rouge">update</code> method on the trait.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[async_trait(</span><span class="err">?</span><span class="nd">Send)]</span>
<span class="k">trait</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="k">async</span> <span class="k">fn</span> <span class="nf">update</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">String</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span> <span class="n">Error</span><span class="o">&gt;</span><span class="p">;</span>

    <span class="k">async</span> <span class="k">fn</span> <span class="nf">update_all</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">items</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="nn">stream</span><span class="p">::</span><span class="nf">iter</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
            <span class="nf">.map</span><span class="p">(</span><span class="k">move</span> <span class="p">|</span><span class="n">item</span><span class="p">|</span> <span class="k">async</span> <span class="k">move</span> <span class="p">{</span> <span class="k">self</span><span class="nf">.update</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="k">.await</span> <span class="p">})</span>
            <span class="nf">.buffered</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
            <span class="nf">.try_collect</span><span class="p">()</span>
            <span class="k">.await</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We then have several implementations of <code class="language-plaintext highlighter-rouge">Foo</code>, here represented by <code class="language-plaintext highlighter-rouge">FooImpl</code>, and another type <code class="language-plaintext highlighter-rouge">FooWrapper</code> which makes use of a boxed <code class="language-plaintext highlighter-rouge">dyn Foo</code> to do various things.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">FooImpl</span><span class="p">;</span>
<span class="nd">#[async_trait(</span><span class="err">?</span><span class="nd">Send)]</span>
<span class="k">impl</span> <span class="n">Foo</span> <span class="k">for</span> <span class="n">FooImpl</span> <span class="p">{</span>
    <span class="k">async</span> <span class="k">fn</span> <span class="nf">update</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">String</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} Updating {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">item</span><span class="p">);</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">tokio</span><span class="p">::</span><span class="nn">time</span><span class="p">::</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_millis</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="k">.await</span><span class="p">;</span>
        <span class="nf">Ok</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">FooWrapper</span> <span class="p">{</span>
    <span class="n">foo</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Foo</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>
<span class="k">impl</span> <span class="n">FooWrapper</span> <span class="p">{</span>
    <span class="k">async</span> <span class="k">fn</span> <span class="nf">do_all_the_things</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">..</span><span class="mi">10</span><span class="p">)</span><span class="nf">.into_iter</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">i</span><span class="p">|</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"Item {}"</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span><span class="nf">.collect</span><span class="p">();</span>
        <span class="k">self</span><span class="py">.foo</span><span class="nf">.update_all</span><span class="p">(</span><span class="n">items</span><span class="p">)</span><span class="k">.await</span><span class="o">?</span><span class="p">;</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="the-task">The task</h3>

<p>The change I needed to make was to call some extra logic in <code class="language-plaintext highlighter-rouge">FooWrapper</code> right before each item is processed in the loop inside <code class="language-plaintext highlighter-rouge">Foo::update_all</code>, which is here represented by the <code class="language-plaintext highlighter-rouge">Updates</code> struct and its <code class="language-plaintext highlighter-rouge">notify</code> method. Note that this is a <em>mutable</em> method.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Updates</span><span class="p">;</span>
<span class="k">impl</span> <span class="n">Updates</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">notify</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">String</span><span class="p">)</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"{:?} About to update {}"</span><span class="p">,</span> <span class="nf">time</span><span class="p">(),</span> <span class="n">item</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">FooWrapper</span> <span class="p">{</span>
    <span class="n">foo</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="k">dyn</span> <span class="n">Foo</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">updates</span><span class="p">:</span> <span class="n">Updates</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="part-1-adding-a-callback-parameter">Part 1: Adding a callback parameter</h3>

<p>The obvious approach is to pass a callback into the <code class="language-plaintext highlighter-rouge">Foo::update_all</code> method, and call that before each update. Since <code class="language-plaintext highlighter-rouge">Foo</code> is a dyn trait, the callback needs to be dyn as well, and that usually means boxing, so I went ahead and added a boxed function parameter:</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code> trait Foo {
     async fn update(&amp;self, item: String) -&gt; Result&lt;String, Error&gt;;
 
<span class="gd">-    async fn update_all(&amp;self, items: Vec&lt;String&gt;) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
</span><span class="gi">+    async fn update_all(
+        &amp;self,
+        items: Vec&lt;String&gt;,
+        cb: Box&lt;dyn FnMut(String)&gt;,
+    ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
</span>         stream::iter(items)
             .map(move |item| async move { self.update(item).await })
             .buffered(3)
</code></pre></div></div>
<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code> impl FooWrapper {
     async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
         let items = (0..10).into_iter().map(|i| format!("Item {}", i)).collect();
<span class="gd">-        self.foo.update_all(items).await?;
</span><span class="gi">+        let mut cb = |item| self.updates.notify(item);
+        self.foo.update_all(items, Box::new(cb)).await?;
</span>         Ok(())
     }
 }
</code></pre></div></div>

<p>This results in our first misleading lifetime error message:</p>

<pre><span class="bold red">error</span><span class="bold">: lifetime may not live long enough
  </span><span class="bold blue">--&gt; </span>src/main.rs:60:36
   <span class="bold blue">|
57 | </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
   <span class="bold blue">|                                - let's call the lifetime of this reference `'1`
...
60 | </span>        self.foo.update_all(items, Box::new(cb)).await?;
   <span class="bold blue">|                                    </span><span class="bold red">^^^^^^^^^^^^ cast requires that `'1` must outlive `'static`
   </span><span class="bold blue">|
</span><span class="bold cyan">help</span>: to allow this `impl Trait` to capture borrowed data with lifetime `'1`, add `'_` as a bound
   <span class="bold blue">|
57 | </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt;<span class="green"> + '_</span> {
   <span class="bold blue">|                                                                </span><span class="green">++++

</span></pre>

<p>Most compiler errors in Rust are clear and easy to fix, but this one is different. This error points to <em>the completely wrong part of the code</em> and the suggested fix <em>isn’t even valid Rust</em>, as we can confirm if we try to perform the suggested fix anyway:</p>

<pre><span class="bold red">error[E0404]</span><span class="bold">: expected trait, found enum `Result`
  </span><span class="bold blue">--&gt; </span>src/main.rs:57:46
   <span class="bold blue">|
57 | </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; + '_ {
   <span class="bold blue">|                                              </span><span class="bold red">^^^^^^^^^^^^^^^^^ not a trait
   </span><span class="bold blue">|
</span><span class="bold cyan">help</span>: `+` is used to constrain a "trait object" type with lifetimes or auto-traits; structs and enums can't be bound in that way
  <span class="bold blue">--&gt; </span>src/main.rs:57:66
   <span class="bold blue">|
57 | </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; + '_ {
   <span class="bold blue">|                                              -----------------   </span><span class="bold cyan">^^ ...because of this bound
   </span><span class="bold blue">|                                              |
   |                                              expected this type to be a trait...
</span><span class="bold cyan">help</span>: if you meant to use a type and not a trait here, remove the bounds
   <span class="bold blue">|
57 </span><span class="red">- </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt;<span class="red"> + '_</span> {
<span class="bold blue">57 </span><span class="green">+ </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
   <span class="bold blue">| 

</span><span class="bold red">error[E0782]</span><span class="bold">: trait objects must include the `dyn` keyword
  </span><span class="bold blue">--&gt; </span>src/main.rs:57:46
   <span class="bold blue">|
57 | </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; + '_ {
   <span class="bold blue">|                                              </span><span class="bold red">^^^^^^^^^^^^^^^^^^^^^^
   </span><span class="bold blue">|
</span><span class="bold cyan">help</span>: add `dyn` keyword before this trait
   <span class="bold blue">|
57 </span><span class="red">- </span>    async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; + '_ {
<span class="bold blue">57 </span><span class="green">+ </span>    async fn do_all_the_things(&amp;mut self) -&gt; <span class="green">dyn </span>Result&lt;(), Error&gt; + '_ {
   <span class="bold blue">| 

</span><span class="bold">Some errors have detailed explanations: E0404, E0782.
For more information about an error, try `rustc --explain E0404`.
</span></pre>

<p>Now I should be clear - <strong>Rust is my favorite language</strong>. Rust really stands out for the high quality of its compiler error messages, which is why I was surprised to see such a broken error here. I’m pointing this out because I hold Rust to a higher standard, and so that people can fix this error and make it even better. In many programming languages, inscrutable and misleading compiler error messages are a routine fact of life, not something notable enough to be worth spending my whole Saturday writing a blog post about.</p>

<h3 id="1b">1b</h3>

<p>Fortunately, this error is easily fixed, in spite of the broken error message. We know that we just added a boxed trait object to the signature of <code class="language-plaintext highlighter-rouge">update_all</code>, and that our callback captures a reference to <code class="language-plaintext highlighter-rouge">FooWrapper</code> and that we probably need to indicate that in its type somehow.</p>

<p>We need to add a lifetime bound which is tied to the future that <code class="language-plaintext highlighter-rouge">update_all</code> returns, but it wasn’t clear to me how to do that, given that this is an async trait method. I decided to just add a <code class="language-plaintext highlighter-rouge">'_</code> to see what would happen.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     async fn update_all(
         &amp;self,
         items: Vec&lt;String&gt;,
<span class="gd">-        cb: Box&lt;dyn FnMut(String)&gt;,
</span><span class="gi">+        cb: Box&lt;dyn FnMut(String) + '_&gt;,
</span>     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
         stream::iter(items)
             .map(move |item| async move { self.update(item).await })
</code></pre></div></div>

<p>Fortunately, this time, Rust tells us exactly what we need to do. Apparently, the <code class="language-plaintext highlighter-rouge">async_trait</code> macro generates a <code class="language-plaintext highlighter-rouge">'async_trait</code> lifetime that we can use.</p>

<pre><span class="bold red">error[E0621]</span><span class="bold">: explicit lifetime required in the type of `cb`
  </span><span class="bold blue">--&gt; </span>src/main.rs:26:37
   <span class="bold blue">|
25 |   </span>        cb: Box&lt;dyn FnMut(String) + '_&gt;,
   <span class="bold blue">|               --------------------------- help: add explicit lifetime `'async_trait` to the type of `cb`: `Box&lt;(dyn FnMut(String) + 'async_trait)&gt;`
26 |   </span>    ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
   <span class="bold blue">|  </span><span class="bold red">_____________________________________^
</span><span class="bold blue">27 | </span><span class="bold red">| </span>        stream::iter(items)
<span class="bold blue">28 | </span><span class="bold red">| </span>            .map(move |item| async move { self.update(item).await })
<span class="bold blue">29 | </span><span class="bold red">| </span>            .buffered(3)
<span class="bold blue">30 | </span><span class="bold red">| </span>            .try_collect()
<span class="bold blue">31 | </span><span class="bold red">| </span>            .await
<span class="bold blue">32 | </span><span class="bold red">| </span>    }
   <span class="bold blue">| </span><span class="bold red">|_____^ lifetime `'async_trait` required

</span><span class="bold">For more information about this error, try `rustc --explain E0621`.
</span></pre>

<h3 id="1c">1c</h3>

<p>I later realized that the boxing isn’t necessary in the first place. Boxing is a Rustacean’s first instinct for passing around <code class="language-plaintext highlighter-rouge">dyn Trait</code> objects, but in this case, it makes more sense to pass the callback by mutable reference instead. In fact, the <code class="language-plaintext highlighter-rouge">Box</code> doesn’t actually add anything here since the closure is not <code class="language-plaintext highlighter-rouge">'static</code> anyway - the closure is effectively just a <code class="language-plaintext highlighter-rouge">&amp;mut Updates</code> pointing into the parent <code class="language-plaintext highlighter-rouge">FooWrapper</code>.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     async fn update_all(
         &amp;self,
         items: Vec&lt;String&gt;,
<span class="gd">-        cb: Box&lt;dyn FnMut(String) + '_&gt;,
</span><span class="gi">+        cb: &amp;mut dyn FnMut(String),
</span>     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
         stream::iter(items)
             .map(move |item| async move { self.update(item).await })

     async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
         let items = (0..10).into_iter().map(|i| format!("Item {}", i)).collect();
         let mut cb = |item| self.updates.notify(item);
<span class="gd">-        self.foo.update_all(items, Box::new(cb)).await?;
</span><span class="gi">+        self.foo.update_all(items, &amp;mut cb).await?;
</span>         Ok(())
     }
 }

</code></pre></div></div>

<p>Switching to <code class="language-plaintext highlighter-rouge">&amp;mut</code> dodges the lifetime issues we had with the <code class="language-plaintext highlighter-rouge">Box</code> approach above. If I’d thought of that the first time around, it would have saved a lot of trouble. On the other hand, this way I discovered a broken error message to report, so perhaps it was for the best.</p>

<h2 id="part-2-calling-the-callback">Part 2: Calling the callback</h2>

<p>Now comes the <em>hard</em> part - actually calling the callback parameter that we added to <code class="language-plaintext highlighter-rouge">update_all</code>.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
         stream::iter(items)
<span class="gd">-            .map(move |item| async move { self.update(item).await })
</span><span class="gi">+            .map(move |item| async move {
+                cb(item.clone());
+                self.update(item).await
+            })
</span>             .buffered(3)
             .try_collect()
</code></pre></div></div>

<p>The naive approach predictably fails:</p>

<pre><span class="bold red">error[E0507]</span><span class="bold">: cannot move out of `cb`, a captured variable in an `FnMut` closure
  </span><span class="bold blue">--&gt; </span>src/main.rs:28:41
   <span class="bold blue">|
25 |    </span>        cb: &amp;mut dyn FnMut(String),
   <span class="bold blue">|            -- captured outer variable
...
28 |    </span>            .map(move |item| async move {
   <span class="bold blue">|  </span><span class="bold red">___________________</span><span class="bold blue">-</span><span class="bold red">______________________^
   </span><span class="bold blue">| </span><span class="bold red">| </span><span class="bold blue">__________________|
   | </span><span class="bold red">|</span><span class="bold blue">|
29 | </span><span class="bold red">|</span><span class="bold blue">| </span>                cb(item.clone());
   <span class="bold blue">| </span><span class="bold red">|</span><span class="bold blue">|                 -- move occurs because `cb` has type `&amp;mut dyn FnMut(String)`, which does not implement the `Copy` trait
30 | </span><span class="bold red">|</span><span class="bold blue">| </span>                self.update(item).await
<span class="bold blue">31 | </span><span class="bold red">|</span><span class="bold blue">| </span>            })
   <span class="bold blue">| </span><span class="bold red">|</span><span class="bold blue">|             </span><span class="bold red">^
   </span><span class="bold blue">| </span><span class="bold red">|</span><span class="bold blue">|_____________</span><span class="bold red">|
   </span><span class="bold blue">| </span><span class="bold red">|______________</span><span class="bold blue">captured by this `FnMut` closure
   |                </span><span class="bold red">move out of `cb` occurs here

</span><span class="bold">For more information about this error, try `rustc --explain E0507`.
</span></pre>

<p>Unfortunately, the <em>non-naive</em> approaches also all fail here. There’s just no way to do what we want to do here in Rust. The problem is that we’re creating a bunch of futures, and in order to call the callback, Rust requires them to <em>each</em> have a reference to <code class="language-plaintext highlighter-rouge">cb</code> that is exclusive for the <em>entire</em> duration of the stream.</p>

<p>Usually when you run into an intractable borrow problem in Rust, it means that either a) there’s a bug in your code or b) you need a self-referential type, which requires unsafe code. (There are a number of libraries that aim to fill that gap, such as <code class="language-plaintext highlighter-rouge">owning_ref</code> and <code class="language-plaintext highlighter-rouge">ouroboros</code>, but <a href="https://github.com/noamtashma/owning-ref-unsoundness">their soundness is rather dubious</a>).</p>

<p>Here, on the other hand, we have a “type system false positive” of a different sort. Our callback is synchronous, and the <code class="language-plaintext highlighter-rouge">update_all</code> future can only ever poll a single child future at once, so the callback can only ever be called once at a time. What we need is a reference that is only exclusive <em>while the future is being polled</em>, but Rust provides no facility for this.</p>

<p>The usual approach to solve this in Rust is to just have a <em>single</em> exclusive (i.e. <code class="language-plaintext highlighter-rouge">&amp;mut</code>) reference that we thread through the stream and pass into each future just while it is being polled (or pass around a <code class="language-plaintext highlighter-rouge">GhostCell</code> token if passing the data itself around is too cumbersome for some reason). Unfortunately, <code class="language-plaintext highlighter-rouge">Future</code> and <code class="language-plaintext highlighter-rouge">Stream</code> have fixed interfaces and there is no way to pass extra data through them.</p>

<h3 id="2b">2b</h3>

<p>Given that there is no “proper” way to solve this in Rust, we just have to sigh and go with an imperfect solution. We can work around the issue by wrapping the callback in an unnecessary <code class="language-plaintext highlighter-rouge">RefCell</code>:</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         items: Vec&lt;String&gt;,
         cb: &amp;mut dyn FnMut(String),
     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
<span class="gi">+        let cb = RefCell::new(cb);
</span>         stream::iter(items)
             .map(move |item| async move {
<span class="gd">-                cb(item.clone());
</span><span class="gi">+                cb.borrow_mut()(item.clone());
</span>                 self.update(item).await
             })
             .buffered(3)
</code></pre></div></div>

<p>Since our <code class="language-plaintext highlighter-rouge">map</code> closure is <code class="language-plaintext highlighter-rouge">move</code>, we also need to store a (shared) reference in a local variable so it can be moved into the closure. Note that in this example, there’s no particular reason for the closure to be <code class="language-plaintext highlighter-rouge">move</code>, but the real world code which inspired this post had other stuff going on which required it.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         cb: &amp;mut dyn FnMut(String),
     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
         let cb = RefCell::new(cb);
<span class="gi">+        let cb = &amp;cb;
</span>         stream::iter(items)
             .map(move |item| async move {
                 cb.borrow_mut()(item.clone());
</code></pre></div></div>

<p>… and it works. Yay!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>381ns About to update Item 0
10.431µs Updating Item 0
31.824µs About to update Item 1
36.807µs Updating Item 1
49.812µs About to update Item 2
54.461µs Updating Item 2
101.421368ms About to update Item 3
101.444199ms Updating Item 3
101.477413ms About to update Item 4
101.494382ms Updating Item 4
101.513491ms About to update Item 5
101.522133ms Updating Item 5
202.929102ms About to update Item 6
202.946752ms Updating Item 6
202.972324ms About to update Item 7
202.97918ms Updating Item 7
202.992133ms About to update Item 8
203.004573ms Updating Item 8
304.513564ms About to update Item 9
304.544859ms Updating Item 9

</code></pre></div></div>

<h3 id="2c">2c</h3>

<p>Again, it should be noted that as much as I complain about having to add an unnecessary <code class="language-plaintext highlighter-rouge">RefCell</code> here, I think this is really a testament to Rust and how far it can be pushed. Rust makes it easy to track ownership and aliasing invariants through many layers of abstraction and across large codebases, to the point where people get upset in the rare cases where this <em>isn’t</em> possible. Meanwhile, in other languages programmers slather the code with defensive copies and refcounts and gratuitous runtime checks for far less than this (and in the case of C++, almost certainly <em>still</em> get it wrong and have tons of mysterious crashes).</p>

<h2 id="part-3-making-it-optional">Part 3: Making it optional</h2>

<p>The previous code works, but it has the problem that <em>every</em> caller of <code class="language-plaintext highlighter-rouge">update_all</code> must now provide a callback. Let’s try to make the callback parameter optional instead.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     async fn update_all(
         &amp;self,
         items: Vec&lt;String&gt;,
<span class="gd">-        cb: &amp;mut dyn FnMut(String),
</span><span class="gi">+        cb: Option&lt;&amp;mut dyn FnMut(String)&gt;,
</span>     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
         let cb = RefCell::new(cb);
         let cb = &amp;cb;
</code></pre></div></div>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     async fn do_all_the_things(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
         let items = (0..10).into_iter().map(|i| format!("Item {}", i)).collect();
         let mut cb = |item| self.updates.notify(item);
<span class="gd">-        self.foo.update_all(items, &amp;mut cb).await?;
</span><span class="gi">+        self.foo.update_all(items, Some(&amp;mut cb)).await?;
</span>         Ok(())
     }
 }
</code></pre></div></div>

<p>Now, how do we actually make this work inside <code class="language-plaintext highlighter-rouge">update_all</code>? The natural approach is to just use a default no-op callback if one isn’t provided.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         items: Vec&lt;String&gt;,
         cb: Option&lt;&amp;mut dyn FnMut(String)&gt;,
     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
<span class="gi">+        let cb = cb.unwrap_or(&amp;mut |_| ());
</span>         let cb = RefCell::new(cb);
         let cb = &amp;cb;
         stream::iter(items)
</code></pre></div></div>

<p>Unfortunately, this doesn’t work:</p>

<pre><span class="bold red">error[E0716]</span><span class="bold">: temporary value dropped while borrowed
  </span><span class="bold blue">--&gt; </span>src/main.rs:27:36
   <span class="bold blue">|
27 | </span>        let cb = cb.unwrap_or(&amp;mut |_| ());
   <span class="bold blue">|                                    </span><span class="bold red">^^^^^^ </span><span class="bold blue">- temporary value is freed at the end of this statement
   |                                    </span><span class="bold red">|
   </span><span class="bold blue">|                                    </span><span class="bold red">creates a temporary which is freed while still in use
</span><span class="bold blue">28 | </span>        let cb = RefCell::new(cb);
   <span class="bold blue">|                               -- borrow later used here
   |
   = </span><span class="bold">note</span>: consider using a `let` binding to create a longer lived value

<span class="bold">For more information about this error, try `rustc --explain E0716`.
</span></pre>

<p>I thought the problem might have to do with it being a closure, so I tried converting it to a regular function.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         items: Vec&lt;String&gt;,
         cb: Option&lt;&amp;mut dyn FnMut(String)&gt;,
     ) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; {
<span class="gi">+        fn default_cb(_: String) {}
+        let cb = cb.unwrap_or(&amp;mut default_cb);
</span>         let cb = RefCell::new(cb);
         let cb = &amp;cb;
         stream::iter(items)
</code></pre></div></div>

<p>Surely taking a reference to a plain function would work. After all, functions are stateless and static - there’s no way this could fail a borrow check…</p>

<pre><span class="bold red">error[E0716]</span><span class="bold">: temporary value dropped while borrowed
  </span><span class="bold blue">--&gt; </span>src/main.rs:28:36
   <span class="bold blue">|
28 | </span>        let cb = cb.unwrap_or(&amp;mut default_cb);
   <span class="bold blue">|                                    </span><span class="bold red">^^^^^^^^^^ </span><span class="bold blue">- temporary value is freed at the end of this statement
   |                                    </span><span class="bold red">|
   </span><span class="bold blue">|                                    </span><span class="bold red">creates a temporary which is freed while still in use
</span><span class="bold blue">29 | </span>        let cb = RefCell::new(cb);
   <span class="bold blue">|                               -- borrow later used here
   |
   = </span><span class="bold">note</span>: consider using a `let` binding to create a longer lived value

<span class="bold">For more information about this error, try `rustc --explain E0716`.
</span></pre>

<h3 id="3b">3b</h3>

<p>To be honest, I’m still not sure why that didn’t work. Fortunately, there’s a plan B - we can just keep the <code class="language-plaintext highlighter-rouge">Option</code> inside the <code class="language-plaintext highlighter-rouge">RefCell</code> and check whether the callback exists in the inner loop every time we call it, which is probably the cleaner and more principled approach anyway.</p>

<p>It’s hard to keep track of the billions of helper methods on <code class="language-plaintext highlighter-rouge">Option</code> and <code class="language-plaintext highlighter-rouge">Result</code>, but this is a pretty simple case. We just want to run some code on the contained value (i.e. callback) if present, and do nothing if not present, which is normally done via <code class="language-plaintext highlighter-rouge">Option::map</code>.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         let cb = &amp;cb;
         stream::iter(items)
             .map(move |item| async move {
<span class="gd">-                cb.borrow_mut()(item.clone());
</span><span class="gi">+                cb.borrow_mut().map(|cb| cb(item.clone()));
</span>                 self.update(item).await
             })
             .buffered(3)
</code></pre></div></div>

<p>Unfortunately, this results in the <em>second</em> broken error message I ran into.</p>

<pre><span class="bold red">error[E0507]</span><span class="bold">: cannot move out of dereference of `RefMut&lt;'_, Option&lt;&amp;mut dyn FnMut(String)&gt;&gt;`
  </span><span class="bold blue">--&gt; </span>src/main.rs:31:17
   <span class="bold blue">|
31 | </span>                cb.borrow_mut().map(|cb| cb(item.clone()));
   <span class="bold blue">|                 </span><span class="bold red">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ move occurs because value has type `Option&lt;&amp;mut dyn FnMut(String)&gt;`, which does not implement the `Copy` trait
   </span><span class="bold blue">|
</span><span class="bold cyan">help</span>: consider borrowing the `Option`'s content
   <span class="bold blue">|
31 | </span>                cb.borrow_mut().map(|cb| cb(item.clone()))<span class="green">.as_ref()</span>;
   <span class="bold blue">|                                                           </span><span class="green">+++++++++

</span><span class="bold">For more information about this error, try `rustc --explain E0507`.
</span></pre>

<p>This error message is clearly nonsense, because our callback returns <code class="language-plaintext highlighter-rouge">()</code>, i.e. nothing, and there is no reason you would ever want to call <code class="language-plaintext highlighter-rouge">.as_ref()</code> on an optional <em>nothing</em> - there’s no lifetimes contained in the result to dodge in the first place!</p>

<p>If we humor the Rust compiler anyway, it just repeats the same nonsense suggestion in an infinite loop:</p>

<pre><span class="bold red">error[E0507]</span><span class="bold">: cannot move out of dereference of `RefMut&lt;'_, Option&lt;&amp;mut dyn FnMut(String)&gt;&gt;`
  </span><span class="bold blue">--&gt; </span>src/main.rs:31:17
   <span class="bold blue">|
31 | </span>                cb.borrow_mut().map(|cb| cb(item.clone())).as_ref();
   <span class="bold blue">|                 </span><span class="bold red">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ move occurs because value has type `Option&lt;&amp;mut dyn FnMut(String)&gt;`, which does not implement the `Copy` trait
   </span><span class="bold blue">|
</span><span class="bold cyan">help</span>: consider borrowing the `Option`'s content
   <span class="bold blue">|
31 | </span>                cb.borrow_mut().map(|cb| cb(item.clone()))<span class="green">.as_ref()</span>.as_ref();
   <span class="bold blue">|                                                           </span><span class="green">+++++++++

</span><span class="bold">For more information about this error, try `rustc --explain E0507`.
</span></pre>

<p>This error took quite a bit of trial and error, and some red herrings, to resolve. I noticed that <code class="language-plaintext highlighter-rouge">RefMut</code> (the type of the lock guard) has its own <code class="language-plaintext highlighter-rouge">map</code> method and thought it might be calling the wrong one, so I tried using <a href="https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/book/first-edition/ufcs.html">UFCS</a> to call <code class="language-plaintext highlighter-rouge">Option::map</code> explicitly, but that didn’t work.</p>

<p>I ended up having to split the line up so that each call was a separate variable on a separate line, and then added explicit type annotations to each one (which also required constantly adding and removing imports to the top of the file) in order to narrow down the source of the error. In retrospect, my mistake was obvious, but I’m disappointed that the Rust compiler provided little assistance in discovering it.</p>

<p>The problem is that our refcell has type <code class="language-plaintext highlighter-rouge">RefCell&lt;Option&lt;T&gt;&gt;</code> (where <code class="language-plaintext highlighter-rouge">T</code> is <code class="language-plaintext highlighter-rouge">&amp;mut dyn FnMut(String)</code>). This means that borrowing it results in a guard which derefs to <code class="language-plaintext highlighter-rouge">&amp;mut Option&lt;T&gt;</code>. However, what we <em>want</em> is an <code class="language-plaintext highlighter-rouge">Option&lt;&amp;mut T&gt;</code>, so that we can then unwrap it and call the contained callback. Therefore, the solution is to just add an <code class="language-plaintext highlighter-rouge">as_mut</code> call:</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         let cb = &amp;cb;
         stream::iter(items)
             .map(move |item| async move {
<span class="gd">-                cb.borrow_mut().map(|cb| cb(item.clone()));
</span><span class="gi">+                cb.borrow_mut().as_mut().map(|cb| cb(item.clone()));
</span>                 self.update(item).await
             })
             .buffered(3)
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>…and that’s how what I expected to be a simple change ended up taking the better part of two days. Even as a long-time user of Rust, I still sometimes get frustrated by errors, and sometimes quite frustrated indeed. However, I think this also shows how far Rust has come, in that such cases are the exception rather than the norm, and I hope by highlighting these issues that it will continue to improve.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry></feed>